<h3 id="bib:year-2020" class="bibsonomy_quicknav_group"><a name="2020">2020</a></h3>
<div style="margin-bottom:1em">
<b>Automating hierarchical subject index construction for scientific documents</b>.<br/>
In: 
S. O. Kuznetsov, A. I. Panov and K. S. Yakovlev, editors, 
<i>Artificial Intelligence</i>, pages 201-214.
Springer International Publishing, Cham, 2020.

<br/>
Elena I. Bolshakova and Kirill M. Ivanov.
<br/>

<a href="https://doi.org/10.1007/978-3-030-59535-7_14">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '3ffe781bb2a6cb8fd65e4939198b8bc8'); return false;" href="https://www.bibsonomy.org/bibtex/23ffe781bb2a6cb8fd65e4939198b8bc8/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '3ffe781bb2a6cb8fd65e4939198b8bc8', 'https://www.bibsonomy.org/bibtex/23ffe781bb2a6cb8fd65e4939198b8bc8/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/23ffe781bb2a6cb8fd65e4939198b8bc8/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_3ffe781bb2a6cb8fd65e4939198b8bc8lepsky" style="display:none;border:1px dotted grey;">
Subject, or back-of-the-book index consists of significant terms with relevant page numbers of the text document, thus providing an easy access to its content. The paper describes methods developed for automating main stages of subject indexing for specialized texts: namely, term extraction, selection of the most important ones, detecting their reference pages, as well as recognizing semantic relations among selected index terms in order to structure them into hierarchy. The developed methods are intended for processing scientific documents in Russian and are based both on formal linguistics rules and unsupervised machine learning. Experimental evaluation of the methods have shown their sufficient quality to be built into computer subject indexing system.
</div>
<div style="position:relative">						
	<div id="bib_3ffe781bb2a6cb8fd65e4939198b8bc8lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Improving the effectiveness of subject facets in library catalogs and beyond : a MARC-based semiautomated approach</b>. <br/>
<i>Library Hi Tech</i>, ahead-of-print(ahead-of-print), 2020.

<br/>
Andrea Cuna and Gabriele Angeli.
<br/>
<a href="https://doi.org/10.1108/LHT-07-2019-0132">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'ccc647761fe1cbb53f20573a4224941d'); return false;" href="https://www.bibsonomy.org/bibtex/2ccc647761fe1cbb53f20573a4224941d/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'ccc647761fe1cbb53f20573a4224941d', 'https://www.bibsonomy.org/bibtex/2ccc647761fe1cbb53f20573a4224941d/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2ccc647761fe1cbb53f20573a4224941d/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_ccc647761fe1cbb53f20573a4224941dlepsky" style="display:none;border:1px dotted grey;">
Purpose This paper puts forward a MARC-based semiautomated approach to extracting semantically rich subject facets from general and/or specialized controlled vocabularies for display in topic-oriented faceted catalog interfaces in a way that would better support users' exploratory search tasks. Design/methodology/approach Hierarchical faceted subject metadata is extracted from general and/or specialized controlled vocabularies by using standard client/server communication protocols. Rigorous facet analysis, classification and linguistic principles are applied on top of that to ensure faceting accuracy and consistency. Findings A shallow application of facet analysis and classification, together with poorly organized displays, is one of the major barriers to effective faceted navigation in library, archive and museum catalogs. Research limitations/implications This paper does not deal with Web-scale discovery services. Practical implications This paper offers suggestions that can be used by the technical services departments of libraries, archives and museums in designing and developing more powerful exploratory search interfaces. Originality/value This paper addresses the problem of deriving clearly delineated topical facets from existing metadata for display in a user-friendly, high-level topical overview that is meant to encourage a multidimensional exploration of local collections as well as “learning by browsing.”
</div>
<div style="position:relative">						
	<div id="bib_ccc647761fe1cbb53f20573a4224941dlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Ein Feuerwerk an Algorithmen und der Startschuss zur Bildung eines Kompetenznetzwerks für maschinelle Erschließung : Bericht zur Fachtagung „Netzwerk maschinelle Erschließung“ an der Deutschen Nationalbibliothek am 10. und 11. Oktober 2019</b>. <br/>
<i>o-bib. Das offene Bibliotheksjournal / Herausgeber VDB</i>, 7(1):1-12, 2020.

<br/>
Michael Franke-Maier, Cyrus Beck, Anna Kasprzik, Jan Frederik Maas, Sarah Pielmeier and Heidrun Wiesenmüller.
<br/>
<a href="https://www.o-bib.de/article/view/5565">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '5b6279f74e8d27a2ee156fd8518fdeb8', 'https://www.bibsonomy.org/bibtex/25b6279f74e8d27a2ee156fd8518fdeb8/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/25b6279f74e8d27a2ee156fd8518fdeb8/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_5b6279f74e8d27a2ee156fd8518fdeb8lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_5b6279f74e8d27a2ee156fd8518fdeb8lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatisierte Modellierung von akademischen Wissensdom&auml;nen als Methode zum innovativen Wissensmanagement</b>. <br/>
<i>Information - Wissenschaft &amp; Praxis</i>, 71(1):28-38, 2020.

<br/>
Inga Kampmann, Inka H&auml;hnlein and Pablo Pirnay-Dummer.
<br/>
<a href="https://www.degruyter.com/view/j/iwp.2020.71.issue-1/iwp-2019-2071/iwp-2019-2071.xml">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '93f1358e3163a5eb9a9ddd2b467d878d'); return false;" href="https://www.bibsonomy.org/bibtex/293f1358e3163a5eb9a9ddd2b467d878d/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '93f1358e3163a5eb9a9ddd2b467d878d', 'https://www.bibsonomy.org/bibtex/293f1358e3163a5eb9a9ddd2b467d878d/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/293f1358e3163a5eb9a9ddd2b467d878d/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_93f1358e3163a5eb9a9ddd2b467d878dlepsky" style="display:none;border:1px dotted grey;">
Die Modellierung von akademischen Wissensdom&auml;nen, deren Wissensinhalte sich schnell ver&auml;ndern, ist wegen des gro&szlig;en Aufwandes, st&auml;ndiger Anpassungen und gro&szlig;er Datenmengen eine Herausforderung. Dieser Artikel stellt eine L&ouml;sung f&uuml;r eine neue, epistemologische Dom&auml;nenmodellierung vor, die auf der Theorie menschlicher mentaler Modellbildung basiert und es erlaubt, akademische Wissensdom&auml;nen abzubilden, die st&auml;ndigen Ver&auml;nderungen unterworfen sind. Diese neue Art der Dom&auml;nenmodellierung erweitert das vorhandene technologische Spektrum der Wissensmodellierung (knowledge engineering) um eine neue Methodenklasse und schlie&szlig;t die bisher bestehende konzeptuelle L&uuml;cke in der Vermittlung zwischen maschineller Wissensaufbereitung und der menschlichen Nutzung. Menschliches Wissen zeichnet sich durch eine kontextabh&auml;ngige Vernetzung von Informationen aus. Diese Vernetzungen sind assoziativer Natur. Entsprechend dieser grundlegenden Funktionsweise menschlichen Wissens analysiert das validierte Textanalyseprogramm T-MITOCAR (Text Model Inspection Trace of Concepts and Relations) die in Text enthaltenen semantischen Wissensstrukturen computerlinguistisch und bildet sie als Assoziationsnetze (Landkarten des Wissens) ab. Die resultierenden Wissenslandkarten &auml;hneln in ihrem Erscheinungsbild einer Mindmap. Ziel dabei ist es, eine ad&auml;quate Re-Repr&auml;sentation menschlichen Wissens auf der Grundlage von Text bereitzustellen. Die Methoden k&ouml;nnen ebenfalls ganze Textkorpora in einem zweiten Schritt zu einer Wissensdom&auml;nenlandkarte aggregieren. Mittels dieser Technologien kann eine vollst&auml;ndige akademische Wissensdom&auml;ne automatisch als Wissenslandkarte abgebildet werden. Solche Wissensdom&auml;nenmodelle k&ouml;nnen von Institutionen mit schnelllebigen Wissensdom&auml;nen, wie z. B. Universit&auml;ten und Fachinformationsdiensten (FDI), als Instrumente des innovativen Wissens- und Informationsmanagements eingesetzt werden. Die Methoden erm&ouml;glichen Bibliotheken beispielsweise, aus verschiedenen Textkorpora automatisch je eine Wissenslandkarte zu generieren, diese zu vergleichen und inhaltliche &Uuml;berschneidungen der zugrunde liegenden Wissensdom&auml;nen zu identifizieren. Ver&auml;nderungen an der Wissensdom&auml;ne werden &uuml;berblicksartig analysierbar und Literaturempfehlungen lassen sich auf der Grundlage von bereits Geschriebenen ausgeben.
</div>
<div style="position:relative">						
	<div id="bib_93f1358e3163a5eb9a9ddd2b467d878dlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A new approach to descriptors generation for image retrieval by  analyzing activations of deep neural network layers</b>. <br/>
<i>arXiv:2007.06624 [cs]</i>, 2020.
cite arxiv:2007.06624Comment: 8
<br/>
Paweł Staszewski, Maciej Jaworski, Jinde Cao and Leszek Rutkowski.
<br/>
<a href="http://arxiv.org/abs/2007.06624">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '8f215e4ae5dfe119280ee244b9c1fb18'); return false;" href="https://www.bibsonomy.org/bibtex/28f215e4ae5dfe119280ee244b9c1fb18/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8f215e4ae5dfe119280ee244b9c1fb18', 'https://www.bibsonomy.org/bibtex/28f215e4ae5dfe119280ee244b9c1fb18/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28f215e4ae5dfe119280ee244b9c1fb18/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8f215e4ae5dfe119280ee244b9c1fb18lepsky" style="display:none;border:1px dotted grey;">
In this paper, we consider the problem of descriptors construction for the task of content-based image retrieval using deep neural networks. The idea of neural codes, based on fully connected layers activations, is extended by incorporating the information contained in convolutional layers. It is known that the total number of neurons in the convolutional part of the network is large and the majority of them have little influence on the final classification decision. Therefore, in the paper we propose a novel algorithm that allows us to extract the most significant neuron activations and utilize this information to construct effective descriptors. The descriptors consisting of values taken from both the fully connected and convolutional layers perfectly represent the whole image content. The images retrieved using these descriptors match semantically very well to the query image, and also they are similar in other secondary image characteristics, like background, textures or color distribution. These features of the proposed descriptors are verified experimentally based on the IMAGENET1M dataset using the VGG16 neural network.
</div>
<div style="position:relative">						
	<div id="bib_8f215e4ae5dfe119280ee244b9c1fb18lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Monolingual and multilingual topic analysis using LDA and BERT embeddings</b>. <br/>
<i>Journal of Informetrics</i>, 14(3):101055, 2020.

<br/>
Qing Xie, Xinyuan Zhang, Ying Ding and Min Song.
<br/>
<a href="http://www.sciencedirect.com/science/article/pii/S1751157719305127">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '645e4f31edd97145da2ba8082408e6ce'); return false;" href="https://www.bibsonomy.org/bibtex/2645e4f31edd97145da2ba8082408e6ce/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '645e4f31edd97145da2ba8082408e6ce', 'https://www.bibsonomy.org/bibtex/2645e4f31edd97145da2ba8082408e6ce/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2645e4f31edd97145da2ba8082408e6ce/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_645e4f31edd97145da2ba8082408e6celepsky" style="display:none;border:1px dotted grey;">
Analyzing research topics offers potential insights into the direction of scientific development. In particular, analyzing multilingual research topics can help researchers grasp the evolution of topics globally, revealing topic similarity among scientific publications written in different languages. Most studies to date on topic analysis have been based on English-language publications and have relied heavily on citation-based topic evolution analysis. However, since it can be challenging for English publications to cite non-English sources and since many languages do not offer English translations of abstracts, citation-based methodologies are not suitable for analyzing multilingual research topic relations. Since multilingual sentence embeddings can effectively preserve word semantics in multilingual translation tasks, a topic model based on multilingual sentence embeddings could potentially generate topic–word distributions for publications in multilingual analysis. In this paper, which is situated in the field of library and information science, we use multilingual pretrained Bidirectional Encoder Representations from Transformers (BERT) embeddings and the Latent Dirichlet Allocation (LDA) topic model to analyze topic evolution in monolingual and multilingual topic similarity settings. For each topic, we multiply its LDA probability value by the averaged tensor similarity of BERT embeddings to explore the evolution of the topic in scientific publications. As our proposed method does not rely on a machine translator or the author's subjective translation, it avoids confusion and misusages caused by either machine error or the author's subjectively chosen English keywords. Our results show that the proposed approach is well-suited to analyzing the scientific evolutions in monolingual and scientific multilingual topic similarity relations.
</div>
<div style="position:relative">						
	<div id="bib_645e4f31edd97145da2ba8082408e6celepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2019" class="bibsonomy_quicknav_group"><a name="2019">2019</a></h3>
<div style="margin-bottom:1em">
<b>Domänenspezifische hybride automatische I­ndexierung von bibliographischen Metadaten</b>. <br/>
<i>bit online</i>, 22(6):465–469, 2019.

<br/>
Dimitri Busch.
<br/>

<a onclick="toggleAbstract('lepsky', '6e2395f2c115e04d81fc845f02431291'); return false;" href="https://www.bibsonomy.org/bibtex/26e2395f2c115e04d81fc845f02431291/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '6e2395f2c115e04d81fc845f02431291', 'https://www.bibsonomy.org/bibtex/26e2395f2c115e04d81fc845f02431291/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/26e2395f2c115e04d81fc845f02431291/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_6e2395f2c115e04d81fc845f02431291lepsky" style="display:none;border:1px dotted grey;">
Im Fraunhofer-Informationszentrum Raum und Bau (IRB) wird Fachliteratur im Bereich Planen und Bauen bibliographisch erschlossen. Die daraus resultierenden Dokumente (Metadaten-Einträge) werden u.a. bei der Produktion der bibliographischen Datenbanken des IRB verwendet. Die Dokumente werden mit Deskriptoren von einer Nomenklatur (Schlagwortliste IRB) indexiert. Ein Deskriptor ist „eine Benennung..., die für sich allein verwendbar, eindeutig zur Inhaltskennzeichnung geeignet und im betreffenden Dokumentationssystem zugelassen ist”. Momentan wird die Indexierung intellektuell von menschlichen Experten durchgeführt. Die intellektuelle Indexierung ist zeitaufwendig und teuer. Eine Lösung des Problems besteht in der automatischen Indexierung, bei der die Zuordnung von Deskriptoren durch ein Computerprogramm erfolgt. Solche Computerprogramme werden im Folgenden auch als Klassifikatoren bezeichnet. In diesem Beitrag geht es um ein System zur automatischen Indexierung von deutschsprachigen Dokumenten im Bereich Bauwesen mit Deskriptoren aus der Schlagwortliste IRB.
</div>
<div style="position:relative">						
	<div id="bib_6e2395f2c115e04d81fc845f02431291lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Verlagsschlagwörter als Grundlage für den Einsatz eines maschinellen Verfahrens zur verbalen Erschließung der Kinder- und Jugendliteratur durch die Deutsche Nationalbibliothek</b>.
<br/>
PhD thesis, HTWK Leipzig, Leipzig, 2019.

<br/>
Pauline Marleen Pollmeier.
<br/>
<a href="https://htwk-leipzig.qucosa.de/api/qucosa%3A73978/attachment/ATT-0/">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '5ddbf1b634ae57c7e64f30d8fd31452a'); return false;" href="https://www.bibsonomy.org/bibtex/25ddbf1b634ae57c7e64f30d8fd31452a/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '5ddbf1b634ae57c7e64f30d8fd31452a', 'https://www.bibsonomy.org/bibtex/25ddbf1b634ae57c7e64f30d8fd31452a/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/25ddbf1b634ae57c7e64f30d8fd31452a/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_5ddbf1b634ae57c7e64f30d8fd31452alepsky" style="display:none;border:1px dotted grey;">
Die Inhaltserschließung durch Schlagwörter wird aktuell in vielen Öffentlichen Bibliotheken Deutschlands zurückgefahren. Aufgrund von Personalmangel und den vielfältigen anderen bibliothekarischen Dienstleistungen, die für die Benutzer zu leisten sind, kommt sie oft zu kurz. Die Deutsche Nationalbibliothek unterstützte diese Bibliotheken bisher als wichtigster Datenlieferant, jedoch stellte sie 2017 die intellektuelle Inhaltserschließung der Kinder- und Jugendliteratur und der Belletristik ein. Um diese problematische Situation zu verbessern, wird aktuell in der Deutschen Nationalbibliothek ein Verfahren erprobt, das aus Schlagwörtern von Verlagen maschinell bibliothekarische Schlagwörter aus der Gemeinsamen Normdatei generiert. Auf die Titel der Kinder- und Jugendliteratur aus den Jahren 2018 und 2019 wurde es bereits angewendet. In dieser Arbeit geht es um eine erste Analyse dieser Erschließungsergebnisse, um Aussagen über die Nützlichkeit der Verlagsschlagwörter und des automatischen Verfahrens zu treffen. Im theoretischen Teil werden einerseits die Inhaltserschließung im bibliothekarischen Bereich und deren aktuelle Entwicklungen hinsichtlich der Automatisierung beschrieben. Andererseits wird näher auf die Erschließungspraxis in der Deutschen Nationalbibliothek hinsichtlich der Automatisierung und der Kinder- und Jugendliteratur eingegangen. Im Analyseteil werden sowohl die Verlagsschlagwörter als auch die bibliothekarischen Schlagwörter nach festgelegten Kriterien untersucht und schließlich miteinander verglichen.
</div>
<div style="position:relative">						
	<div id="bib_5ddbf1b634ae57c7e64f30d8fd31452alepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automated subject indexing of domain specific collections using word embeddings and general purpose thesauri</b>. <br/>
In: E. Garoufallou, F. Fallucchi and E. William De Luca, editors, <i>Metadata and Semantic Research</i>, series Communications in Computer and Information Science, pages 103-114.
Springer International Publishing, Cham, 2019.

<br/>
Michalis Sfakakis, Leonidas Papachristopoulos, Kyriaki Zoutsou, Giannis Tsakonas and Christos Papatheodorou.
<br/>


<a onclick="toggleAbstract('lepsky', '993cbf8d93c937287dbf8a534a79fdcd'); return false;" href="https://www.bibsonomy.org/bibtex/2993cbf8d93c937287dbf8a534a79fdcd/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '993cbf8d93c937287dbf8a534a79fdcd', 'https://www.bibsonomy.org/bibtex/2993cbf8d93c937287dbf8a534a79fdcd/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2993cbf8d93c937287dbf8a534a79fdcd/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_993cbf8d93c937287dbf8a534a79fdcdlepsky" style="display:none;border:1px dotted grey;">
In the era of enormous information production human capabilities have reached their limits. The need for automatic information processing which would not be incommensurate to human sophistication seems to be more than imperative. Information scientists have focused on the development of techniques and processes that would assist human contribution while improve, or at least guarantee, information quality. Automatic indexing techniques may lay on various approaches offering different results in information retrieval. In this paper we introduce an automated methodology for subject analysis, including both the determination of the aboutness of the documents and the translation of the related concepts to the terms of a knowledge organization system. Focusing on a corpus consisting of articles related to the Digital Library Evaluation domain, topic modeling algorithms are utilized for the aboutness of the documents, while the context of the words in topics, as captured by Word Embeddings, are used for the assignment of the extracted topics to the concepts of the EuroVoc thesaurus.
</div>
<div style="position:relative">						
	<div id="bib_993cbf8d93c937287dbf8a534a79fdcdlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Text Mining and Subject Analysis for Fiction; or, Using Machine Learning and Information Extraction to Assign Subject Headings to Dime Novels</b>. <br/>
<i>Cataloging &amp; Classification Quarterly</i>, 57(5):315-336, 2019.
Citation Key Alias: shorttext2019
<br/>
Matthew Short.
<br/>
<a href="https://doi.org/10.1080/01639374.2019.1653413">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'd368f6a19e4f975b1adb12e887f9ff6f'); return false;" href="https://www.bibsonomy.org/bibtex/2d368f6a19e4f975b1adb12e887f9ff6f/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'd368f6a19e4f975b1adb12e887f9ff6f', 'https://www.bibsonomy.org/bibtex/2d368f6a19e4f975b1adb12e887f9ff6f/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2d368f6a19e4f975b1adb12e887f9ff6f/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_d368f6a19e4f975b1adb12e887f9ff6flepsky" style="display:none;border:1px dotted grey;">
This article describes multiple experiments in text mining at Northern Illinois University that were undertaken to improve the efficiency and accuracy of cataloging. It focuses narrowly on subject analysis of dime novels, a format of inexpensive fiction that was popular in the United States between 1860 and 1915. NIU holds more than 55,000 dime novels in its collections, which it is in the process of comprehensively digitizing. Classification, keyword extraction, named-entity recognition, clustering, and topic modeling are discussed as means of assigning subject headings to improve their discoverability by researchers and to increase the productivity of digitization workflows.
</div>
<div style="position:relative">						
	<div id="bib_d368f6a19e4f975b1adb12e887f9ff6flepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2018" class="bibsonomy_quicknav_group"><a name="2018">2018</a></h3>
<div style="margin-bottom:1em">
<b>Bilderschließung gemäß Resource Description and Access (RDA)</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Christian Aliverti.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3661">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'f0ef2935416acbf5080e4922f593e4af'); return false;" href="https://www.bibsonomy.org/bibtex/2f0ef2935416acbf5080e4922f593e4af/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'f0ef2935416acbf5080e4922f593e4af', 'https://www.bibsonomy.org/bibtex/2f0ef2935416acbf5080e4922f593e4af/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2f0ef2935416acbf5080e4922f593e4af/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_f0ef2935416acbf5080e4922f593e4aflepsky" style="display:none;border:1px dotted grey;">
Die AG Bild erarbeitet ein RDA-Anwendungsprofil zur Erschließung von Bildern. Das Regelwerk RDA ist international und im deutschsprachigen Raum zum wichtigsten Erschließungsstandard in Bibliotheken geworden. Da RDA die Erschließung von Bildern nur rudimentär regelt, wird zur Katalogisierung von Bildern und Bildsammlungen ein Anwendungsprofil mit detaillierten Bestimmungen benötigt. Schwerpunkte der Arbeit der AG Bild sind: Definition des Werks beim Bild unter Beachtung des Referenzmodells IFLA LRM, Erarbeitung eines Standardelementesets für Bilder, "Sacherschließung" beim Bild und die Verwendung von Normdaten (GND). Zielgruppe des Anwendungsprofils sind Bibliotheken, Museen, Archive und weitere Institutionen, welche Bilder katalogisieren. In der AG arbeiten im Auftrag des Standardisierungsausschuss ca. 30 Spezialisten und Spezialistinnen aus den Bereichen Bibliothek, Archiv, Museum und Dokumentationsstellen aus Deutschland, Österreich und der Schweiz zusammen. Im Vortrag werden die Arbeitsresultate zu den obengenannten Bereichen gezeigt. Skizziert wird wie die Bilderschließung gemäß RDA aussehen könnte. Auch wird kurz die Organisation der AG Bild vorgestellt.
</div>
<div style="position:relative">						
	<div id="bib_f0ef2935416acbf5080e4922f593e4aflepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Alles unter eine Haube : die nächste Generation des Digitalen Assistenten DA-3</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Regine Beckmann and Imma Hinrichs.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3635">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'ee5e71727fe372333b7e0dfc5798f74c'); return false;" href="https://www.bibsonomy.org/bibtex/2ee5e71727fe372333b7e0dfc5798f74c/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'ee5e71727fe372333b7e0dfc5798f74c', 'https://www.bibsonomy.org/bibtex/2ee5e71727fe372333b7e0dfc5798f74c/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2ee5e71727fe372333b7e0dfc5798f74c/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_ee5e71727fe372333b7e0dfc5798f74clepsky" style="display:none;border:1px dotted grey;">
Auf dem LIS Workshop 2016 in Leipzig wurde der Fachcommunity ein webbasiertes Vorschlagssystem zur halbautomatischen Unterstützung der intellektuellen Sacherschließung, der "Digitale Assistent Version 2 (DA-2)" vorgestellt. Die Präsentation wurde eingebettet in die alte, kontrovers und bis heute nicht abschließend diskutierte Frage, wie sich die Inhaltserschließung in Zukunft entwickele: "Evolutionär, disruptiv oder terminativ?" Eine mögliche Antwort auf diese Frage hat die DNB im September 2017 mit ihrem neuen Konzept zur Inhaltserschließung gegeben. Mit einem anderen Ansatz war der DA-2 an den Start gegangen. Inzwischen ist er in einigen Bibliotheken des SWB erfolgreich im Einsatz und in der Staatsbibliothek zu Berlin für die Nutzung im GBV erprobt worden. Aus den sehr positiven Erfahrungen beider Verbünde entstand die Initiative, das Tool als gemeinsames Projekt mit der Firma Eurospider zur Verbesserung des inhaltlichen Zugangs in K10+, der Verbunddatenbank von BSZ und GBV, weiterzuentwickeln. Im Vortrag werden die Anforderungen beider Verbünde und die geplanten Entwicklungsziele der nächsten Generation, des Digitalen Assistenten Version 3 (DA-3) vorgestellt. Es wird diskutiert, worin die Vorteile gegenüber den in vielen Fällen noch nicht überzeugenden Ergebnissen aus der maschinellen Erschließung liegen.
</div>
<div style="position:relative">						
	<div id="bib_ee5e71727fe372333b7e0dfc5798f74clepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Indexierung von deutschsprachigen bibliographischen Metadaten im Bereich Bauwesen</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Dimitri Busch.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3620">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '07bc3c548a0fae9391c3107080c65c4e'); return false;" href="https://www.bibsonomy.org/bibtex/207bc3c548a0fae9391c3107080c65c4e/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '07bc3c548a0fae9391c3107080c65c4e', 'https://www.bibsonomy.org/bibtex/207bc3c548a0fae9391c3107080c65c4e/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/207bc3c548a0fae9391c3107080c65c4e/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_07bc3c548a0fae9391c3107080c65c4elepsky" style="display:none;border:1px dotted grey;">
In dem Beitrag handelt es sich um automatische und halbautomatische (computerunterstützte) Indexierung von deutschsprachigen Dokumenten (Metadaten-Einträgen) im Bereich Planen und Bauen, die in bibliographischen Datenbanken des Fraunhofer Informationszentrums Raum und Bau (IRB) enthalten sind. Zu den Dokumenten werden Deskriptoren von einer Nomenklatur (Schlagwortliste IRB) und Notationen von einem Klassifikationssystem (Fachgliederung IRB) zugeordnet. Momentan wird die Indexierung intellektuell durchgeführt. Die Intellektuelle Indexierung ist zeitaufwendig und teuer. Um die Probleme zu lösen, wurde ein System für automatische Indexierung entwickelt. Die automatische Indexierung mit Deskriptoren erfolgt nach einem linearen profilbasierten Verfahren. Die Indexierung mit Notationen erfolgt nach einem instanzbasierten Verfahren. Um die Indexierung von deutschsprachigen Dokumenten zu ermöglichen, wurde eine Weiterentwicklung der Programme durchgeführt, die das Fraunhofer IRB für die Indexierung von englischsprachigen Dokumenten verwendet. Die Änderungen betreffen u.a. den Algorithmus für die Profil-Erzeugung. Darüber hinaus werden eine deutschsprachige Lemmatisierung, Erkennung von Komposita und Mehrwortbegriffen durchgeführt. Der vorgestellte Einsatz eignet sich insbesondere für halbautomatische Indexierung, bei der ein menschlicher Indexierer eine endgültige Entscheidung über die Zuordnung von Deskriptoren und Notationen trifft.
</div>
<div style="position:relative">						
	<div id="bib_07bc3c548a0fae9391c3107080c65c4elepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>DDC-Kurznotationen : der Weg zu einer maschinellen klassifikatorischen Erschließung</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Frank Busse.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3637">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '37a3ee2fa35bac38155c1ace362f70cd'); return false;" href="https://www.bibsonomy.org/bibtex/237a3ee2fa35bac38155c1ace362f70cd/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '37a3ee2fa35bac38155c1ace362f70cd', 'https://www.bibsonomy.org/bibtex/237a3ee2fa35bac38155c1ace362f70cd/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/237a3ee2fa35bac38155c1ace362f70cd/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_37a3ee2fa35bac38155c1ace362f70cdlepsky" style="display:none;border:1px dotted grey;">
Seit 2006 betreibt die Deutsche Nationalbibliothek eine "Erschließung auf zwei Beinen" - verbale und klassifikatorische Inhaltserschließung. Im Zuge der Einführung maschineller Verfahren für die verbale Erschließung wird auch an der maschinellen Vergabe von DDC-Notationen gearbeitet. Da die vollständigen DDC-Notationen bei maschinellen Prozessen Schwierigkeiten bereiten, sollen sie durch DDC-Kurznotationen ersetzt werden.Erste Erfahrungen wurden im Fachgebiet Medizin gesammelt. Seit 2005 werden medizinische Dissertationen nach einem Schema von 140 DDC-Kurznotationen klassifiziert. Seit 2015 werden diese Kurznotationen auch schon maschinell vergeben. Das eingesetzte Verfahren ist ein Lernverfahren, das in der DNB seit 2012 für die maschinelle Sachgruppenvergabe erfolgreich eingesetzt wird. Zurzeit werden Klassifikationsschemata für DDC-Kurznotationen für alle übrigen Fächer erarbeitet. Die maschinelle Vergabe der Kurznotationen soll nach Möglichkeit auf alle Fachgebiete ausgeweitet werden. Wie dieses maschinelle Verfahren im Einzelnen arbeitet und welche Herausforderungen die Entwicklung der Kurznotationen und die maschinelle Vergabe in den strukturell unterschiedlichen Wissenschaftsgebieten mit sich bringen ist Teil des Vortrag S. Darüber hinaus wird auf die Fragen der zukünftigen Kennzeichnung maschinell vergebener Notationen, die Datenauslieferung und das Qualitätsmanagement eingegangen.
</div>
<div style="position:relative">						
	<div id="bib_37a3ee2fa35bac38155c1ace362f70cdlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Anforderungen an die Qualität der Inhaltserschließung im Spannungsfeld von intellektuell und automatisch erzeugten Metadaten</b>. <br/>
<i>ABI Technik</i>, 38(4):327-331, 2018.

<br/>
Michael Franke-Maier.
<br/>
<a href="https://www.degruyter.com/view/j/abit.2018.38.issue-4/abitech-2018-4005/abitech-2018-4005.xml">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'c3869c292f53197d23598c7cd862ef6e'); return false;" href="https://www.bibsonomy.org/bibtex/2c3869c292f53197d23598c7cd862ef6e/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'c3869c292f53197d23598c7cd862ef6e', 'https://www.bibsonomy.org/bibtex/2c3869c292f53197d23598c7cd862ef6e/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2c3869c292f53197d23598c7cd862ef6e/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_c3869c292f53197d23598c7cd862ef6elepsky" style="display:none;border:1px dotted grey;">
Spätestens seit dem Deutschen Bibliothekartag 2018 hat sich die Diskussion zu den automatischen Verfahren der Inhaltserschließung der Deutschen Nationalbibliothek von einer politisch geführten Diskussion in eine Qualitätsdiskussion verwandelt. Der folgende Beitrag beschäftigt sich mit Fragen der Qualität von Inhaltserschließung in digitalen Zeiten, wo heterogene Erzeugnisse unterschiedlicher Verfahren aufeinandertreffen und versucht, wichtige Anforderungen an Qualität zu definieren.
</div>
<div style="position:relative">						
	<div id="bib_c3869c292f53197d23598c7cd862ef6elepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatisierte Sacherschließung : Vergabe von Notationen der Regensburger Verbundklassifikation (RVK)</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Konstantin Hermann.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3636">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '65827a6005b8a49c4701848b4837f241'); return false;" href="https://www.bibsonomy.org/bibtex/265827a6005b8a49c4701848b4837f241/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '65827a6005b8a49c4701848b4837f241', 'https://www.bibsonomy.org/bibtex/265827a6005b8a49c4701848b4837f241/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/265827a6005b8a49c4701848b4837f241/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_65827a6005b8a49c4701848b4837f241lepsky" style="display:none;border:1px dotted grey;">
In der Präsentation stellt die SLUB Dresden ihre ersten Ergebnisse aus dem Pilotprojekt zur (semi)automatisierten Sacherschließung nach RVK mittels Verfahren der künstlichen Intelligenz vor. Die SLUB setzt damit den eingeschlagenen Weg der Automatisierung weiter fort, den sie bereits mit dem Dresdner Erwerbungsmodell begonnen hat. Ziel der automatisierten Sacherschließung ist neben der Gewinnung von Personalkapazitäten auch die Erweiterung der RVK-Vergabe auf Medien, die bisher nicht sachlich erschlossen wurden, besonders elektronische Ressourcen. Der anhaltende Trend im Angebot und der kundenseitigen Nachfrage nach digitalen Medien stellt Bibliotheken vor die Herausforderungen, ihre redaktionellen Prozesse an den aktuellen Stand der Technik anzupassen. Interne Studien haben gezeigt, dass jede intellektuelle Notationsvergabe durchschnittlich sechs Minuten in Anspruch nimmt. Bei 40.000 neu erworbenen Monographien pro Jahr kann dieser Prozessschritt zu zeitlichen Engpässen innerhalb der Erwerbung führen. Ziel des Pilotprojektes ist die Reduktion der Erschließungsdauer um 80 Prozent, d.h. auf eine Minute pro Notationsvergabe. Dies kann durch einen webbasierten Assistenten gelingen, der die Titeldaten analysiert und aus den ca. 800.000 möglichen Kategorien der RVK die fünf relevantesten dem Bibliothekar vorschlägt. Die intellektuelle Auswahl eines Vorschlags durch den Bibliothekar verbesserte gleichzeitig das Ergebnis von zukünftigen automatisierten Vorschlägen. Der Erschließungsassistent ist als selbstlernendes System konzeptioniert, wodurch sich die Vorschläge schrittweise an das Feedback des Bibliothekars anpassen sollen. Ein digitaler Assistent, der den bibliothekarischen Wissensarbeiter bei der Flut seiner Arbeit immer stärker unter die Arme greift. Die SLUB Dresden wird in ihrem Projekt von der Dresdner IT-Firma Avantgarde Labs GmbH unterstützt. SLUB: Dr. Konstantin Hermann Avantgarde Labs: Herr Torsten Hartmann
</div>
<div style="position:relative">						
	<div id="bib_65827a6005b8a49c4701848b4837f241lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>The influence of the order of adding documents to datasets on terminological saturation</b>.<br/>
2018. 
<br/>Victoria Kosa, David Chaves-Fraga, Dmitriy Naumenko, Eugene Yuschenko, Carlos Badenes-Olmedo, Vadim Ermolayev and Aliaksandr Birukou.
<br/>

<a onclick="toggleAbstract('lepsky', 'ab923f6c21d3a79da2fc50b429fafc60'); return false;" href="https://www.bibsonomy.org/bibtex/2ab923f6c21d3a79da2fc50b429fafc60/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'ab923f6c21d3a79da2fc50b429fafc60', 'https://www.bibsonomy.org/bibtex/2ab923f6c21d3a79da2fc50b429fafc60/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2ab923f6c21d3a79da2fc50b429fafc60/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_ab923f6c21d3a79da2fc50b429fafc60lepsky" style="display:none;border:1px dotted grey;">
fThis document reports the results of our experimental study aimed to find out the impact of different orders of adding documents to datasets for measuring terminological saturation. The motivation for this research activity lies in the fact that real world document collections are retrospective. So, terminological drift in time is often present in such collections. We empirically investigated the proper ways to cope with this temporal drift and its influence on terminological saturation. Our premise was that there could be several different orders of adding documents to the processed datasets, dealing with the time of publication: (i) chronological; (ii) reversed-chronological; (iii) bi-directional; and (iv) random. Experiments were performed using three different real world document collections coming from different domains, where the collections of high-quality documents were available as scientific papers. In the presence of different levels of noise it has also been checked if different orders are differently sensitive in detecting excessive noise. Based on the comparison of experimental results, we recommended that the reversed-chronological order of adding documents to datasets is preferrable as it demonstrated the most balanced performance.
</div>
<div style="position:relative">						
	<div id="bib_ab923f6c21d3a79da2fc50b429fafc60lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Maschinelle Sacherschließungsverfahren bei medizinischen Publikationen : Erfahrungen an der DNB</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Karen Kristina Köhn.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3633">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '7eb3f3a30c626d1c46809bc278b433ff'); return false;" href="https://www.bibsonomy.org/bibtex/27eb3f3a30c626d1c46809bc278b433ff/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '7eb3f3a30c626d1c46809bc278b433ff', 'https://www.bibsonomy.org/bibtex/27eb3f3a30c626d1c46809bc278b433ff/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/27eb3f3a30c626d1c46809bc278b433ff/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_7eb3f3a30c626d1c46809bc278b433fflepsky" style="display:none;border:1px dotted grey;">
Was wird in der DNB wie maschinell erschlossen? Welche Erfahrungen hat die DNB bei der Einführung maschineller Verfahren zur Inhaltserschließung gesammelt? Der Vortrag stellt sich diesen Fragen und gibt am Beispiel der Sachgruppe Medizin einen Einblick aus fachlicher Sicht in die von der DNB eingesetzten maschinellen Verfahren zur Inhaltserschließung. Seit April 2017 werden an der Deutschen Nationalbibliothek neben Netzpublikationen nun auch gedruckte Monografien außerhalb des Verlagsbuchhandels (Reihen B) und gedruckte Hochschulschriften (Reihe H) auf der Basis von Titelaufnahme und gescanntem Inhaltsverzeichnis klassifikatorisch und verbal mit maschinellen Verfahren erschlossen. Konkret erhalten alle Monografien maschinell eine DDC-Sachgruppe; eine maschinelle Beschlagwortung mit GND-Schlagwörtern erfolgt bei allen deutschsprachigen Publikationen und im Bereich der medizinischen Literatur erfolgt zusätzlich eine maschinelle Klassifikation mit DDC-Kurznotationen.
</div>
<div style="position:relative">						
	<div id="bib_7eb3f3a30c626d1c46809bc278b433fflepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Bewertung maschineller Indexierung : "Qualität ist kein Zufall!"</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Tobias Rebholz, Elisabeth Mödden, Helga Karg and Andreas Oskar Kempf.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3316">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'b15b5d27d8cab4cc3c300284c2afe4fb'); return false;" href="https://www.bibsonomy.org/bibtex/2b15b5d27d8cab4cc3c300284c2afe4fb/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'b15b5d27d8cab4cc3c300284c2afe4fb', 'https://www.bibsonomy.org/bibtex/2b15b5d27d8cab4cc3c300284c2afe4fb/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2b15b5d27d8cab4cc3c300284c2afe4fb/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_b15b5d27d8cab4cc3c300284c2afe4fblepsky" style="display:none;border:1px dotted grey;">
Die Qualität der maschinellen Sacherschließung ist das zentrale Thema, wenn es um eine Automatisierung der Inhaltserschließung geht. Einerseits werden die Ergebnisse der maschinellen Erschließung durch verfahrenstechnische Weiterentwicklungen laufend verbessert, andererseits sind die Qualitätsverbesserungen nicht konstanter Art und nicht auf alle Fachdomänen übertragbar. Demzufolge wird zum jetzigen Zeitpunkt eine computergestützte Inhaltserschließung von vielen Akteuren als "goldener Weg" gesehen. Jedoch muss angesichts des stetig wachsenden Publikationsoutputs konstatiert werden, dass eine reine Fokussierung auf unterstützende Computererschließung allein die schon bestehenden Erschließungslücken in Zukunft weiter anwachsen lassen wird. Infolgedessen haben sich sowohl die Deutsche Nationalbibliothek als auch die ZBW - Leibniz-Informationszentrum Wirtschaft mit Blick auf ihre umfangreichen Sammlungen dazu entschieden, bereits zum jetzigen Zeitpunkt neben einer intellektuellen Indexierung vollautomatische Verfahren einzusetzen. Im Rahmen eines Hands-on Labs geben beide Institutionen einen tieferen Einblick in das Qualitätsmanagement der maschinellen Indexierung. Teilnehmerinnen und Teilnehmer sind dazu eingeladen, im ersten Teil der Veranstaltung gemeinsam mit den Fachexpertinnen und -experten der Einrichtungen die Qualität der aktuellen Indexierungsverfahren in webbasierten Tools zu bewerten. Darüber hinaus werden anhand von Beispielen die Arbeitsweisen der Verfahren näher betrachtet sowie Vor- und Nachteile aufgezeigt. Im zweiten Teil der Veranstaltung werden wir im Rahmen eines World Cafes allen Teilnehmerinnen und Teilnehmern die Gelegenheit zum direkten fachlichen Erfahrungsaustausch bieten und die in der Bewertungssession aufgeworfenen zentralen Fragen hinsichtlich der Qualität vollautomatischer Verfahren diskutieren. Abgerundet wird die Veranstaltung mit einer gemeinsamen Vorstellung der Ergebnisse des World Cafes und einer Zusammenfassung der Key-Learning S.
</div>
<div style="position:relative">						
	<div id="bib_b15b5d27d8cab4cc3c300284c2afe4fblepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Clustering von Ergebnissen einer automatischen Verschlagwortung</b>.
<br/>
PhD thesis, LMU München; Fakultät für Sprach- und Kulturwissenschaften, München, 2018.

<br/>
Julius Steidl.
<br/>
<a href="http://www.topiczoom.de/wp-content/uploads/2018/12/BA_Julius_Steidl.pdf">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '495bc98a0cf5ca95e2175de1f93e608e'); return false;" href="https://www.bibsonomy.org/bibtex/2495bc98a0cf5ca95e2175de1f93e608e/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '495bc98a0cf5ca95e2175de1f93e608e', 'https://www.bibsonomy.org/bibtex/2495bc98a0cf5ca95e2175de1f93e608e/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2495bc98a0cf5ca95e2175de1f93e608e/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_495bc98a0cf5ca95e2175de1f93e608elepsky" style="display:none;border:1px dotted grey;">
In dieser Arbeit wird ein neuartiger Ansatz zur Clusteranalyse von Dokumenten vorgestellt,  bei  dem  die  Ergebnisse  einer  automatischen  Verschlagwortung  dieser  Dokumente zur Analyse genutzt werden. Für die automatische Verschlagwortung wurde der Dientst ”TopicZoom Webtags“ genutzt, der zu den erzeugten Schlagwörtern auch Werte über ihre Gewichtung und Angaben zu ihreren Eingeschaften liefert. Zur Umsetzung und Evalution dieses  Ansatzes  wurde  ein  Programm  entwickelt,  dass  diese  unterschiedlichen ”Feature-Werte“  nutzt  und  verschiedene  Cluster-Algorithmen  darauf  anwendet.  Damit  fungiert eine  solche  Verschlagwortung  auch  als  ein  neuer  Ansatz  zur ”Feature-Extraction“,  die zur  Durchführung  eines  Clusterings  nötig  ist.  Durch  die  Einschränkung  auf  bestimmte Schlagwörter anhand ihrer Feature-Werte, sowie der Nutzung ihrer Gewichtungs-Werte, wurden unterschiedliche Ergebnisse bei der Cluster-Analyse erzeugt und evaluiert um die beste Kombination für Nutzung zum Clustering zu ermitteln. Außerdem wurden verschiedene  Clustering-Algorithmen  dafür  angewandt  und  ihre  Ergebnisse  ebenfalls  evaluiert. Schließlich wurde dieser Ansatz zur Nutzung der Verschlagwortung zur Feature-Extrationmit dem gängigen Verfahren der Gewichtung durch Tf-idf verglichen.
</div>
<div style="position:relative">						
	<div id="bib_495bc98a0cf5ca95e2175de1f93e608elepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Fusion architectures for automatic subject indexing under concept drift</b>. <br/>
<i>International Journal on Digital Libraries</i>:1-21, 2018.

<br/>
Martin Toepfer and Christin Seifert.
<br/>
<a href="https://link.springer.com/article/10.1007/s00799-018-0240-3">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '077a6aecfb835f84428ad2696dbc45ed'); return false;" href="https://www.bibsonomy.org/bibtex/2077a6aecfb835f84428ad2696dbc45ed/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '077a6aecfb835f84428ad2696dbc45ed', 'https://www.bibsonomy.org/bibtex/2077a6aecfb835f84428ad2696dbc45ed/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2077a6aecfb835f84428ad2696dbc45ed/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_077a6aecfb835f84428ad2696dbc45edlepsky" style="display:none;border:1px dotted grey;">
Indexing documents with controlled vocabularies enables a wealth of semantic applications for digital libraries. Due to the rapid growth of scientific publications, machine learning-based methods are required that assign subject descriptors automatically. While stability of generative processes behind the underlying data is often assumed tacitly, it is being violated in practice. Addressing this problem, this article studies explicit and implicit concept drift, that is, settings with new descriptor terms and new types of documents, respectively. First, the existence of concept drift in automatic subject indexing is discussed in detail and demonstrated by example. Subsequently, architectures for automatic indexing are analyzed in this regard, highlighting individual strengths and weaknesses. The results of the theoretical analysis justify research on fusion of different indexing approaches with special consideration on information sharing among descriptors. Experimental results on titles and author keywords in the domain of economics underline the relevance of the fusion methodology, especially under concept drift. Fusion approaches outperformed non-fusion strategies on the tested data sets, which comprised shifts in priors of descriptors as well as covariates. These findings can help researchers and practitioners in digital libraries to choose appropriate methods for automatic subject indexing, as is finally shown by a recent case study.
</div>
<div style="position:relative">						
	<div id="bib_077a6aecfb835f84428ad2696dbc45edlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Maschinelle Indexierung am Beispiel der DNB</b>. <br/>
<i>o-bib. Das offene Bibliotheksjournal / Herausgeber VDB</i>, 5(4):141-153, 2018.

<br/>
Heidrun Wiesenmüller.
<br/>
<a href="https://www.o-bib.de/article/view/5396">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'b29ab563e9ac8eb87d7112f0a4879a7b'); return false;" href="https://www.bibsonomy.org/bibtex/2b29ab563e9ac8eb87d7112f0a4879a7b/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'b29ab563e9ac8eb87d7112f0a4879a7b', 'https://www.bibsonomy.org/bibtex/2b29ab563e9ac8eb87d7112f0a4879a7b/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2b29ab563e9ac8eb87d7112f0a4879a7b/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_b29ab563e9ac8eb87d7112f0a4879a7blepsky" style="display:none;border:1px dotted grey;">
Der Beitrag untersucht die Ergebnisse des bei der Deutschen Nationalbibliothek (DNB) eingesetzten Verfahrens zur automatischen Vergabe von Schlagwörtern. Seit 2017 kommt dieses auch bei Printausgaben der Reihen B und H der Deutschen Nationalbibliografie zum Einsatz. Die zentralen Problembereiche werden dargestellt und an Beispielen illustriert – beispielsweise dass nicht alle im Inhaltsverzeichnis vorkommenden Wörter tatsächlich thematische Aspekte ausdrücken und dass die Software sehr häufig Körperschaften und andere „Named entities“ nicht erkennt. Die maschinell generierten Ergebnisse sind derzeit sehr unbefriedigend. Es werden Überlegungen für mögliche Verbesserungen und sinnvolle Strategien angestellt.
</div>
<div style="position:relative">						
	<div id="bib_b29ab563e9ac8eb87d7112f0a4879a7blepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Maschinelle Indexierung am Beispiel der DNB : Analyse und Entwicklungsmöglichkeiten</b>. <br/>
<i>107. Deutscher Bibliothekartag in Berlin 2018</i>, 2018.

<br/>
Heidrun Wiesenmüller.
<br/>
<a href="https://opus4.kobv.de/opus4-bib-info/frontdoor/index/index/docId/3634">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '70f8db350f6cf0068dbddc0792158acc'); return false;" href="https://www.bibsonomy.org/bibtex/270f8db350f6cf0068dbddc0792158acc/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '70f8db350f6cf0068dbddc0792158acc', 'https://www.bibsonomy.org/bibtex/270f8db350f6cf0068dbddc0792158acc/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/270f8db350f6cf0068dbddc0792158acc/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_70f8db350f6cf0068dbddc0792158acclepsky" style="display:none;border:1px dotted grey;">
Die Deutsche Nationalbibliothek (DNB) plant, die Sacherschließung in den nächsten Jahren weitestgehend auf automatische Methoden umzustellen. Ein bei Netzpublikationen schon länger angewendetes Verfahren zur automatischen Vergabe von Schlagwörtern kommt seit 2017 auch bei Printausgaben der Reihen B und H zum Einsatz. Handelt es sich dabei um einen zukunftsweisenden Weg oder um eine Sackgasse? Im Vortrag werden konkrete Beispiele aus der Produktion der DNB analysiert und auf ihre Qualität geprüft. Es werden typische Fehlerquellen erläutert, u.a. die falsche Einordnung von Autoren oder Herausgebern als Themen oder die bisher mangelhafte Named-entity recognition. Letztere führt dazu, dass die Software wichtige Konzepte nicht erkennt (z.B. Körperschaften als Themen) oder falsche Themen extrahiert (z.B. "Santiago de Chile" aus "Santiago-de-Chile-Platz"). Aus der Untersuchung ergibt sich auch ein frischer Blick auf den Vorgang der Inhaltsanalyse: Diese besteht nicht in einer bloßen "Übersetzung" von Wörtern aus Titel und Inhaltsverzeichnis in Schlagwörter, sondern umfasst komplexe Prozesse des Verstehens und Interpretierens von Sprache. So sind viele Formulierungen überhaupt nicht dazu gedacht, ein Thema zu benennen. Die Kapitelüberschrift "Geschichte in Jahreszahlen" sollte folglich nicht zum Schlagwort "Jahreszahl" führen oder die Gliederung eines Museumsführers nach Stockwerken nicht zum Schlagwort "Geschoss (Bauwesen)". Im Vortrag wird auch erörtert, welche alternativen oder zusätzlichen Verfahren zu Verbesserungen führen könnten. Hilfreich wäre beispielsweise ein Werk-Clustering zur Übernahme bereits vorhandener intellektueller Sacherschließungsdaten, eine vorgeschaltete Layoutanalyse der Inhaltsverzeichnisse sowie der Einbezug von Informationen, die in der Formalerschließung erfasst werden.
</div>
<div style="position:relative">						
	<div id="bib_70f8db350f6cf0068dbddc0792158acclepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2017" class="bibsonomy_quicknav_group"><a name="2017">2017</a></h3>
<div style="margin-bottom:1em">
<b>Automatic identification of synonym relations in the Dutch Parliament’s Thesaurus</b>. <br/>
<i>Archives of Data Science, Series A (Online First)</i>, 2(1), 2017.

<br/>
Rosa Tsegaye Aga, Christian Wartena, Otto Lange and Nelleke Aders.
<br/>
<a href="https://publikationen.bibliothek.kit.edu/1000073425">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '310a1557b611f5ac04ffec9c851ed687', 'https://www.bibsonomy.org/bibtex/2310a1557b611f5ac04ffec9c851ed687/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2310a1557b611f5ac04ffec9c851ed687/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_310a1557b611f5ac04ffec9c851ed687lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_310a1557b611f5ac04ffec9c851ed687lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Deutsche Nationalbibliothek : in Frankfurt lesen jetzt zuerst Maschinen</b>. <br/>
<i>Frankfurter Allgemeine Zeitung</i>, 2017.

<br/>
Klaus Ceynowa.
<br/>
<a href="http://www.faz.net/aktuell/feuilleton/buecher/maschinen-lesen-buecher-deutsche-nationalbibliothek-setzt-auf-technik-15128954.html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'e81e98da3ff070d2ab20de9c5f976007'); return false;" href="https://www.bibsonomy.org/bibtex/2e81e98da3ff070d2ab20de9c5f976007/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'e81e98da3ff070d2ab20de9c5f976007', 'https://www.bibsonomy.org/bibtex/2e81e98da3ff070d2ab20de9c5f976007/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e81e98da3ff070d2ab20de9c5f976007/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e81e98da3ff070d2ab20de9c5f976007lepsky" style="display:none;border:1px dotted grey;">
Die Deutsche Nationalbibliothek sammelt alle deutschen Bücher – und erschließt sie mit Schlagworten. Diese Arbeit sollen künftig keine Menschen mehr verrichten. So macht die Digitalisierung Wissen unzugänglich.
</div>
<div style="position:relative">						
	<div id="bib_e81e98da3ff070d2ab20de9c5f976007lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>SISA : automatic indexing system for scientific articles : experiments with location heuristics rules versus TF-IDF rules</b>. <br/>
<i>Knowledge Organization</i>, 44(3):139-162, 2017.

<br/>
Isidoro Gil-Leiva.
<br/>

<a onclick="toggleAbstract('lepsky', '7f6cc2fba4bfabaead8ceb4465b0679f'); return false;" href="https://www.bibsonomy.org/bibtex/27f6cc2fba4bfabaead8ceb4465b0679f/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '7f6cc2fba4bfabaead8ceb4465b0679f', 'https://www.bibsonomy.org/bibtex/27f6cc2fba4bfabaead8ceb4465b0679f/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/27f6cc2fba4bfabaead8ceb4465b0679f/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_7f6cc2fba4bfabaead8ceb4465b0679flepsky" style="display:none;border:1px dotted grey;">
Indexing is contextualized and a brief description is provided of some of the most used automatic indexing systems. We describe SISA, a system which uses location heuristics rules, statistical rules like term frequency (TF) or TF-IDF to obtain automatic or semi-automatic indexing, depending on the user's preference. The aim of this research is to ascertain which rules (location heuristics rules or TF-IDF rules) provide the best indexing terms. SISA is used to obtain the automatic indexing of 200 scientific articles on fruit growing written in Portuguese. It uses, on the one hand, location heuristics rules founded on the value of certain parts of the articles for indexing such as titles, abstracts, keywords, headings, first paragraph, conclusions and references and, on the other, TF-IDF rules. The indexing is then evaluated to ascertain retrieval performance through recall, precision and f-measure. Automatic indexing of the articles with location heuristics rules provided the best results with the evaluation measures.
</div>
<div style="position:relative">						
	<div id="bib_7f6cc2fba4bfabaead8ceb4465b0679flepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatic subject indexing of text</b>.<br/>
In: 

.
International Society for Knowledge Organization, 2017.

<br/>
Koraljka Golub.
<br/>

<a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2:1149085">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'b50ba49002ba1fe93fc861b01e1df3c1'); return false;" href="https://www.bibsonomy.org/bibtex/2b50ba49002ba1fe93fc861b01e1df3c1/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'b50ba49002ba1fe93fc861b01e1df3c1', 'https://www.bibsonomy.org/bibtex/2b50ba49002ba1fe93fc861b01e1df3c1/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2b50ba49002ba1fe93fc861b01e1df3c1/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_b50ba49002ba1fe93fc861b01e1df3c1lepsky" style="display:none;border:1px dotted grey;">
Automatic subject indexing addresses problems of scale and sustainability and can be at the same time used to enrich existing metadata records, establish more connections across and between resourc ...
</div>
<div style="position:relative">						
	<div id="bib_b50ba49002ba1fe93fc861b01e1df3c1lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Mehrwortbegriffe und Latent Semantic Analysis : Bewertung automatisch extrahierter Mehrwortgruppen mit LSA</b>.
<br/>
PhD thesis, Studiengang Informationswissenschaft und Sprachtechnologie; Institut für Sprache und Information; Philosophische Fakultät; Heinrich-Heine-Universität Düsseldorf, Düsseldorf, 2017.

<br/>
Stefan Grün.
<br/>

<a onclick="toggleAbstract('lepsky', '564400a38d552226f1fa16d302ee42e3'); return false;" href="https://www.bibsonomy.org/bibtex/2564400a38d552226f1fa16d302ee42e3/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '564400a38d552226f1fa16d302ee42e3', 'https://www.bibsonomy.org/bibtex/2564400a38d552226f1fa16d302ee42e3/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2564400a38d552226f1fa16d302ee42e3/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_564400a38d552226f1fa16d302ee42e3lepsky" style="display:none;border:1px dotted grey;">
Die vorliegende Studie untersucht das Potenzial von Mehrwortbegriffen für das Information Retrieval. Zielsetzung der Arbeit ist es, intellektuell positiv bewertete Kandidaten mithilfe des Latent Semantic Analysis (LSA) Verfahren höher zu gewichten, als negativ bewertete Kandidaten. Die positiven Kandidaten sollen demnach bei einem Ranking im Information Retrieval bevorzugt werden. Als Kollektion wurde eine Version der sozialwissenschaftlichen GIRT-Datenbank (German Indexing and Retrieval Testdatabase) eingesetzt. Um Kandidaten für Mehrwortbegriffe zu identifizieren wurde die automatische Indexierung Lingo verwendet. Die notwendigen Kernfunktionalitäten waren Lemmatisierung, Identifizierung von Komposita, algorithmische Mehrworterkennung sowie Gewichtung von Indextermen durch das LSA-Modell. Die durch Lingo erkannten und LSA-gewichteten Mehrwortkandidaten wurden evaluiert. Zuerst wurde dazu eine intellektuelle Auswahl von positiven und negativen Mehrwortkandidaten vorgenommen. Im zweiten Schritt der Evaluierung erfolgte die Berechnung der Ausbeute, um den Anteil der positiven Mehrwortkandidaten zu erhalten. Im letzten Schritt der Evaluierung wurde auf der Basis der R-Precision berechnet, wie viele positiv bewerteten Mehrwortkandidaten es an der Stelle k des Rankings geschafft haben. Die Ausbeute der positiven Mehrwortkandidaten lag bei durchschnittlich ca. 39 während die R-Precision einen Durchschnittswert von 54%erzielte. Das LSA-Modell erzielt ein ambivalentes Ergebnis mit positiver Tendenz.
</div>
<div style="position:relative">						
	<div id="bib_564400a38d552226f1fa16d302ee42e3lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Grundzüge und erste Schritte der künftigen inhaltlichen Erschließung von Publikationewn in der Deutschen Nationalbibliothek</b>.<br/>
2017. 
<br/>Volker Henze, Ulrike Junger and Elisabeth Mödden.
<br/>
<a href="http://www.dnb.de/DE/Erwerbung/Inhaltserschliessung/grundzuegeInhaltserschliessungMai2017.html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '60e806692a79cb682d5785c6aebb1838'); return false;" href="https://www.bibsonomy.org/bibtex/260e806692a79cb682d5785c6aebb1838/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '60e806692a79cb682d5785c6aebb1838', 'https://www.bibsonomy.org/bibtex/260e806692a79cb682d5785c6aebb1838/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/260e806692a79cb682d5785c6aebb1838/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_60e806692a79cb682d5785c6aebb1838lepsky" style="display:none;border:1px dotted grey;">
Die parallele Verbreitung von analogen und digitalen Informationen führt zu einer stetig ansteigenden Menge neu erscheinender Publikationen. Die Auswertungsmöglichkeiten digitaler Inhalte, die Kooperationsmöglichkeiten durch das Internet sowie die Entwicklung technischer Verfahren, Inhalte miteinander vernetzen und thematisch in Beziehung setzen zu können, lassen Raum, bibliothekarische Erschließungsverfahren neu zu denken. Erschließung muss dabei nicht mehr als einmaliger abgeschlossener Vorgang, sondern kann als zyklisches Verfahren betrachtet werden, bei dem Erschließungsdaten immer wieder verändert und aktualisiert werden.
</div>
<div style="position:relative">						
	<div id="bib_60e806692a79cb682d5785c6aebb1838lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Die inhaltliche Erschließung des schriftlichen kulturellen Erbes auf dem Weg in die Zukunft : automatische Vergabe von Schlagwörtern in der Deutschen Nationalbibliothek</b>.<br/>
Deutsche Nationalbibliothek, 2017. 
<br/>Ulrike Junger and Ute Schwens.
<br/>
<a href="http://www.dnb.de/SharedDocs/Downloads/DE/DNB/inhaltserschliessung/automatischeInhaltserschliessung.pdf?__blob=publicationFile">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', 'f7aee5a91b13de778bd2425d96b253e9', 'https://www.bibsonomy.org/bibtex/2f7aee5a91b13de778bd2425d96b253e9/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2f7aee5a91b13de778bd2425d96b253e9/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_f7aee5a91b13de778bd2425d96b253e9lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_f7aee5a91b13de778bd2425d96b253e9lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatisches Indexieren des Griechischen : Erstellung eines Prototyps für die Grundformerzeugung mit Lingo</b>.
<br/>
PhD thesis, Technische Hochschule Köln; Fakultät für Informations- und Kommunikationswissenschaft, Köln, 2017.

<br/>
Konstantinos Kamargiannis.
<br/>

<a onclick="toggleAbstract('lepsky', '633c4f946a52a500b8ef78a9e264dd8b'); return false;" href="https://www.bibsonomy.org/bibtex/2633c4f946a52a500b8ef78a9e264dd8b/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '633c4f946a52a500b8ef78a9e264dd8b', 'https://www.bibsonomy.org/bibtex/2633c4f946a52a500b8ef78a9e264dd8b/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2633c4f946a52a500b8ef78a9e264dd8b/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_633c4f946a52a500b8ef78a9e264dd8blepsky" style="display:none;border:1px dotted grey;">
Diese Arbeit befasst sich mit dem automatischen Indexieren der griechischen Sprache mittels dem System Lingo. Das Programm Lingo wird beleuchtet, die für die Arbeit relevanten Funktionen geschildert und beschrieben. Anschließend wird die griechische Sprache betrachtet, Besonderheiten diskutiert und in das System Lingo implementiert. Schritt für Schritt werden die zuvor beleuchteten Funktionen mit griechischen Beispielen angewandt, während die Änderung und die Problematik im Vergleich zur deutschen Sprache hierbei erörtert wird. An- schließend werden griechische Dokumente beispielhaft analysiert und Auszüge hieraus in dieser Arbeit präsentiert. Kern dieser Arbeit ist es, die Lingo System- befehle, inkl. der unter anderem dazu gehörigen Suffixlisten, für die griechische Sprache umzuschreiben. Gleichfalls müssen neben dem Systemwörterbuch, verschiedene Wörterbücher in der griechischen Sprache angelegt werden.
</div>
<div style="position:relative">						
	<div id="bib_633c4f946a52a500b8ef78a9e264dd8blepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Neue Verfahrenswege der Wissensorganisation : eine Evaluation automatischer Indexierung in der sozialwissenschaftlichen Fachinformation</b>.<br/>
In: 

<i>Theorie, Semantik und Organisation von Wissen: Proceedings der 13. Tagung der Deutschen Sektion der Internationalen Gesellschaft für Wissensorganisation (ISKO) und dem 13. Internationalen Symposium der Informationswissenschaft der Higher Education Association for Information Science (HI) Potsdam (19.-20.03.2013): 'Theory, Information and Organization of Knowledge' / Proceedings der 14. Tagung der Deutschen Sektion der Internationalen Gesellschaft für Wissensorganisation (ISKO) und Natural Language &amp; Information Systems (NLDB) Passau (16.06.2015): 'Lexical Resources for Knowledge Organization' / Proceedings des Workshops der Deutschen Sektion der Internationalen Gesellschaft für Wissensorganisation (ISKO) auf der SEMANTICS Leipzig (1.09.2014): 'Knowledge Organization and Semantic Web' / Proceedings des Workshops der Polnischen und Deutschen Sektion der Internationalen Gesellschaft für Wissensorganisation (ISKO) Cottbus (29.-30.09.2011): 'Economics of Knowledge Production and Organization'. Hrsg. von W. Babik, H.P. Ohly u. K. Weber</i>, pages 147-160.
Ergon, Würzburg, 2017.

<br/>
Andreas Oskar Kempf.
<br/>

<a href="https://www.nomos-elibrary.de/10.5771/9783956503269-147/neue-verfahrenswege-der-wissensorganisation-eine-evaluation-automatischer-indexierung-in-der-sozialwissenschaftlichen-fachinformation">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '1f3d9e67d778f9a9579e556d733bc746'); return false;" href="https://www.bibsonomy.org/bibtex/21f3d9e67d778f9a9579e556d733bc746/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '1f3d9e67d778f9a9579e556d733bc746', 'https://www.bibsonomy.org/bibtex/21f3d9e67d778f9a9579e556d733bc746/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/21f3d9e67d778f9a9579e556d733bc746/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_1f3d9e67d778f9a9579e556d733bc746lepsky" style="display:none;border:1px dotted grey;">
Der vorliegende Artikel präsentiert Evaluationsergebnisse eines automatischen Indexierungsverfah-rens  zur  Erschließung  sozialwissenschaftlicher  Forschungsliteratur.  Auf  der  Grundlage  des  sog. Schalenmodells (Krause 1996, 2006) und des darin formulierten Anwendungsszenarios, wonach als weniger  relevant  erachtete  Datensätze  der  Literaturdatenbank  SOLIS  (Sozialwissenschaftliches Literaturinformationssystem)  automatisch erschlossen  werden sollten,  wurde die  Indexierungssoft-ware MindServer der Firma Recommind in zwei Testserien getestet. Wurden in der ersten Testserie die allgemeinen Softwareeinstellungen getestet, wurden in der zweiten Testserie die Indexierungser-gebnisse  zwischen  den  Kern-  und  einem  Randbereich  der  Literaturdatenbank  miteinander  vergli-chen.  Zu  diesem  Zweck  wurden  fachteilgebietsspezifische  Versionen  der  Indexierungssoftware aufgebaut, die ausschließlich anhand von Datensätzen der entsprechenden Fachteilgebiete trainiert wurden.  Die  Ergebnisse  der  Evaluation,  die  auf  Basis  intellektuell  generierter  Vergleichsdaten vorgenommen  wurde,  weisen  auf  Unterschiede  in  der  Indexierungsleistung  zwischen  Rand-  und Kernbereichen  der  Datenbank  hin,  die  einerseits  gegen  die  Implementierung  des  automatischen Indexierungsverfahren  für  die  Erschließung  der  Randbereiche  sprechen.  Andererseits  deutet  sich an,  dass  sich  die  Indexierungsqualität  durch  den  Aufbau  fachteilgebietsspezifischer  Trainingsmen-gen verbessern lässt.
</div>
<div style="position:relative">						
	<div id="bib_1f3d9e67d778f9a9579e556d733bc746lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatisierte Inhaltserschließung in der Deutschen Nationalbibliothek : was Maschinen können und was nicht</b>.<br/>
2017. 
<br/>Michael Roesler-Graichen.
<br/>
<a href="https://www.boersenblatt.net/artikel-automatisierte_inhaltserschliessung_in_der_deutschen_nationalbibliothek.1361205.html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'e9cd33e8b093ac427664a8b478dfe733'); return false;" href="https://www.bibsonomy.org/bibtex/2e9cd33e8b093ac427664a8b478dfe733/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'e9cd33e8b093ac427664a8b478dfe733', 'https://www.bibsonomy.org/bibtex/2e9cd33e8b093ac427664a8b478dfe733/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e9cd33e8b093ac427664a8b478dfe733/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e9cd33e8b093ac427664a8b478dfe733lepsky" style="display:none;border:1px dotted grey;">
Die Deutsche Nationalbibliothek will künftig nicht nur Netzpublikationen, sondern auch gedruckte Bücher mit automatischen Verfahren inhaltlich erschließen. Dagegen werden jetzt Bedenken laut. Worum es dabei geht, und was bei der geplanten Umstellung auf dem Spiel steht, hat boersenblatt.net recherchiert.
</div>
<div style="position:relative">						
	<div id="bib_e9cd33e8b093ac427664a8b478dfe733lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Vollautomatische thematische Verschlagwortung großer Textkollektionen mittels semantischer Netze</b>.<br/>
In: 

<i>Theorie, Semantik und Organisation von Wissen</i>, pages 140-146.
Ergon, Würzburg, 2017.

<br/>
K. U. Schulz and Levin Brunner.
<br/>


<a onclick="toggleAbstract('lepsky', 'c57df67ed0bd9f11ffe6ccd57f7443e3'); return false;" href="https://www.bibsonomy.org/bibtex/2c57df67ed0bd9f11ffe6ccd57f7443e3/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'c57df67ed0bd9f11ffe6ccd57f7443e3', 'https://www.bibsonomy.org/bibtex/2c57df67ed0bd9f11ffe6ccd57f7443e3/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2c57df67ed0bd9f11ffe6ccd57f7443e3/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_c57df67ed0bd9f11ffe6ccd57f7443e3lepsky" style="display:none;border:1px dotted grey;">
In  Bibliotheken,  Verlagen  und  Firmen  trifft  man  oft  auf  extrem  umfangreiche  Kollektionen elektronischer  Textdokumente,  bei  denen  keine  Informationen  oder  Metadaten  zu  den  in  den Dokumenten abgehandelten Inhalten und Themen vorliegen. Zwar kann man mit konventioneller Suchtechnologie  leicht  nach  einzelnen  Begriffen  in  den  Dokumenten  suchen.  Dies  schafft  jedoch keinen Überblick über die Inhalte der Kollektion und keine Einordnung der Dokumente etwa nach dem  Schema  von  Bibliothekskatalogen.  Für  eine  manuelle  thematische  Verschlagwortung  und Eingruppierung  fehlen  fast  immer  Zeit  und Mittel.  Hier  wird  dargestellt,  wie  man  mit  Hilfe  eines extrem  umfangreichen  semantischen  Netzes  vollautomatisch  und  hocheffizient  Themen  und Schlagwörter  zu  Texten  in  Kollektionen  ermitteln  kann.  Die  auf  diesem  Verfahren  beruhende thematische  Verschlagwortung  deutscher  Texte  ist  als  Webservice  der  Firma  TopicZoom,  einem SpinOff   der   Ludwig-Maximilians-Universität   München,   frei   und   unentgeltlich   zugänglich (http://www.topiczoom.de/?pageid=131).
</div>
<div style="position:relative">						
	<div id="bib_c57df67ed0bd9f11ffe6ccd57f7443e3lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Mehr und bessere Information : Ute Schwens zur maschinellen Texterschließung [AUDIO]</b>.<br/>
Radiosendung.  2017. 
<br/>Ute Schwens.
<br/>

<a onclick="toggleAbstract('lepsky', '8fb79c01c92057baa66a70fc55ed2538'); return false;" href="https://www.bibsonomy.org/bibtex/28fb79c01c92057baa66a70fc55ed2538/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8fb79c01c92057baa66a70fc55ed2538', 'https://www.bibsonomy.org/bibtex/28fb79c01c92057baa66a70fc55ed2538/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28fb79c01c92057baa66a70fc55ed2538/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8fb79c01c92057baa66a70fc55ed2538lepsky" style="display:none;border:1px dotted grey;">
Kurzes Interview als Antwort auf Ceynowa
</div>
<div style="position:relative">						
	<div id="bib_8fb79c01c92057baa66a70fc55ed2538lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A survey on thesauri application in automatic natural language processing</b>. <br/>
In: <i>Proceedings of the 21st Conference of Open Innovations Association FRUCT</i>, series FRUCT'21, pages 39:296-39:303.
FRUCT Oy, Helsinki, 2017.

<br/>
Ivan Shchitov, Ksenia Lagutina, Nadezhda Lagutina, Ilya Paramonov and Andrey Vasilyev.
<br/>

<a href="http://dl.acm.org/citation.cfm?id=3176190.3176229">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'b12e3fa9b1a43723f138493af6b1c810'); return false;" href="https://www.bibsonomy.org/bibtex/2b12e3fa9b1a43723f138493af6b1c810/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'b12e3fa9b1a43723f138493af6b1c810', 'https://www.bibsonomy.org/bibtex/2b12e3fa9b1a43723f138493af6b1c810/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2b12e3fa9b1a43723f138493af6b1c810/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_b12e3fa9b1a43723f138493af6b1c810lepsky" style="display:none;border:1px dotted grey;">
This paper is devoted to investigate efficiency of thesauri use in popular natural language processing (NLP) fields: information retrieval and analysis of texts and subject areas. A thesaurus is a natural language resource that models a subject area and can reflect human experts knowledge in many NLP tasks. The main target of this survey is to determine how much thesauri affect processing quality and where they can provide better performance.We describe studies that use different types of thesauri, discuss contribution of the thesaurus into achieved results, and propose directions for future research in the thesaurus field.
</div>
<div style="position:relative">						
	<div id="bib_b12e3fa9b1a43723f138493af6b1c810lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Tracking the evolution of clustering, machine learning, automatic indexing and automatic classification in knowledge organization</b>. <br/>
<i>Knowledge Organization</i>, 44(3):215-233, 2017.

<br/>
Richard P. Smiraglia and Xin Cai.
<br/>

<a onclick="toggleAbstract('lepsky', 'dc9343e05aef4f1f7ed0a273a98e993e'); return false;" href="https://www.bibsonomy.org/bibtex/2dc9343e05aef4f1f7ed0a273a98e993e/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'dc9343e05aef4f1f7ed0a273a98e993e', 'https://www.bibsonomy.org/bibtex/2dc9343e05aef4f1f7ed0a273a98e993e/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2dc9343e05aef4f1f7ed0a273a98e993e/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_dc9343e05aef4f1f7ed0a273a98e993elepsky" style="display:none;border:1px dotted grey;">
A very important extension of the traditional domain of knowledge organization (KO) arises from attempts to incorporate techniques devised in the computer science domain for automatic concept extraction and for grouping, categorizing, clustering and otherwise organizing knowledge using mechanical means. Four specific terms have emerged to identify the most prevalent techniques: machine learning, clustering, automatic indexing, and automatic classification. Our study presents three domain analytical case analyses in search of answers. The first case relies on citations located using the ISKO-supported "Knowledge Organization Bibliography." The second case relies on works in both Web of Science and SCOPUS. Case three applies co-word analysis and citation analysis to the contents of the papers in the present special issue. We observe scholars involved in "clustering" and "automatic classification" who share common thematic emphases. But we have found no coherence, no common activity and no social semantics. We have not found a research front, or a common teleology within the KO domain. We also have found a lively group of authors who have succeeded in submitting papers to this special issue, and their work quite interestingly aligns with the case studies we report. There is an emphasis on KO for information retrieval; there is much work on clustering (which involves conceptual points within texts) and automatic classification (which involves semantic groupings at the meta-document level).
</div>
<div style="position:relative">						
	<div id="bib_dc9343e05aef4f1f7ed0a273a98e993elepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>AATOS : a configurable tool for automatic annotation</b>. <br/>
In: <i>Language, Data, and Knowledge</i>, pages 276-289.
Springer, Cham, 2017.

<br/>
Minna Tamper, Petri Leskinen, Esko Ikkala, Arttu Oksanen, Eetu Mäkelä, Erkki Heino, Jouni Tuominen, Mikko Koho and Eero Hyvönen.
<br/>

<a href="https://link.springer.com/chapter/10.1007/978-3-319-59888-8_24">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '0adf13656db7c2c4b7b702ecc30d3a06'); return false;" href="https://www.bibsonomy.org/bibtex/20adf13656db7c2c4b7b702ecc30d3a06/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '0adf13656db7c2c4b7b702ecc30d3a06', 'https://www.bibsonomy.org/bibtex/20adf13656db7c2c4b7b702ecc30d3a06/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/20adf13656db7c2c4b7b702ecc30d3a06/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_0adf13656db7c2c4b7b702ecc30d3a06lepsky" style="display:none;border:1px dotted grey;">
This paper presents an automatic annotation tool AATOS for providing documents with semantic annotations. The tool links entities found from the texts to ontologies defined by the user. The application is highly configurable and can be used with different natural language Finnish texts. The application was developed as a part of the WarSampo (http://seco.cs.aalto.fi/projects/sotasampo/en/) and Semantic Finlex (http://seco.cs.aalto.fi/projects/lawlod/en/) projects and tested using Kansa Taisteli magazine articles and consolidated Finnish legislation of Semantic Finlex. The quality of the automatic annotation was evaluated by measuring precision and recall against existing manual annotations. The results showed that the quality of the input text, as well as the selection and configuration of the ontologies impacted the results.
</div>
<div style="position:relative">						
	<div id="bib_0adf13656db7c2c4b7b702ecc30d3a06lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Descriptor-invariant fusion architectures for automatic subject indexing</b>. <br/>
In: <i>2017 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</i>, pages 1-10.
2017.

<br/>
Martin Toepfer and Christin Seifert.
<br/>


<a onclick="toggleAbstract('lepsky', 'c1c47d86182dfc4767f0012777e82a65'); return false;" href="https://www.bibsonomy.org/bibtex/2c1c47d86182dfc4767f0012777e82a65/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'c1c47d86182dfc4767f0012777e82a65', 'https://www.bibsonomy.org/bibtex/2c1c47d86182dfc4767f0012777e82a65/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2c1c47d86182dfc4767f0012777e82a65/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_c1c47d86182dfc4767f0012777e82a65lepsky" style="display:none;border:1px dotted grey;">
Documents indexed with controlled vocabularies enable users of libraries to discover relevant documents, even across language barriers. Due to the rapid growth of scientific publications, digital libraries require automatic methods that index documents accurately, especially with regard to explicit or implicit concept drift, that is, with respect to new descriptor terms and new types of documents, respectively. This paper first analyzes architectures of related approaches on automatic indexing. We show that their design determines individual strengths and weaknesses and justify research on their fusion. In particular, systems benefit from statistical associative components as well as from lexical components applying dictionary matching, ranking, and binary classification. The analysis emphasizes the importance of descriptor-invariant learning, that is, learning based on features which can be transferred between different descriptors. Theoretic and experimental results on economic titles and author keywords underline the relevance of the fusion methodology in terms of overall accuracy and adaptability to dynamic domains. Experiments show that fusion strategies combining a binary relevance approach and a thesaurus-based system outperform all other strategies on the tested data set. Our findings can help researchers and practitioners in digital libraries to choose appropriate methods for automatic indexing.
</div>
<div style="position:relative">						
	<div id="bib_c1c47d86182dfc4767f0012777e82a65lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Towards semantic quality control of automatic subject indexing</b>. <br/>
In: <i>Research and Advanced Technology for Digital Libraries</i>, series Lecture Notes in Computer Science, pages 616-619.
Springer, Cham, 2017.

<br/>
Martin Toepfer and Christin Seifert.
<br/>

<a href="https://link.springer.com/chapter/10.1007/978-3-319-67008-9_56">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '7fd18b6358aab55803c54f85c0c9c0ca'); return false;" href="https://www.bibsonomy.org/bibtex/27fd18b6358aab55803c54f85c0c9c0ca/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '7fd18b6358aab55803c54f85c0c9c0ca', 'https://www.bibsonomy.org/bibtex/27fd18b6358aab55803c54f85c0c9c0ca/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/27fd18b6358aab55803c54f85c0c9c0ca/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_7fd18b6358aab55803c54f85c0c9c0calepsky" style="display:none;border:1px dotted grey;">
Automatic subject indexing is a key technology for digital libraries, however, factors like concept drift hinder its success in practice. Releasing high-quality results into productive retrieval systems may still be possible when thorough quality control is applied, which may support algorithmic improvements and allow to create high precision filters. Since errors and their relevance can depend on characteristics of concepts and their relations, evaluations should take semantic aspects into account. For this reason, we present the prototype of a web-based reviewing tool which especially aims at fostering semantic analysis and visualization, that is, considering relations, properties and semantic categories of concepts, algorithms and reviews. The tool uses techniques of the Semantic Web. Its application is demonstrated by example.
</div>
<div style="position:relative">						
	<div id="bib_7fd18b6358aab55803c54f85c0c9c0calepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Staatsbibliothek zu Berlin wird modernisiert : "Maschinen können vieles besser"</b>.<br/>
2017. 
<br/>Ute Welty and Reinhard Altenhöner.
<br/>
<a href="http://www.deutschlandfunkkultur.de/staatsbibliothek-zu-berlin-wird-modernisiert-maschinen.1008.de.html?dram:article_id=393857">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'cc0c3e964e99d008bb404bd44a2eb670'); return false;" href="https://www.bibsonomy.org/bibtex/2cc0c3e964e99d008bb404bd44a2eb670/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'cc0c3e964e99d008bb404bd44a2eb670', 'https://www.bibsonomy.org/bibtex/2cc0c3e964e99d008bb404bd44a2eb670/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2cc0c3e964e99d008bb404bd44a2eb670/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_cc0c3e964e99d008bb404bd44a2eb670lepsky" style="display:none;border:1px dotted grey;">
Interview: Maschinen übernehmen die Verschlagwortung der Bücher der Staatsbiblothek zu Berlin. Reinhard Altenhöner, der Ständige Vertreter der Generaldirektorin, erklärt, dass der Mensch keineswegs obsolet werde. Vielmehr sei eine "Kombination aus Maschine und Mensch" erforderlich.
</div>
<div style="position:relative">						
	<div id="bib_cc0c3e964e99d008bb404bd44a2eb670lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Computerunterstützte Inhaltserschließung : Bericht über einen Workshop an der UB Stuttgart ; mit einem Exkurs zum neuen Inhaltserschließungskonzept der DNB</b>. <br/>
<i>o-bib. Das offene Bibliotheksjournal / herausgegeben vom VDB</i>, 4(3):94-105, 2017.

<br/>
Heidrun Wiesenmüller and Imma Hinrichs.
<br/>
<a href="https://www.o-bib.de/article/view/2017H3S94-105">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '390c02f28f13a934cb4c24749448a377'); return false;" href="https://www.bibsonomy.org/bibtex/2390c02f28f13a934cb4c24749448a377/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '390c02f28f13a934cb4c24749448a377', 'https://www.bibsonomy.org/bibtex/2390c02f28f13a934cb4c24749448a377/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2390c02f28f13a934cb4c24749448a377/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_390c02f28f13a934cb4c24749448a377lepsky" style="display:none;border:1px dotted grey;">
Am 8. und 9. Mai 2017 fand an der Universitätsbibliothek Stuttgart ein Workshop zum Thema „Computerunterstützte Inhaltserschließung“ mit über 50 Teilnehmenden statt.1 Ausgangspunkt der Veranstaltung war die Einführung des sogenannten „Digitalen Assistenten“ – eines Werkzeugs zur maschinellen Unterstützung der verbalen Sacherschließung – an der UB Stuttgart und weiteren Bibliotheken in Baden-Württemberg. Doch ging der Workshop auch darüber hinaus und bot die Gelegenheit, sich grundsätzlicher mit der Frage nach dem Wert von Inhaltserschließung und nach der aktuellen und künftigen Rolle von intellektuellen, halbautomatischen und vollautomatischen Verfahren auseinanderzusetzen. Alle Vortragsfolien stehen auf der Website der UB Stuttgart zur Verfügung.
</div>
<div style="position:relative">						
	<div id="bib_390c02f28f13a934cb4c24749448a377lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2016" class="bibsonomy_quicknav_group"><a name="2016">2016</a></h3>
<div style="margin-bottom:1em"><b>Semantic indexing engine</b>.<br/>
2016. 
<br/>Jannes Aasman and Marc C. Hadfield.
<br/>
<a href="http://www.freepatentsonline.com/y2016/0179979.html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '8a3d3992ff087fe314b1f76d78446814'); return false;" href="https://www.bibsonomy.org/bibtex/28a3d3992ff087fe314b1f76d78446814/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8a3d3992ff087fe314b1f76d78446814', 'https://www.bibsonomy.org/bibtex/28a3d3992ff087fe314b1f76d78446814/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28a3d3992ff087fe314b1f76d78446814/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8a3d3992ff087fe314b1f76d78446814lepsky" style="display:none;border:1px dotted grey;">
Embodiments are described for a method of distributing n-tuples over a cluster of triple-store machines, by storing each n-tuple as text in a distributed file system using a key value store; providing each machine of the cluster with a resident semantic data lake component accessing one or more persistent RDF triplestores for the n-tuple data stored on each machine; and defining one part of each n-tuple as a partition variable to ensure locality of data within each respective n-tuple. A method includes inserting graphs into a key/value store to determine how the key/value store distributes the data across a plurality of servers, by generating textual triple data, and storing the triple data in key-value stores wherein a fourth element of the triple comprises the key, and a value associated with the key comprises all the triples about a subject; indexing the data in the key-value store in an RDF triplestore using a partition based on the fourth element.
</div>
<div style="position:relative">						
	<div id="bib_8a3d3992ff087fe314b1f76d78446814lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatic recognition and disambiguation of Library of Congress Subject Headings</b>.<br/>
In: 
N. Fuhr, L. Kovács, T. Risse and W. Nejdl, editors, 
<i>Research and Advanced Technology for Digital Libraries</i>, pages 442-446.
Springer International Publishing, 2016.

<br/>
Rosa Tsegaye Aga, Christian Wartena and Michael Franke-Maier.
<br/>

<a href="http://link.springer.com/chapter/10.1007/978-3-319-43997-6_40">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '3614a20092f1e2050e88f3c02287f446'); return false;" href="https://www.bibsonomy.org/bibtex/23614a20092f1e2050e88f3c02287f446/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '3614a20092f1e2050e88f3c02287f446', 'https://www.bibsonomy.org/bibtex/23614a20092f1e2050e88f3c02287f446/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/23614a20092f1e2050e88f3c02287f446/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_3614a20092f1e2050e88f3c02287f446lepsky" style="display:none;border:1px dotted grey;">
In this article we investigate the possibilities to extract Library of Congress Subject Headings from texts. The large number of ambiguous terms turns out to be a problem. Disambiguation of subject headings seems to have potentials to improve the extraction results.
</div>
<div style="position:relative">						
	<div id="bib_3614a20092f1e2050e88f3c02287f446lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Leveraging metadata to recommend keywords for academic papers</b>. <br/>
<i>Journal of the Association for Information Science and Technology</i>, 67(12):3073-3091, 2016.

<br/>
Ido Blank, Lior Rokach and Guy Shani.
<br/>
<a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.23571/abstract">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'a1a28b6446e00110bf89d0a2725ed681'); return false;" href="https://www.bibsonomy.org/bibtex/2a1a28b6446e00110bf89d0a2725ed681/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'a1a28b6446e00110bf89d0a2725ed681', 'https://www.bibsonomy.org/bibtex/2a1a28b6446e00110bf89d0a2725ed681/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2a1a28b6446e00110bf89d0a2725ed681/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_a1a28b6446e00110bf89d0a2725ed681lepsky" style="display:none;border:1px dotted grey;">
Users of research databases, such as CiteSeerX, Google Scholar, and Microsoft Academic, often search for papers using a set of keywords. Unfortunately, many authors avoid listing sufficient keywords for their papers. As such, these applications may need to automatically associate good descriptive keywords with papers. When the full text of the paper is available this problem has been thoroughly studied. In many cases, however, due to copyright limitations, research databases do not have access to the full text. On the other hand, such databases typically maintain metadata, such as the title and abstract and the citation network of each paper. In this paper we study the problem of predicting which keywords are appropriate for a research paper, using different methods based on the citation network and available metadata. Our main goal is in providing search engines with the ability to extract keywords from the available metadata. However, our system can also be used for other applications, such as for recommending keywords for the authors of new papers. We create a data set of research papers, and their citation network, keywords, and other metadata, containing over 470K papers with and more than 2 million keywords. We compare our methods with predicting keywords using the title and abstract, in offline experiments and in a user study, concluding that the citation network provides much better predictions.
</div>
<div style="position:relative">						
	<div id="bib_a1a28b6446e00110bf89d0a2725ed681lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Intelligent tagging of online texts using fuzzy logic</b>.<br/>
2016. bibtex: Damaeviius2016IntelligentTO.
<br/>Robertas Damavsevivcius, Remigijus Valys and Marcin Woźniak.
<br/>
<a href="https://www.semanticscholar.org/paper/Intelligent-Tagging-of-Online-Texts-Using-Fuzzy-Damaševičius-Valys/b4f24b1778f971427d0ff9ef69945669586a2283">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'bbd4f6d1edfd4bf8991a7dda6ec789b5'); return false;" href="https://www.bibsonomy.org/bibtex/2bbd4f6d1edfd4bf8991a7dda6ec789b5/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'bbd4f6d1edfd4bf8991a7dda6ec789b5', 'https://www.bibsonomy.org/bibtex/2bbd4f6d1edfd4bf8991a7dda6ec789b5/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2bbd4f6d1edfd4bf8991a7dda6ec789b5/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_bbd4f6d1edfd4bf8991a7dda6ec789b5lepsky" style="display:none;border:1px dotted grey;">
We propose four fuzzy-logic based models of tag recommendation, which are based on the interpretation of word frequency as a fuzzy membership function, and provide experimental results of tag recommendation for a variety of text datasets using different fuzzy logic operators. The novelty of the proposed models is the use of fuzzy logic modeling concepts to define a set of tags, the use of an existing set of tags for the selection of tags to strengthen the selection of most relevant (i.e., commonly used) tags, and the possibility to use an ontology to select semantically generalized tags. A system developed using the proposed models is adaptive (adapts the recommended tags to the existing set of tags), has a feedback (after each tagging, the set of tags and the dictionary are updated), is personalized (each user develops its own set of tags), and is semantics-aware (uses an ontology to refine tags). The models are validated using five sets of texts with different topics (technology, cooking, carrier, scientific, nature) and different length.
</div>
<div style="position:relative">						
	<div id="bib_bbd4f6d1edfd4bf8991a7dda6ec789b5lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A framework for evaluating automatic indexing or classification in the context of retrieval</b>. <br/>
<i>Journal of the American Society For Information Science And Technology</i>, 67(1):3-16, 2016.

<br/>
Koraljka Golub, Soergel Dagobert, George Buchanan, Douglas Tudhope, Debra Hiom and Marianne Lykke.
<br/>
<a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A842453&amp;dswid=_new">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'be084123eab58c556affb88cfaf600b3'); return false;" href="https://www.bibsonomy.org/bibtex/2be084123eab58c556affb88cfaf600b3/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'be084123eab58c556affb88cfaf600b3', 'https://www.bibsonomy.org/bibtex/2be084123eab58c556affb88cfaf600b3/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2be084123eab58c556affb88cfaf600b3/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_be084123eab58c556affb88cfaf600b3lepsky" style="display:none;border:1px dotted grey;">
Tools for automatic subject assignment help deal with scale and sustainability in creating and enriching metadata, establishing more connections across and between resources and enhancing consistency. While some software vendors and experimental researchers claim the tools can replace manual subject indexing, hard scientific evidence of their performance in operating information environments is scarce. A major reason for this is that research is usually conducted in laboratory conditions, excluding the complexities of real-life systems and situations. The paper reviews and discusses issues with existing evaluation approaches such as problems of aboutness and relevance assessments, implying the need to use more than a single “gold standard” method when evaluating indexing and retrieval and proposes a comprehensive evaluation framework. The framework is informed by a systematic review of the literature on indexing, classification and approaches: evaluating indexing quality directly through assessment by an evaluator or through comparison with a gold standard; evaluating the quality of computer-assisted indexing directly in the context of an indexing workflow, and evaluating indexing quality indirectly through analyzing retrieval performance.
</div>
<div style="position:relative">						
	<div id="bib_be084123eab58c556affb88cfaf600b3lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Subject indexing for author name disambiguation : opportunities and challenges</b>.<br/>
In: 
A. F. X. Wilhelm and H. A. Kestler, editors, 
<i>Analysis of Large and Complex Data</i>, pages 639-649.
Springer International Publishing, 2016.

<br/>
Cornelia Hedeler, Andreas Oskar Kempf and Jan Steinberg.
<br/>

<a href="http://link.springer.com/chapter/10.1007/978-3-319-25226-1_55">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '0af0ef2f2ed5d24ebb9361d5ca3b557d'); return false;" href="https://www.bibsonomy.org/bibtex/20af0ef2f2ed5d24ebb9361d5ca3b557d/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '0af0ef2f2ed5d24ebb9361d5ca3b557d', 'https://www.bibsonomy.org/bibtex/20af0ef2f2ed5d24ebb9361d5ca3b557d/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/20af0ef2f2ed5d24ebb9361d5ca3b557d/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_0af0ef2f2ed5d24ebb9361d5ca3b557dlepsky" style="display:none;border:1px dotted grey;">
Author name disambiguation is becoming increasingly important due to the prevalent availability of publications in digital libraries. Various approaches for author name disambiguation are available, utilising a variety of information, e.g., author name, affiliation, title, journal and conference name or venue, citation, co-author, and topic information (Ferreira et al., SIGMOD Rec 41(2), 2012). Topics can be obtained, e.g., using subject information captured in various controlled vocabularies, classifications and mappings between them used to index publications (Torvik et al., J Am Soc Inf Sci Technol 56(2):140–158, 2005). Research interests of authors, evident in topics, might change over time though (Ferreira et al., SIGMOD Rec 41(2), 2012), and thus limit their usefulness for author name disambiguation. Here we present a longitudinal analysis of topics with respect to their suitability for author name disambiguation. We analyse the distribution of subject headings and classification notations taken from the Thesaurus (TSS) and the Classification for the Social Sciences (CSS) (http://​www.​gesis.​org/​en/​services/​research/​thesauri-und-klassifikationen​/​) for research projects and literature (available in sowiport—http://​sowiport.​gesis.​org maintained by GESIS) and the changes in distribution over time. To assess the suitability of subject information for author name disambiguation more closely, we then analyse the changes in the annotation over time for a selection of authors and author groups at different stages in their career, also taking into account the hierarchical organisation of the applied controlled vocabularies.
</div>
<div style="position:relative">						
	<div id="bib_0af0ef2f2ed5d24ebb9361d5ca3b557dlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automated arabic text classification with P-Stemmer, machine learning, and a tailored news article taxonomy</b>. <br/>
<i>Journal of the Association for Information Science &amp; Technology</i>, 67(11):2667-2683, 2016.

<br/>
Tarek Kanan and Edward A. Fox.
<br/>

<a onclick="toggleAbstract('lepsky', '0e75aefc39d00879c8b05975d9a038d2'); return false;" href="https://www.bibsonomy.org/bibtex/20e75aefc39d00879c8b05975d9a038d2/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '0e75aefc39d00879c8b05975d9a038d2', 'https://www.bibsonomy.org/bibtex/20e75aefc39d00879c8b05975d9a038d2/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/20e75aefc39d00879c8b05975d9a038d2/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_0e75aefc39d00879c8b05975d9a038d2lepsky" style="display:none;border:1px dotted grey;">
Arabic news articles in electronic collections are difficult to study. Browsing by category is rarely supported. Although helpful machine-learning methods have been applied successfully to similar situations for English news articles, limited research has been completed to yield suitable solutions for Arabic news. In connection with a Qatar National Research Fund ( QNRF)-funded project to build digital library community and infrastructure in Qatar, we developed software for browsing a collection of about 237,000 Arabic news articles, which should be applicable to other Arabic news collections. We designed a simple taxonomy for Arabic news stories that is suitable for the needs of Qatar and other nations, is compatible with the subject codes of the International Press Telecommunications Council, and was enhanced with the aid of a librarian expert as well as five Arabic-speaking volunteers. We developed tailored stemming (i.e., a new Arabic light stemmer called P- Stemmer) and automatic classification methods (the best being binary Support Vector Machines classifiers) to work with the taxonomy. Using evaluation techniques commonly used in the information retrieval community, including 10-fold cross-validation and the Wilcoxon signed-rank test, we showed that our approach to stemming and classification is superior to state-of-the-art techniques.
</div>
<div style="position:relative">						
	<div id="bib_0e75aefc39d00879c8b05975d9a038d2lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Subject indexing of textbooks : challenges in the construction of a discovery system</b>.<br/>
In: 
A. F. X. Wilhelm and H. A. Kestler, editors, 
<i>Analysis of Large and Complex Data</i>, pages 621-627.
Springer International Publishing, 2016.

<br/>
Bianca Pramann, Jessica Drechsler, Esther Chen and Robert Strötgen.
<br/>

<a href="http://link.springer.com/chapter/10.1007/978-3-319-25226-1_53">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '013365583fc9c9bba80b586037d60e14'); return false;" href="https://www.bibsonomy.org/bibtex/2013365583fc9c9bba80b586037d60e14/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '013365583fc9c9bba80b586037d60e14', 'https://www.bibsonomy.org/bibtex/2013365583fc9c9bba80b586037d60e14/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2013365583fc9c9bba80b586037d60e14/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_013365583fc9c9bba80b586037d60e14lepsky" style="display:none;border:1px dotted grey;">
The purpose of this paper is to present the steps on the way of finding a suitable classification system for subject indexing of textbooks and to integrate this into a resource discovery system. Textbooks are usually not indexed at great length. Yet, the research library of the Georg Eckert Institute has a unique status regarding the range of collected textbooks. This makes a detailed subject indexing indispensable. The currently used local solution shall be replaced by a more standardised solution to serve greater dissemination and compatibility of our data and to simplify the search process for the user.
</div>
<div style="position:relative">						
	<div id="bib_013365583fc9c9bba80b586037d60e14lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Indexierung auf Basis von Titeln und Autoren-Keywords : ein Werkstattbericht</b>. <br/>
<i>027.7 Zeitschrift für Bibliothekskultur / Journal for Library Culture</i>, 4(2):84-97, 2016.

<br/>
Martin Toepfer and Andreas Oskar Kempf.
<br/>
<a href="http://0277.ch/ojs/index.php/cdrs_0277/article/view/156">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'f53c6b4a51f8a0be991f325ecb244a8c'); return false;" href="https://www.bibsonomy.org/bibtex/2f53c6b4a51f8a0be991f325ecb244a8c/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'f53c6b4a51f8a0be991f325ecb244a8c', 'https://www.bibsonomy.org/bibtex/2f53c6b4a51f8a0be991f325ecb244a8c/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2f53c6b4a51f8a0be991f325ecb244a8c/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_f53c6b4a51f8a0be991f325ecb244a8clepsky" style="display:none;border:1px dotted grey;">
Automatische Verfahren sind für Bibliotheken essentiell, um die Erschliessung stetig wachsender Datenmengen zu stemmen. Die Deutsche Zentralbibliothek für Wirtschaftswissenschaften – Leibniz-Informationszentrum Wirtschaft sammelt seit Längerem Erfahrungen im Bereich automatischer Indexierung und baut hier eigene Kompetenzen auf. Aufgrund rechtlicher Restriktionen werden unter anderem Ansätze untersucht, die ohne Volltextnutzung arbeiten. Dieser Beitrag gibt einen Einblick in ein laufendes Teilprojekt, das unter Verwendung von Titeln und Autoren-Keywords auf eine Nachnormierung der inhaltsbeschreibenden Metadaten auf den Standard-Thesaurus Wirtschaft (STW) abzielt. Wir erläutern den Hintergrund der Arbeit, betrachten die Systemarchitektur und stellen erste vielversprechende Ergebnisse eines dokumentenorientierten Verfahrens vor.Automatic systems are indispensable for libraries in order to make the rapidly growing number of publications accessible to their users. In the past the ZBW – German National Library of Economics – Leibniz Information Centre for Economics has gained practical experience in this field. Due to legal constraints it currently investigates methods that solely use author generated descriptive metadata. This article gives an insight into on-going developments and relates them to past activities. We report on a promising document-oriented approach, which uses author keywords and titles in combination to automatically assign subject headings from the STW Thesaurus for Economics to a document.
</div>
<div style="position:relative">						
	<div id="bib_f53c6b4a51f8a0be991f325ecb244a8clepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2015" class="bibsonomy_quicknav_group"><a name="2015">2015</a></h3>
<div style="margin-bottom:1em"><b>Bildung von Komposita-Indextermen auf der Basis einer algorithmischen Mehrwortgruppenanalyse mit Lingo</b>.
<br/>
PhD thesis, Fachhochschule Köln; Fakultät für Informations- und Kommunikationswissenschaften, Köln, 2015.

<br/>
Stefan Grün.
<br/>

<a onclick="toggleAbstract('lepsky', 'daf09abdf12a69f8919aafc69b60af25'); return false;" href="https://www.bibsonomy.org/bibtex/2daf09abdf12a69f8919aafc69b60af25/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'daf09abdf12a69f8919aafc69b60af25', 'https://www.bibsonomy.org/bibtex/2daf09abdf12a69f8919aafc69b60af25/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2daf09abdf12a69f8919aafc69b60af25/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_daf09abdf12a69f8919aafc69b60af25lepsky" style="display:none;border:1px dotted grey;">
In der deutschen Sprache lassen sich Begriffe durch Komposita und Mehrwortgruppen ausdrücken. Letztere können dabei aber auch als Kompositum selbst ausgedrückt werden und entsprechend auf den gleichen Begriff verweisen. In der nachfolgenden Studie werden Mehrwortgruppen analysiert, die auch Komposita sein können. Ziel der Untersuchung ist es, diese Wortfolgen über Muster zu identifizieren. Analysiert wurden Daten des Karrieremanagers Placement24 GmbH – in Form von Stellenanzeigen. Die Extraktion von Mehrwortgruppen erfolgte algorithmisch und wurde mit der Open-Source Software Lingo durchgeführt. Auf der Basis von Erweiterungen bzw. Anpassungen in Wörterbüchern und den darin getaggten Wörtern, wurden drei- bis fünfstellige Kandidaten analysiert. Aus positiv bewerteten Mehrwortgruppen wurden Komposita gebildet. Diese wurden mit den identifizierten Komposita aus den Stellenanzeigen verglichen. Der Vergleich zeigte, dass ein Großteil der neu generierten Komposita nicht durch eine Kompositaidentifizierung erzeugt wurde.
</div>
<div style="position:relative">						
	<div id="bib_daf09abdf12a69f8919aafc69b60af25lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Two steps break-cull model for automatic indexing of Persian texts</b>. <br/>
<i>Research on Information Science and Public Libraries</i>, 21(1):13-40, 2015.

<br/>
Mohammad Tavakolizadeh-Ravari.
<br/>
<a href="http://www.publij.ir/article-1-966-en.html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '8ff87c6d87638e144035eccd5c1465b0'); return false;" href="https://www.bibsonomy.org/bibtex/28ff87c6d87638e144035eccd5c1465b0/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8ff87c6d87638e144035eccd5c1465b0', 'https://www.bibsonomy.org/bibtex/28ff87c6d87638e144035eccd5c1465b0/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28ff87c6d87638e144035eccd5c1465b0/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8ff87c6d87638e144035eccd5c1465b0lepsky" style="display:none;border:1px dotted grey;">
Purpose: Each language has its own problems. This leads to consider appropriate models for automatic indexing of every language. These models should concern the exhaustificity and specificity of indexing. This paper aims at introduction and evaluation of a model which is suited for Persian automatic indexing. This model suggests to break the text into the particles of candidate terms and to cull the most appropriate ones through a special method of term weighting. Methodology: The introduction method of the automatic indexing model is performed through showing the steps and the possible problems for running them. Evaluation is based on the inclusion index. This index is used for determination the inter-indexer consistency. Therefore, the consistency of resulted index terms (from this model) and author keywords is determined. Findings: Findings show that 90%of articles' most weighted terms are similar to their first author keywords. The overall consistency between the results of running the model and author keywords is 76 Compared with the prior works, the performance of the model is acceptable. Originality/Value: The initial value of this paper is concerning the automatic indexing with regard of Persian language problems. The model is well suited for using regular expression language which is supported by many programming languages. This diminishes the need to create database tables for text manipulation and processing. In addition, the model solves the problem of upper threshold for determination of final terms. Another algorithm makes it possible to determine the lower one. Finally, the number of culled terms does not depend on the text length. This guaranties the exhaustificity and specificity of indexing
</div>
<div style="position:relative">						
	<div id="bib_8ff87c6d87638e144035eccd5c1465b0lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Retrieval methods of natural language based on automatic indexing</b>.<br/>
In: 
D. Li and Z. Li, editors, 
<i>Computer and Computing Technologies in Agriculture IX</i>, pages 346-356.
Springer International Publishing, 2015.

<br/>
Dan Wang, Xiaorong Yang, Jian Ma and Liping Zhang.
<br/>

<a href="http://link.springer.com/chapter/10.1007/978-3-319-48354-2_35">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '21f9c46e9e6b2f7e05dbc984915ed209'); return false;" href="https://www.bibsonomy.org/bibtex/221f9c46e9e6b2f7e05dbc984915ed209/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '21f9c46e9e6b2f7e05dbc984915ed209', 'https://www.bibsonomy.org/bibtex/221f9c46e9e6b2f7e05dbc984915ed209/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/221f9c46e9e6b2f7e05dbc984915ed209/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_21f9c46e9e6b2f7e05dbc984915ed209lepsky" style="display:none;border:1px dotted grey;">
Since natural language enter the computer retrieval system, due to the natural language retrieval is not restricted by professional experience, knowledge background, retrieval experience by users, and above reasons favored by the users. As the title of the Chinese literature is the concentrated reflection of Chinese literature content, it reflects the central idea of the literature. Retrieval methods of natural language described in this article is limited to literature title in subject indexing. The basic idea of this method is, with automatic indexing methods respectively the literature title in the database of retrieval system used in natural language retrieval for automatic word indexing. To control the concept of a given keyword, namely meaning transformation, form the final indexing words. Then, using the vector space model for the index data in the database will be “or” operation to retrieve, forming a document set B. For each document title in set B for automatic indexing, the title of each article for automatic indexing, indexing terms for the formation and retrieval of natural language indexing terms similarity calculation, sorted according to similarity of each document in set B. The first best match the requirements presented to the user documentation. This method is a simple and practical method of natural language retrieval.
</div>
<div style="position:relative">						
	<div id="bib_21f9c46e9e6b2f7e05dbc984915ed209lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2014" class="bibsonomy_quicknav_group"><a name="2014">2014</a></h3>
<div style="margin-bottom:1em"><b>Methode zum strukturellen Abgleich unternehmensspezifischer Logistikprozesse mit Best-Practice-Prozessen</b>.
<br/>
PhD thesis, TU Dortmund, Dortmund, 2014.

<br/>
Torsten Bugla.
<br/>

<a onclick="toggleAbstract('lepsky', '68afb13e9bcd935130ba29fd0b4a6a66'); return false;" href="https://www.bibsonomy.org/bibtex/268afb13e9bcd935130ba29fd0b4a6a66/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '68afb13e9bcd935130ba29fd0b4a6a66', 'https://www.bibsonomy.org/bibtex/268afb13e9bcd935130ba29fd0b4a6a66/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/268afb13e9bcd935130ba29fd0b4a6a66/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_68afb13e9bcd935130ba29fd0b4a6a66lepsky" style="display:none;border:1px dotted grey;">
Durch die Arbeit soll eine Methode geschaffen werden, die den strukturellen Vergleich logisti- scher Geschäftsprozesse ermöglicht. Die Motivation dazu basiert auf vier Eigenschaften, die dem Thema der Arbeit zu Grunde liegen. Erstens ist eine Verknüpfung der Logistik und Informationstechnologie (IT) erforderlich. Die Methode gründet einerseits auf den Eigenschaften logistischer Prozesse, andererseits auf dem Einsatz von IT-Verfahren. Durch die Verbindung beider Themenbereiche werden neue Forschungserkenntnisse aufgedeckt, die hilfreich für die Wissenschaft sind. Dass die Logistik einen aktuellen Themenbereich darstellt, wird durch das steigende Interesse an logistischen Fragestellungen in der Wirtschaft belegt (vgl. [Win08], S.1). Zweitens sind die Verbesserungspotenziale logistischer Geschäftsprozesse nicht ausge- schöpft. Das belegen zahlreiche Technologien und Ansätze, die durch die Verknüpfung von Geschäftsprozessen und IT die Optimierung von Unternehmensstrukturen verbessern (vgl. [PB06], S.321). Veranstaltungen und Konferenzen zu Themen der Prozessoptimierung und des Wissensmanagements belegen die Aussage zusätzlich ([Bai08], S.7; [Joh06], S.3; [FFO06], S.1). Dabei bestehen in den operativen Geschäftsfeldern, z.B. der Logistik, die größten Verbes- serungspotenziale. Drittens hat das Forschungsthema einen starken Praxisbezug. Der Abgleich von Geschäfts- prozessen ist nicht nur ein interessantes Forschungsthema sondern auch ein möglicher Ansatz zur Lösung praxisrelevanter Problemstellungen in Unternehmen. Dass das Forschungsthema diesen praktischen Bezug hat, zeigt ein Projekt des Instituts für Produktionsanlagen und Kon- struktionstechnik (IPK) in Berlin, indem der strukturelle Abgleich von Geschäftsprozessen in der IT-Branche ermöglicht wurde (vgl. [Kno12]). Innerhalb des Projektes haben zahlreiche mit- telständische Unternehmen mit dem IPK kooperiert, was das wirtschaftliche Interesse beweist. Viertens kann die Arbeit eine optimale Grundlage für weitere Forschungsansätze bilden. Die Umsetzung der Methode in eine Software ist ein Ziel. Dafür bedarf es einerseits geeignete Methodenschritte und andererseits eine verständliche Darstellung dieser Schritte. Die Methode zum strukturellen Vergleich logistischer Geschäftsprozesse ist somit eine entscheidende Arbeit für weitere Forschungszwecke. Durch die interdisziplinäre Aufgabenstellung und den starken Praxisbezug ergibt sich somit eine Begründung dafür, warum die Arbeit verfasst wird.
</div>
<div style="position:relative">						
	<div id="bib_68afb13e9bcd935130ba29fd0b4a6a66lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A preliminary investigation into the automatic EuroVoc indexing of greek documents</b>. <br/>
In: <i>Proceedings of the 18th Panhellenic Conference on Informatics</i>, series PCI '14, pages 45:1-45:5.
ACM, New York, NY, 2014.

<br/>
Eleni Galiotou.
<br/>

<a href="http://doi.acm.org/10.1145/2645791.2645822">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '5a6804530e099fbf5cb74e50f35581df'); return false;" href="https://www.bibsonomy.org/bibtex/25a6804530e099fbf5cb74e50f35581df/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '5a6804530e099fbf5cb74e50f35581df', 'https://www.bibsonomy.org/bibtex/25a6804530e099fbf5cb74e50f35581df/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/25a6804530e099fbf5cb74e50f35581df/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_5a6804530e099fbf5cb74e50f35581dflepsky" style="display:none;border:1px dotted grey;">
In this paper, we present an automatic indexing experiment of greek documents. In particular, we describe an attempt to use JEX, the JRC-developed indexing tool, in order to assign EuroVoc descriptors to a collection of Greek open data. We discuss the results and limitations of this approach and we propose solutions which take into account the particularities of the Greek language.
</div>
<div style="position:relative">						
	<div id="bib_5a6804530e099fbf5cb74e50f35581dflepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Towards linking libraries and Wikipedia : automatic subject indexing of library records with Wikipedia concepts</b>. <br/>
<i>Journal of Information Science</i>, 40(2):211-221, 2014.

<br/>
Arash Joorabchi and Abdulhussain E. Mahdi.
<br/>
<a href="http://dx.doi.org/10.1177/0165551513514932">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '3e1eb722ce7237215a97712f3c823b4a'); return false;" href="https://www.bibsonomy.org/bibtex/23e1eb722ce7237215a97712f3c823b4a/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '3e1eb722ce7237215a97712f3c823b4a', 'https://www.bibsonomy.org/bibtex/23e1eb722ce7237215a97712f3c823b4a/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/23e1eb722ce7237215a97712f3c823b4a/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_3e1eb722ce7237215a97712f3c823b4alepsky" style="display:none;border:1px dotted grey;">
In this article, we first argue the importance and timely need of linking libraries and Wikipedia for improving the quality of their services to information consumers, as such linkage will enrich the quality of Wikipedia articles and at the same time increase the visibility of library resources which are currently overlooked to a large degree. We then describe the development of an automatic system for subject indexing of library metadata records with Wikipedia concepts as an important step towards library–Wikipedia integration. The proposed system is based on first identifying all Wikipedia concepts occurring in the metadata elements of library records. This is then followed by training and deploying generic machine learning algorithms to automatically select those concepts which most accurately reflect the core subjects of the library materials whose records are being indexed. We have assessed the performance of the developed system using standard information retrieval measures of precision, recall and F-score on a dataset consisting of 100 library metadata records manually indexed with a total of 469 Wikipedia concepts. The evaluation results show that the developed system is capable of achieving an averaged F-score as high as 0.92.
</div>
<div style="position:relative">						
	<div id="bib_3e1eb722ce7237215a97712f3c823b4alepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Can indexing be automated? : the example of the Deutsche Nationalbibliothek</b>. <br/>
<i>Cataloging &amp; Classification Quarterly</i>, 52(1):102-109, 2014.

<br/>
Ulrike Junger.
<br/>
<a href="http://www.nlib.ee/index.php?id=17763">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '2daed5bfa957ec39af7f0c6e8f023db8'); return false;" href="https://www.bibsonomy.org/bibtex/22daed5bfa957ec39af7f0c6e8f023db8/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '2daed5bfa957ec39af7f0c6e8f023db8', 'https://www.bibsonomy.org/bibtex/22daed5bfa957ec39af7f0c6e8f023db8/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/22daed5bfa957ec39af7f0c6e8f023db8/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_2daed5bfa957ec39af7f0c6e8f023db8lepsky" style="display:none;border:1px dotted grey;">
The German Integrated Authority File (Gemeinsame Normdatei, GND), provides a broad controlled vocabulary for indexing documents on all subjects. Traditionally used for intellectual subject cataloging primarily for books, the Deutsche Nationalbibliothek (DNB, German National Library) has been working on developing and implementing procedures for automated assignment of subject headings for online publications. This project, its results, and problems are outlined in this article. Contribution in a special issue "Beyond libraries: Subject metadata in the digital environment and Semantic Web"
</div>
<div style="position:relative">						
	<div id="bib_2daed5bfa957ec39af7f0c6e8f023db8lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Noun phrases in automatic indexing : a structural analysis of the distribution of relevant terms in doctoral theses</b>. <br/>
In: , pages 327-334.
Ergon, 2014.

<br/>
Luiz Mesquita, Renato Souza and Renata Baracho Porto.
<br/>


<a onclick="toggleAbstract('lepsky', '605b75f1d6d9156e1a778cb961245dd3'); return false;" href="https://www.bibsonomy.org/bibtex/2605b75f1d6d9156e1a778cb961245dd3/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '605b75f1d6d9156e1a778cb961245dd3', 'https://www.bibsonomy.org/bibtex/2605b75f1d6d9156e1a778cb961245dd3/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2605b75f1d6d9156e1a778cb961245dd3/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_605b75f1d6d9156e1a778cb961245dd3lepsky" style="display:none;border:1px dotted grey;">
The main objective of this research was to analyze whether there was a characteristic distribution behavior of relevant terms over a scientific text that could contribute as a criterion for their process of automatic indexing. The terms considered in this study were only full noun phrases contained in the texts themselves. The texts were considered a total of 98 doctoral theses of the eight areas of knowledge in a same university. Initially, 20 full noun phrases were automatically extracted from each text as candidates to be the most relevant terms, and each author of each text assigned a relevance value 0-6 (not relevant and highly relevant, respectively) for each of the 20 noun phrases sent. Only, 22.1 %of noun phrases were considered not relevant. A relevance values of the terms assigned by the authors were associated with their positions in the text. Each full noun phrases found in the text was considered as a valid linear position. The results that were obtained showed values resulting from this distribution by considering two types of position: linear, with values consolidated into ten equal consecutive parts; and structural, considering parts of the text (such as introduction, development and conclusion). As a result of considerable importance, all areas of knowledge related to the Natural Sciences showed a characteristic behavior in the distribution of relevant terms, as well as all areas of knowledge related to Social Sciences showed the same characteristic behavior of distribution, but distinct from the Natural Sciences. The difference of the distribution behavior between the Natural and Social Sciences can be clearly visualized through graphs. All behaviors, including the general behavior of all areas of knowledge together, were characterized in polynomial equations and can be applied in future as criteria for automatic indexing. Until the present date this work has become inedited of for two reasons: to present a method for characterizing the distribution of relevant terms in a scientific text, and also, through this method, pointing out a quantitative trait difference between the Natural and Social Sciences.
</div>
<div style="position:relative">						
	<div id="bib_605b75f1d6d9156e1a778cb961245dd3lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2013" class="bibsonomy_quicknav_group"><a name="2013">2013</a></h3>
<div style="margin-bottom:1em">
<b>Automatic information extraction from texts with inference and linguistic knowledge acquisition rules</b>. <br/>
<i>Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 2013 IEEE/WIC/ACM International Joint Conferences on</i>, 3:151-154, 2013.

<br/>
Denis de Araujo, Sandro Rigo, Carolina Muller and Rove Chishman.
<br/>
<a href="http://dx.doi.org/10.1109/WI-IAT.2013.171">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'bd6a713f3bdc093bb194884b4312b4c3'); return false;" href="https://www.bibsonomy.org/bibtex/2bd6a713f3bdc093bb194884b4312b4c3/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'bd6a713f3bdc093bb194884b4312b4c3', 'https://www.bibsonomy.org/bibtex/2bd6a713f3bdc093bb194884b4312b4c3/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2bd6a713f3bdc093bb194884b4312b4c3/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_bd6a713f3bdc093bb194884b4312b4c3lepsky" style="display:none;border:1px dotted grey;">
In this paper we present a novel methodology for automatic information extraction from natural language texts, based on the integration of linguistic rules, multiple ontologies and inference resources, integrated with an abstraction layer for linguistic annotation and data representation. The methodology allows ontology population with instances of events. The main contribution presented is related to the exploration of the flexibility of linguistic rules and domain knowledge representation, through their manipulation and integration by a reasoning system. The results from the case study indicate that the proposed approach is effective for the legal domain.
</div>
<div style="position:relative">						
	<div id="bib_bd6a713f3bdc093bb194884b4312b4c3lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Document-based synonym generation</b>. <br/>
(United States Patent 8392413), 2013.

<br/>
Oleksandr Grushetskyy and Steven Baker.
<br/>
<a href="http://www.freepatentsonline.com/8392413.html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '08372dffdf1c155eda5e36fb1025a846'); return false;" href="https://www.bibsonomy.org/bibtex/208372dffdf1c155eda5e36fb1025a846/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '08372dffdf1c155eda5e36fb1025a846', 'https://www.bibsonomy.org/bibtex/208372dffdf1c155eda5e36fb1025a846/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/208372dffdf1c155eda5e36fb1025a846/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_08372dffdf1c155eda5e36fb1025a846lepsky" style="display:none;border:1px dotted grey;">
One embodiment of the present invention provides a system that automatically generates synonyms for words from documents. During operation, this system determines co-occurrence frequencies for pairs of words in the documents. The system also determines closeness scores for pairs of words in the documents, wherein a closeness score indicates whether a pair of words are located so close to each other that the words are likely to occur in the same sentence or phrase. Finally, the system determines whether pairs of words are synonyms based on the determined co-occurrence frequencies and the determined closeness scores. While making this determination, the system can additionally consider correlations between words in a title or an anchor of a document and words in the document as well as word-form scores for pairs of words in the documents.
</div>
<div style="position:relative">						
	<div id="bib_08372dffdf1c155eda5e36fb1025a846lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Initialism disambiguation : man versus machine</b>. <br/>
<i>J Am Soc Inf Sci Tec</i>, 64(10):2133-2148, 2013.

<br/>
Yaakov HaCohen-Kerner, Ariel Kass and Ariel Peretz.
<br/>
<a href="http://dx.doi.org/10.1002/asi.22909">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '2ab900f3f4dc8eb85d704305275c6fac'); return false;" href="https://www.bibsonomy.org/bibtex/22ab900f3f4dc8eb85d704305275c6fac/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '2ab900f3f4dc8eb85d704305275c6fac', 'https://www.bibsonomy.org/bibtex/22ab900f3f4dc8eb85d704305275c6fac/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/22ab900f3f4dc8eb85d704305275c6fac/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_2ab900f3f4dc8eb85d704305275c6faclepsky" style="display:none;border:1px dotted grey;">
Disambiguation of ambiguous initialisms and acronyms is critical to the proper understanding of various types of texts. A model that attempts to solve this has previously been presented. This model contained various baseline features, including contextual relationship features, statistical features, and language-specific features. The domain of Jewish law documents written in Hebrew and Aramaic is known to be rich in ambiguous abbreviations and therefore this model was implemented and applied over 2 separate corpuses within this domain. Several common machine-learning (ML) methods were tested with the intent of finding a successful integration of the baseline feature variants. When the features were evaluated individually, the best averaged results were achieved by a library for support vector machines (LIBSVM); 98.07%of the ambiguous abbreviations, which were researched in the domain, were disambiguated correctly. When all the features were evaluated together, the J48 ML method achieved the best result, with 96.95%accuracy. In this paper, we examine the system's degree of success and the degree of its professionalism by conducting a comparison between this system's results and the results achieved by 39 participants, highly fluent in the research domain. Despite the fact that all the participants had backgrounds in religious scriptures and continue to study these texts, the system's accuracy rate, 98.07 was significantly higher than the average accuracy result of the participants, 91.65 Further analysis of the results for each corpus implies that participants overcomplicate the required task, as well as exclude vital information needed to properly examine the context of a given initialism.
</div>
<div style="position:relative">						
	<div id="bib_2ab900f3f4dc8eb85d704305275c6faclepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Inhaltserschliessung in der Fachinformation</b>. <br/>
<i>Information-Wissenschaft  Praxis</i>, 64(2-3):96-106, 2013.

<br/>
Andreas Kempf.
<br/>

<a onclick="toggleAbstract('lepsky', 'c81c218b7d9667dacdbc95754c994196'); return false;" href="https://www.bibsonomy.org/bibtex/2c81c218b7d9667dacdbc95754c994196/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'c81c218b7d9667dacdbc95754c994196', 'https://www.bibsonomy.org/bibtex/2c81c218b7d9667dacdbc95754c994196/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2c81c218b7d9667dacdbc95754c994196/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_c81c218b7d9667dacdbc95754c994196lepsky" style="display:none;border:1px dotted grey;">
Der Artikel basiert auf einer Masterarbeit mit dem Titel „Automatische Indexierung in der sozialwissenschaftli- chen Fachinformation. Eine Evaluationsstudie zur ma- schinellen Erschliessung für die Datenbank SOLIS`` (Kempf 2012), die im Rahmen des Aufbaustudiengangs Biblio- theks- und Informationswissenschaft an der Humboldt- Universität zu Berlin am Lehrstuhl Information Retrieval verfasst wurde. Auf der Grundlage des Schalenmodells zur Inhaltserschliessung in der Fachinformation (vgl. Krause 1996, 2006) stellt der Artikel Evaluationsergebnis- se eines automatischen Erschliessungsverfahrens für den Einsatz in der sozialwissenschaftlichen Fachinformation vor. Ausgehend von dem von Krause beschriebenen An- wendungsszenario, wonach SOLIS-Datenbestände (Sozi- alwissenschaftliches Literaturinformationssystem) von geringerer Relevanz automatisch erschlossen werden soll- ten, wurden auf dieser Dokumentgrundlage zwei Testrei- hen mit der Indexierungssoftware MindServer der Firma Recommind1 durchgeführt. Neben den Auswirkungen all- gemeiner Systemeinstellungen in der ersten Testreihe wurde in der zweiten Testreihe die Indexierungsleistung der Software für die Rand- und die Kernbereiche der Lite- raturdatenbank miteinander verglichen. Für letztere Test- reihe wurden für beide Bereiche der Datenbank spezi- fische Versionen der Indexierungssoftware aufgebaut, die anhand von Dokumentkorpora aus den entsprechenden Bereichen trainiert wurden. Die Ergebnisse der Evaluati- on, die auf der Grundlage intellektuell generierter Ver- gleichsdaten erfolgt, weisen auf Unterschiede in der Inde- xierungsleistung zwischen Rand- und Kernbereichen hin, die einerseits gegen den Einsatz automatischer Indexie- rungsverfahren in den Randbereichen sprechen. Anderer- seits deutet sich an, dass sich die Indexierungsresultate durch den Aufbau fachteilgebietsspezifischer Trainings- mengen verbessern lassen.
</div>
<div style="position:relative">						
	<div id="bib_c81c218b7d9667dacdbc95754c994196lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Indexierung</b>.<br/>
In: 
R. Kuhlen, W. Semar and D. Strauch, editors, 
<i>Grundlagen der praktischen Information und Dokumentation: Handbuch zur Einführung in die Informationswissenschaft und -praxis</i>, pages 272-285.
De Gruyter, Berlin, 2013.

<br/>
Klaus Lepsky.
<br/>

<a href="http://dx.doi.org/10.1515/9783110258264.272">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', 'd3867ad30d8907fb54ee7e87213c68dc', 'https://www.bibsonomy.org/bibtex/2d3867ad30d8907fb54ee7e87213c68dc/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2d3867ad30d8907fb54ee7e87213c68dc/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_d3867ad30d8907fb54ee7e87213c68dclepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_d3867ad30d8907fb54ee7e87213c68dclepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Abgleichen, anreichern, verknüpfen : das Clustering-Verfahren ; eine neue Möglichkeit für die Analyse und Verbesserung von Katalogdaten</b>. <br/>
<i>BUB - Buch und Bibliothek</i>, 65(09):625-629, 2013.

<br/>
Magnus Pfeffer and Heidrun Wiesenmüller.
<br/>


<a onclick="toggleBibtex('lepsky', '76378a087d37e6c380930dc4bca3448c', 'https://www.bibsonomy.org/bibtex/276378a087d37e6c380930dc4bca3448c/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/276378a087d37e6c380930dc4bca3448c/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_76378a087d37e6c380930dc4bca3448clepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_76378a087d37e6c380930dc4bca3448clepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatische Erschließung : Strategie und Leitlinien der Deutschen Nationalbibliothek</b>.<br/>
2013. 
<br/>Christa Schöning-Walter.
<br/>


<a onclick="toggleBibtex('lepsky', 'edeb3f58006027e249a38cedccd01ea8', 'https://www.bibsonomy.org/bibtex/2edeb3f58006027e249a38cedccd01ea8/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2edeb3f58006027e249a38cedccd01ea8/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_edeb3f58006027e249a38cedccd01ea8lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_edeb3f58006027e249a38cedccd01ea8lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Beschlagwortung von deutschsprachigen Netzpublikationen mit dem Vokabular der Gemeinsamen Normdatei (GND)</b>. <br/>
<i>Dialog mit Bibliotheken</i>, 25(2):26-36, 2013.

<br/>
Sandro Uhlmann.
<br/>
<a href="http://nbn-resolving.de/urn:nbn:de:101-20140305238">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '9041cd97f5ea6466cc8d83da1e8971e6', 'https://www.bibsonomy.org/bibtex/29041cd97f5ea6466cc8d83da1e8971e6/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/29041cd97f5ea6466cc8d83da1e8971e6/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_9041cd97f5ea6466cc8d83da1e8971e6lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_9041cd97f5ea6466cc8d83da1e8971e6lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Examining scientific vocabulary : mapping controlled vocabularies with free text keywords</b>. <br/>
<i>Cataloging &amp; Classification Quarterly</i>, 51:655-674, 2013.

<br/>
Hollie White and J. Michael Goodson.
<br/>

<a onclick="toggleAbstract('lepsky', '62dc9e969bc17468c1dbfa9b932da819'); return false;" href="https://www.bibsonomy.org/bibtex/262dc9e969bc17468c1dbfa9b932da819/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '62dc9e969bc17468c1dbfa9b932da819', 'https://www.bibsonomy.org/bibtex/262dc9e969bc17468c1dbfa9b932da819/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/262dc9e969bc17468c1dbfa9b932da819/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_62dc9e969bc17468c1dbfa9b932da819lepsky" style="display:none;border:1px dotted grey;">
Scientific repositories create a new environment for studying traditional information science issues. The interaction between indexing terms provided by users and controlled vocabularies continues to be an area of debate and study. This article reports and analyzes findings from a study that mapped the relationships between free text keywords and controlled vocabulary terms used in the sciences. Based on this study's findings recommendations are made about which vocabularies may be better to use in scientific data repositories.
</div>
<div style="position:relative">						
	<div id="bib_62dc9e969bc17468c1dbfa9b932da819lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A random walk on an ontology : using thesaurus structure for automatic subject indexing</b>. <br/>
<i>Journal of the American Society for Information Science &amp; Technology</i>, 64(7):1330-1344, 2013.

<br/>
Craig Willis and Robert M. Losee.
<br/>

<a onclick="toggleAbstract('lepsky', '8f708d7baae2f0d347a6bd454d4479dc'); return false;" href="https://www.bibsonomy.org/bibtex/28f708d7baae2f0d347a6bd454d4479dc/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8f708d7baae2f0d347a6bd454d4479dc', 'https://www.bibsonomy.org/bibtex/28f708d7baae2f0d347a6bd454d4479dc/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28f708d7baae2f0d347a6bd454d4479dc/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8f708d7baae2f0d347a6bd454d4479dclepsky" style="display:none;border:1px dotted grey;">
Relationships between terms and features are an essential component of thesauri, ontologies, and a range of controlled vocabularies. In this article, we describe ways to identify important concepts in documents using the relationships in a thesaurus or other vocabulary structures. We introduce a methodology for the analysis and modeling of the indexing process based on a weighted random walk algorithm. The primary goal of this research is the analysis of the contribution of thesaurus structure to the indexing process. The resulting models are evaluated in the context of automatic subject indexing using four collections of documents pre-indexed with 4 different thesauri ( AGROVOC [UN Food and Agriculture Organization], high-energy physics taxonomy [ HEP], National Agricultural Library Thesaurus [ NALT], and medical subject headings [ MeSH]). We also introduce a thesaurus-centric matching algorithm intended to improve the quality of candidate concepts. In all cases, the weighted random walk improves automatic indexing performance over matching alone with an increase in average precision ( AP) of 9%for HEP, 11%for MeSH, 35%for NALT, and 37%for AGROVOC. The results of the analysis support our hypothesis that subject indexing is in part a browsing process, and that using the vocabulary and its structure in a thesaurus contributes to the indexing process. The amount that the vocabulary structure contributes was found to differ among the 4 thesauri, possibly due to the vocabulary used in the corresponding thesauri and the structural relationships between the terms. Each of the thesauri and the manual indexing associated with it is characterized using the methods developed here.
</div>
<div style="position:relative">						
	<div id="bib_8f708d7baae2f0d347a6bd454d4479dclepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2012" class="bibsonomy_quicknav_group"><a name="2012">2012</a></h3>
<div style="margin-bottom:1em">
<b>Assessment of indexing trends with specific and general terms for herbal medicine</b>. <br/>
<i>Health Information &amp; Libraries Journal</i>, 29(4):285-295, 2012.

<br/>
Tomaz Bartol.
<br/>
<a href="http://onlinelibrary.wiley.com/doi/10.1111/hir.12005/abstract">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '8486abeb5b090cfdcf364841c79664bf'); return false;" href="https://www.bibsonomy.org/bibtex/28486abeb5b090cfdcf364841c79664bf/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8486abeb5b090cfdcf364841c79664bf', 'https://www.bibsonomy.org/bibtex/28486abeb5b090cfdcf364841c79664bf/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28486abeb5b090cfdcf364841c79664bf/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8486abeb5b090cfdcf364841c79664bflepsky" style="display:none;border:1px dotted grey;">
Background  Concepts for medicinal plants are represented by a variety of associated general terms with specific indexing patterns in databases, which may not consistently reflect growth of records.   Objectives  The objectives of this study are to assess the development in databases by identifying general terms that describe herbal medicine with optimal retrieval recall and to identify possible special trends in co-occurrence of specific and general concepts.   Methods  Different search strategies are tested in cab abstracts, medline and web of science. Specific terms (Origanum and Salvia) are employed. Relevant general terms (e.g. ‘Plants, Medicinal’, Phytotherapy, Herbal drugs) are identified, along with indexing trends and co-occurrences.   Results  Growth trends, in specific (narrower) terms, are similar among databases. General terms, however, exhibit dissimilar trends, sometimes almost opposing one another. Co-occurrence of specific and general terms is changing over time.   Conclusions  General terms may not denote definite development of trends as the use of terms differs amongst databases, making it difficult to correctly assess possible numbers of relevant records. Perceived increase can, sometimes, be attributed to an increased occurrence of a more general term alongside the specific one. Thesaurus-controlled databases may yield more hits, because of ‘up-posted’ (broader) terms. Use of broader terms is helpful as it enhances retrieval of relevant documents.
</div>
<div style="position:relative">						
	<div id="bib_8486abeb5b090cfdcf364841c79664bflepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Semi-automatische Verschlagwortung zur Integration externer semantischer Inhalte innerhalb einer medizinischen Kooperationsplattform</b>.<br/>
2012. 
<br/>Zeljko Carevic.
<br/>
<a href="http://opus.bibl.fh-koeln.de/volltexte/2012/376/pdf/Carevic.pdf">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '44fbcdeaf4da4abb335bea3cf61d7ec9'); return false;" href="https://www.bibsonomy.org/bibtex/244fbcdeaf4da4abb335bea3cf61d7ec9/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '44fbcdeaf4da4abb335bea3cf61d7ec9', 'https://www.bibsonomy.org/bibtex/244fbcdeaf4da4abb335bea3cf61d7ec9/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/244fbcdeaf4da4abb335bea3cf61d7ec9/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_44fbcdeaf4da4abb335bea3cf61d7ec9lepsky" style="display:none;border:1px dotted grey;">
In der vorliegenden Arbeit wurde die Integration von externen semantischen Infor- mationen auf Basis einer einheitlichen Terminologie behandelt. Um den Prozess der Abbildung natürlicher Sprache auf die zugrundeliegende Terminologie zu unterstüt- zen wurde eine automatische Verschlagwortung textbasierter Inhalte vorgenommen. Mittels Methoden der Computerlinguistik konnte eine Vorverarbeitung textbasierter Inhalte durchgeführt werden. Bei der Identifikation medizinisch relevanter Begriffe in textbasierten Inhalten konnte ein domänenspezifisches Begriffssystem unterstützend eingesetzt werden. Durch Anwendung einer einheitlichen Terminologie auf Seiten des Anfragesystems und der Wissensbasis konnte der Prozess der Informationsbeschaffung optimiert werden.
</div>
<div style="position:relative">						
	<div id="bib_44fbcdeaf4da4abb335bea3cf61d7ec9lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatisches Indexieren einer informationswissenschaftlichen Datenbank mit Mehrwortgruppen</b>. <br/>
, 2012.

<br/>
Lena Glaesener.
<br/>

<a onclick="toggleAbstract('lepsky', 'df625681ebfd898d08b3001d5c9dfa47'); return false;" href="https://www.bibsonomy.org/bibtex/2df625681ebfd898d08b3001d5c9dfa47/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'df625681ebfd898d08b3001d5c9dfa47', 'https://www.bibsonomy.org/bibtex/2df625681ebfd898d08b3001d5c9dfa47/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2df625681ebfd898d08b3001d5c9dfa47/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_df625681ebfd898d08b3001d5c9dfa47lepsky" style="display:none;border:1px dotted grey;">
Ein Bericht über die Ergebnisse und die Prozessanalyse einer automatischen Indexierung mit Mehrwortgruppen. Diese Bachelorarbeit beschreibt, inwieweit der Inhalt informationswissenschaftlicher Fachtexte durch informationswissenschaftliches Fachvokabular erschlossen werden kann und sollte und dass in diesen wissenschaftlichen Texten ein Grossteil der fachlichen Inhalte in Mehrwortgruppen vorkommt. Die Ergebnisse wurden durch eine automatische Indexierung mit Mehrwortgruppen mithilfe des Programme Lingo an einer informationswissenschaftlichen Datenbank ermittelt.
</div>
<div style="position:relative">						
	<div id="bib_df625681ebfd898d08b3001d5c9dfa47lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Informationserschließung und Automatisches Indexieren : ein Lehr- und Arbeitsbuch</b>.<br/>
2012. 
<br/>Winfried Gödert, Klaus Lepsky and Matthias Nagelschmidt.
<br/>

<a onclick="toggleAbstract('lepsky', 'bb8fc6100068132225410c8a604b561f'); return false;" href="https://www.bibsonomy.org/bibtex/2bb8fc6100068132225410c8a604b561f/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'bb8fc6100068132225410c8a604b561f', 'https://www.bibsonomy.org/bibtex/2bb8fc6100068132225410c8a604b561f/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2bb8fc6100068132225410c8a604b561f/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_bb8fc6100068132225410c8a604b561flepsky" style="display:none;border:1px dotted grey;">
Das Buch vermittelt Kenntnisse über die Modellierung dokumentbezogener Metadaten durch praktische Aufgabenstellungen, begleitende theoretische Erläuterungen sowie ergänzende Übungen. Als Beispiele dienen Bilddokumente und bibliografische Daten. Es wird vermittelt, wie entsprechende Datenbanken aufgebaut und mit geeigneten Suchumgebungen ausgestattet werden. Es wird dargestellt und praktisch geübt, wie Kenntnisse über die Struktur der Daten zum Import von Fremddaten genutzt werden können. Zielvorstellung ist der Aufbau von Datenbanken zur formalen und inhaltlichen Erschließung und die Gestaltung von Retrievalumgebungen, für bibliografische Daten auch die Erstellung von Bibliografien. Als Methoden zur inhaltlichen Erschließung werden besonders die semantische Strukturierung von Themenfeldern am Beispiel des aspektorientierten Thesaurus-Konzepts und das Automatische Indexieren bibliografischer Daten behandelt. Abgerundet wird die Darstellung durch die Diskussion von Bezügen zum Aufbau relationaler Datenbanken für bibliografische Daten sowie Hintergründe der Zeichencodierung und Ordnungsfragen.
</div>
<div style="position:relative">						
	<div id="bib_bb8fc6100068132225410c8a604b561flepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatische Indexierung in der sozialwissenschaftlichen Fachinformation : eine Evaluationsstudie zur maschinellen Erschließung für die Datenbank SOLIS</b>.
<br/>
PhD thesis, Humboldt-Universität zu Berlin, Philosophische Fakultät I, Institut für Bibliotheks- und Informationswissenschaft, 2012.

<br/>
Andreas Kempf.
<br/>

<a onclick="toggleAbstract('lepsky', '5a21101e6bfe4bb98a35a452c9c753a0'); return false;" href="https://www.bibsonomy.org/bibtex/25a21101e6bfe4bb98a35a452c9c753a0/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '5a21101e6bfe4bb98a35a452c9c753a0', 'https://www.bibsonomy.org/bibtex/25a21101e6bfe4bb98a35a452c9c753a0/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/25a21101e6bfe4bb98a35a452c9c753a0/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_5a21101e6bfe4bb98a35a452c9c753a0lepsky" style="display:none;border:1px dotted grey;">
Automatische Indexierungsverfahren werden mit Zunahme der digitalen Verfügbarkeit von Metadaten und Volltexten mehr und mehr als eine mögli- che Antwort auf das Management unstrukturierter Daten diskutiert. In der sozialwissenschaftlichen Fachinformation existiert in diesem Zusammen- hang seit einiger Zeit der Vorschlag eines sogenannten Schalenmodells (vgl. Krause, 1996) mit unterschiedlichen Qualitätsstufen bei der inhaltlichen Er- schlie ssung. Vor diesem Hintergrund beschreibt die Arbeit zunächst Metho- den und Verfahren der inhaltlichen und automatischen Indexierung, bevor vier Testläufe eines automatischen Indexierungssystems (MindServer) zur automatischen Erschlie ssung von Datensätzen der bibliographischen Litera- turdatenbank SOLIS mit Deskriptoren des Thesaurus Sozialwissenschaften sowie der Klassifikation Sozialwissenschaften beschrieben und analysiert werden. Es erfolgt eine ausführliche Fehleranalyse mit Beispielen sowie eine abschlie ssende Diskussion, inwieweit die automatische Erschlie ssung in die- ser Form für die Randbereiche der Datenbank SOLIS für die Zukunft einen gangbaren Weg darstellt. Diese Veröffentlichung geht zurück auf eine Masterarbeit im postgradualen Fernstudiengang Master of Arts (Library and Information Science) an der Humboldt-Universität zu Berlin.
</div>
<div style="position:relative">						
	<div id="bib_5a21101e6bfe4bb98a35a452c9c753a0lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>The HIVE impact : contributing to consistency via automatic indexing</b>. <br/>
In: , pages 582-584.
2012.

<br/>
Hollie White, Craig Willis and Jane Greenberg.
<br/>

<a href="http://dx.doi.org/10.1145/2132176.2132297">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '3e1a7ce8f43d49a22dab826444550747'); return false;" href="https://www.bibsonomy.org/bibtex/23e1a7ce8f43d49a22dab826444550747/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '3e1a7ce8f43d49a22dab826444550747', 'https://www.bibsonomy.org/bibtex/23e1a7ce8f43d49a22dab826444550747/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/23e1a7ce8f43d49a22dab826444550747/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_3e1a7ce8f43d49a22dab826444550747lepsky" style="display:none;border:1px dotted grey;">
Research has shown that automatic subject indexing is more efficient and consistent than manual indexing; yet many organizations continue to use manual indexing because of the unacceptable quality of automatically produced results. This poster presents the results of an exploratory experiment examining consistency stemming from a machine-aided indexing approach. The HIVE vocabulary server was used to present concepts to 31 workshop participants. The presentation of terms via an automatic sequence reduced the indexer burden and contributed to increased consistency. This poster reports initial results and provides a framework for further exploration of automatic indexing in manual workflows.
</div>
<div style="position:relative">						
	<div id="bib_3e1a7ce8f43d49a22dab826444550747lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2011" class="bibsonomy_quicknav_group"><a name="2011">2011</a></h3>
<div style="margin-bottom:1em">
<b>Automatische Verfahren für die Formalerschließung im Projekt PETRUS</b>. <br/>
<i>Dialog mit Bibliotheken</i>(2):5-10, 2011.

<br/>
Christian Beyer and Daniela Trunk.
<br/>


<a onclick="toggleBibtex('lepsky', '593cce0f3fade519f0add2ae950dc4d0', 'https://www.bibsonomy.org/bibtex/2593cce0f3fade519f0add2ae950dc4d0/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2593cce0f3fade519f0add2ae950dc4d0/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_593cce0f3fade519f0add2ae950dc4d0lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_593cce0f3fade519f0add2ae950dc4d0lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Erschließungsverfahren für Netzpublikationen : zum Stand der Arbeiten im Projekt PETRUS</b>. <br/>
<i>Dialog mit Bibliotheken</i>, 23(1):31-36, 2011.

<br/>
Christa Schöning-Walter.
<br/>
<a href="http://nbn-resolving.de/urn:nbn:de:101-2011101170">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', 'a207da25f08df349869a37e3713c4f64', 'https://www.bibsonomy.org/bibtex/2a207da25f08df349869a37e3713c4f64/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2a207da25f08df349869a37e3713c4f64/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_a207da25f08df349869a37e3713c4f64lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_a207da25f08df349869a37e3713c4f64lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatic Semantic subject indexing of web documents in highly inflected languages</b>.<br/>
In: 
G. Antoniou, M. Grobelnik, E. Simperl, B. Parsia, D. Plexousakis, P. D. Leenheer and J. Pan, editors, 
<i>The Semantic Web: Research and Applications</i>, pages 215-229.
Springer, Berlin ; Heidelberg, 2011.

<br/>
Reetta Sinkkilä, Osma Suominen and Eero Hyvönen.
<br/>

<a href="http://link.springer.com/chapter/10.1007/978-3-642-21034-1_15">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'c928264231fbedbadc4c9b9fd6adaca8'); return false;" href="https://www.bibsonomy.org/bibtex/2c928264231fbedbadc4c9b9fd6adaca8/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'c928264231fbedbadc4c9b9fd6adaca8', 'https://www.bibsonomy.org/bibtex/2c928264231fbedbadc4c9b9fd6adaca8/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2c928264231fbedbadc4c9b9fd6adaca8/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_c928264231fbedbadc4c9b9fd6adaca8lepsky" style="display:none;border:1px dotted grey;">
Structured semantic metadata about unstructured web documents can be created using automatic subject indexing methods, avoiding laborious manual indexing. A succesful automatic subject indexing tool for the web should work with texts in multiple languages and be independent of the domain of discourse of the documents and controlled vocabularies. However, analyzing text written in a highly inflected language requires word form normalization that goes beyond rule-based stemming algorithms. We have tested the state-of-the art automatic indexing tool Maui on Finnish texts using three stemming and lemmatization algorithms and tested it with documents and vocabularies of different domains. Both of the lemmatization algorithms we tested performed significantly better than a rule-based stemmer, and the subject indexing quality was found to be comparable to that of human indexers.
</div>
<div style="position:relative">						
	<div id="bib_c928264231fbedbadc4c9b9fd6adaca8lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2010" class="bibsonomy_quicknav_group"><a name="2010">2010</a></h3>
<div style="margin-bottom:1em"><b>Automatische Indexierung von wirtschaftswissenschaftlichen Dokumenten : Implementierung und Evaluierung am Beispiel der Deutschen Zentralbibliothek für Wirtschaftswissenschaften</b>.<br/>
2010. 
<br/>Thomas Groß.
<br/>
<a href="http://edoc.hu-berlin.de/series/berliner-handreichungen/2010-284">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'baf66e34ea4dff9460c4d66aa910105f'); return false;" href="https://www.bibsonomy.org/bibtex/2baf66e34ea4dff9460c4d66aa910105f/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'baf66e34ea4dff9460c4d66aa910105f', 'https://www.bibsonomy.org/bibtex/2baf66e34ea4dff9460c4d66aa910105f/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2baf66e34ea4dff9460c4d66aa910105f/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_baf66e34ea4dff9460c4d66aa910105flepsky" style="display:none;border:1px dotted grey;">
Die Bewertung der Indexierungsqualität bzw. -güte ist ein grundlegendes Problem von manuellen und automatischen Indexierungsverfahren. Letztere werden aber gerade im digitalen Zeitalter als einzige Möglichkeit angesehen, den zunehmenden Schwierigkeiten bibliothekarischer Informationsstrukturie- rung gerecht zu werden. Diese Arbeit befasst sich mit der Funktionsweise, Implementierung und Evaluierung der Sacherschliessungssoftware MindServer Categorizer, der Firma Recommind, an der Deutschen Zentralbibliothek für Wirtschaftswissenschaften (ZBW). Grundlage der maschinellen Sacherschliessung und anschliessenden quantitativen und qualitativen Auswertung bilden rund 39.000 wirtschaftswis- senschaftliche Dokumente aus den Datenbanken Econis und EconStor. Unter Zuhilfenahme des rund 6.000 Deskriptoren umfassenden Standard-Thesaurus Wirtschaft (STW) wird der ursprünglich rein statistische Indexierungsansatz des MindServer Categorizer zu einem begriffsorientierten Verfahren weiterent- wickelt und zur Inhaltserschliessung digitaler Informationsressourcen eingesetzt. Der zentrale Fokus dieser Arbeit liegt vor allem auf der Evaluierung der maschinell beschlagworteten Titel, in Anlehnung und entsprechender Anpas- sung der von Stock (2008) und Lancaster (2003) hierzu vorgeschlagenen Kriterien: Indexierungskonsistenz, -tiefe, -breite, -spezifität, -effektivität. Zusätzlich wird die Belegungsbilanz des STW evaluiert und es erfolgt ferner eine stichprobenartige, qualitative Bewertung der Ergebnisse seitens der zuständigen Fachreferenten und -referentinnen. Diese Veröffentlichung geht, in leicht geänderter Fassung, zurück auf eine Masterarbeit im postgradualen Fernstudiengang Master of Arts (Library and Information Science) an der Humboldt-Universität zu Berlin. Online-Version: http://edoc.hu-berlin.de/series/berliner-handreichungen/2010-284
</div>
<div style="position:relative">						
	<div id="bib_baf66e34ea4dff9460c4d66aa910105flepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Metadata improvement for image information retrieval</b>.<br/>
In: 

<i>Paradigms and conceptual systems in knowledge organization. Proceedings of the eleventh international ISKO conference. 23-26 February 2010. Rome. Italy. Ed. by Claudio Gnoli and Fulvio Mazzocchi</i>, pages 316-321.
Ergon, Würzburg, 2010.

<br/>
Klaus Lepsky, Thomas Müller and Jens Wille.
<br/>


<a onclick="toggleAbstract('lepsky', '72dd79ef2e06f07f30d2917797b30639'); return false;" href="https://www.bibsonomy.org/bibtex/272dd79ef2e06f07f30d2917797b30639/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '72dd79ef2e06f07f30d2917797b30639', 'https://www.bibsonomy.org/bibtex/272dd79ef2e06f07f30d2917797b30639/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/272dd79ef2e06f07f30d2917797b30639/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_72dd79ef2e06f07f30d2917797b30639lepsky" style="display:none;border:1px dotted grey;">
This paper discusses the goals and results of the research project perseus-a as an attempt to improve information retrieval of digital images by automatically connecting them with text based descriptions. The development uses the image collection of prometheus, the distributed digital image archive for research and studies, the articles of the digitized Reallexikon zur Deutschen Kunstgeschichte, art historical terminological resources and classification data, and an open source system for linguistic and statistic automatic indexing called lingo.
</div>
<div style="position:relative">						
	<div id="bib_72dd79ef2e06f07f30d2917797b30639lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Hans Peter Luhn and Herbert M. Ohlman : their roles in the origins of keyword-in-context/permutation automatic indexing</b>. <br/>
<i>Journal of the American Society for Information Science and Technology</i>, 61(4):835-849, 2010.

<br/>
Robert Williams.
<br/>
<a href="http://dx.doi.org/10.1002/asi.21265">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '00197ad9976a0c67dfd2aab8e9a77689'); return false;" href="https://www.bibsonomy.org/bibtex/200197ad9976a0c67dfd2aab8e9a77689/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '00197ad9976a0c67dfd2aab8e9a77689', 'https://www.bibsonomy.org/bibtex/200197ad9976a0c67dfd2aab8e9a77689/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/200197ad9976a0c67dfd2aab8e9a77689/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_00197ad9976a0c67dfd2aab8e9a77689lepsky" style="display:none;border:1px dotted grey;">
The invention of automatic indexing using a keyword-in-context approach has generally been attributed solely to Hans Peter Luhn of IBM. This article shows that credit for this invention belongs equally to Luhn and Herbert Ohlman of the System Development Corporation. It also traces the origins of title derivative automatic indexing, its development and implementation, and current status.
</div>
<div style="position:relative">						
	<div id="bib_00197ad9976a0c67dfd2aab8e9a77689lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2009" class="bibsonomy_quicknav_group"><a name="2009">2009</a></h3>
<div style="margin-bottom:1em">
<b>Can an English word frequency counter serve the requirements of Persian automatic indexing</b>. <br/>
<i>Glottotheory</i>(1/2):18-29, 2009.

<br/>
Mohammad Reza Falahati-Fumani and C. S. Ramachandra.
<br/>
<a href="https://www.researchgate.net/profile/Mohammad_Reza_Falahati_Qadimi_Fumani2/publication/272570007_Can_an_English_Word_Frequency_Counter_Serve_the_Requirements_of_Persian_Automatic_Indexing/links/5733103b08aea45ee838eb19.pdf">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '8e8d538293c80a457e420029f021058f'); return false;" href="https://www.bibsonomy.org/bibtex/28e8d538293c80a457e420029f021058f/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8e8d538293c80a457e420029f021058f', 'https://www.bibsonomy.org/bibtex/28e8d538293c80a457e420029f021058f/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28e8d538293c80a457e420029f021058f/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8e8d538293c80a457e420029f021058flepsky" style="display:none;border:1px dotted grey;">
This article assessed the possible suitability of an English word frequency counter for Persian. Ten Persian articles related to agriculture were input to the software. The error analysis revealed that it had the potential to be used for Persian but modifications were necessary to reduce the errors. The main source of the errors lied in Persian morphology and alphabet and the availability of Persian and Arabic fonts, which permitted writers to introduce unsystematic variations in their writings. It was suggested that the Persian text be handled with all its inconsistencies through algorithms that would merge variations before the frequency count in run, or through deleting illegal spaces and converting them into full spaces and then using a closed list of bound morphemes to join the elements of multi unit words together.
</div>
<div style="position:relative">						
	<div id="bib_8e8d538293c80a457e420029f021058flepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A comparison of sub-word indexing methods for information retrieval</b>.<br/>
In: 

<i>LWA 2009 - Workshop-Woche: Lernen - Wissen - Adaptivität, 21-23 Sept 2009, Darmstadt, Germany.</i>.
Darmstadt, 2009.

<br/>
Johannes Leveling.
<br/>

<a href="http://doras.dcu.ie/16446/">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '8f2998b211c53a5add314af8320a4566'); return false;" href="https://www.bibsonomy.org/bibtex/28f2998b211c53a5add314af8320a4566/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8f2998b211c53a5add314af8320a4566', 'https://www.bibsonomy.org/bibtex/28f2998b211c53a5add314af8320a4566/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28f2998b211c53a5add314af8320a4566/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8f2998b211c53a5add314af8320a4566lepsky" style="display:none;border:1px dotted grey;">
This paper compares different methods of subword indexing and their performance on the English and German domain-specific document collection of the Cross-language Evaluation Forum (CLEF). Four major methods to index sub-words are investigated and compared to indexing stems: 1) sequences of vowels and consonants, 2) a dictionary-based approach for decompounding, 3) overlapping character n-grams, and 4) Knuth’s algorithm for hyphenation. The performance and effects of sub-word extraction on search time and index size and time are reported for English and German retrieval experiments. The main results are: For English, indexing sub-words does not outperform the baseline using standard retrieval on stemmed word forms (–8%mean average precision (MAP), – 11%geometric MAP (GMAP), +1%relevant and retrieved documents (rel ret) for the best experiment). For German, with the exception of n-grams, all methods for indexing sub-words achieve a higher performance than the stemming baseline. The best performing sub-word indexing methods are to use consonant-vowelconsonant sequences and index them together with word stems (+17%MAP, +37%GMAP, +14%rel ret compared to the baseline), or to index syllable-like sub-words obtained from the hyphenation algorithm together with stems (+9%MAP, +23%GMAP, +11%rel ret).
</div>
<div style="position:relative">						
	<div id="bib_8f2998b211c53a5add314af8320a4566lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2008" class="bibsonomy_quicknav_group"><a name="2008">2008</a></h3>
<div style="margin-bottom:1em"><b>Foundation, implementation and evaluation of the MorphoSaurus system : subword indexing, lexical learning and word sense disambiguation for medical cross-language information retrieval</b>.
<br/>
PhD thesis, Friedrich-Schiller-Universität, Jena, 2008.

<br/>
Kornél Markό.
<br/>
<a href="http://d-nb.info/993373798/about/html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '2346b608da8951f0f54aa8dea72e60c3'); return false;" href="https://www.bibsonomy.org/bibtex/22346b608da8951f0f54aa8dea72e60c3/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '2346b608da8951f0f54aa8dea72e60c3', 'https://www.bibsonomy.org/bibtex/22346b608da8951f0f54aa8dea72e60c3/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/22346b608da8951f0f54aa8dea72e60c3/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_2346b608da8951f0f54aa8dea72e60c3lepsky" style="display:none;border:1px dotted grey;">
This work proposes an approach which is intended to meet the particular challenges of Medical Language Processing, in particular medical information retrieval. At its core lies a new type of dictionary, in which the entries are equivalence classes of subwords, i.e., semantically minimal units. These equivalence classes capture intralingual as well as interlingual synonymy. As equivalence classes abstract away from subtle particularities within and between languages and reference to them is realized via a language-independent conceptual system, they form an interlingua. In this work, the theoretical foundations of this approach are elaborated on. Furthermore, design considerations of applications based on the subword methodology are drawn up and showcase implementations are evaluated in detail. Starting with the introduction of Medical Linguistics as a field of active research in Chapter two, its consideration as a domain separated form general linguistics is motivated. In particular, morphological phenomena inherent to medical language are figured in more detail, which leads to an alternative view on medical terms and the introduction of the notion of subwords. Chapter three describes the formal foundation of subwords and the underlying linguistic declarative as well as procedural knowledge. An implementation of the subword model for the medical domain, the MorphoSaurus system, is presented in Chapter four. Emphasis will be given on the multilingual aspect of the proposed approach, including English, German, and Portuguese. The automatic acquisition of (medical) subwords for other languages (Spanish, French, and Swedish), and their integration in already available resources is described in the fifth Chapter. ; The proper handling of acronyms plays a crucial role in medical texts, e.g. in patient records, as well as in scientific literature. Chapter six presents an approach, in which acronyms are automatically acquired from (bio-) medical literature. Furthermore, acronyms and their definitions in different languages are linked to each other using the MorphoSaurus text processing system. Automatic word sense disambiguation is still one of the most challenging tasks in Natural Language Processing. In Chapter seven, cross-lingual considerations lead to a new methodology for automatic disambiguation applied to subwords. Beginning with Chapter eight, a series of applications based onMorphoSaurus are introduced. Firstly, the implementation of the subword approach within a crosslanguage information retrieval setting for the medical domain is described and evaluated on standard test document collections. In Chapter nine, this methodology is extended to multilingual information retrieval in the Web, for which user queries are translated into target languages based on the segmentation into subwords and their interlingual mappings. The cross-lingual, automatic assignment of document descriptors to documents is the topic of Chapter ten. A large-scale evaluation of a heuristic, as well as a statistical algorithm is carried out using a prominent medical thesaurus as a controlled vocabulary. In Chapter eleven, it will be shown how MorphoSaurus can be used to map monolingual, lexical resources across different languages. As a result, a large multilingual medical lexicon with high coverage and complete lexical information is built and evaluated against a comparable, already available and commonly used lexical repository for the medical domain. Chapter twelve sketches a few applications based on MorphoSaurus. The generality and applicability of the subword approach to other domains is outlined, and proof-of-concepts in real-world scenarios are presented. Finally, Chapter thirteen recapitulates the most important aspects of MorphoSaurus and the potential benefit of its employment in medical information systems is carefully assessed, both for medical experts in their everyday life, but also with regard to health care consumers and their existential information needs.
</div>
<div style="position:relative">						
	<div id="bib_2346b608da8951f0f54aa8dea72e60c3lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2007" class="bibsonomy_quicknav_group"><a name="2007">2007</a></h3>
<div style="margin-bottom:1em"><b>Automatisches Indexieren technischer Kongressschriften</b>.
<br/>
PhD thesis, Fachhochschule Köln; Fakultät für Informations- und Kommunikationswissenschaften, Köln, 2007.

<br/>
Ralf Schiffer.
<br/>
<a href="http://ixtrieve.fh-koeln.de/lehre/schiffer-2007.pdf">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '5a554c59bd1b4719201476e5b50193dd', 'https://www.bibsonomy.org/bibtex/25a554c59bd1b4719201476e5b50193dd/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/25a554c59bd1b4719201476e5b50193dd/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_5a554c59bd1b4719201476e5b50193ddlepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_5a554c59bd1b4719201476e5b50193ddlepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2006" class="bibsonomy_quicknav_group"><a name="2006">2006</a></h3>
<div style="margin-bottom:1em">
<b>Automatische Indexierung des Reallexikons zur Deutschen Kunstgeschichte</b>.<br/>
In: 
I. Harms, H.-D. Luckhardt and H. W. Giessen, editors, 
<i>Information und Sprache: Beiträge zu Informationswissenschaft, Computerlinguistik, Bibliothekswesen und verwandten Fächern. Festschrift für Harald H. Zimmermann</i>, pages 169-178.
Saur, München, 2006.

<br/>
Klaus Lepsky.
<br/>



<a onclick="toggleBibtex('lepsky', '8451775ccd0f6e4567276674ed3baf31', 'https://www.bibsonomy.org/bibtex/28451775ccd0f6e4567276674ed3baf31/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28451775ccd0f6e4567276674ed3baf31/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8451775ccd0f6e4567276674ed3baf31lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_8451775ccd0f6e4567276674ed3baf31lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Lingo : ein open source System für die Automatische Indexierung deutschsprachiger Dokumente</b>. <br/>
<i>ABI-Technik</i>, 26:18-29, 2006.

<br/>
Klaus Lepsky and John Vorhauer.
<br/>

<a onclick="toggleAbstract('lepsky', '89fef1b9a3cc679877cf6a50a1fabac4'); return false;" href="https://www.bibsonomy.org/bibtex/289fef1b9a3cc679877cf6a50a1fabac4/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '89fef1b9a3cc679877cf6a50a1fabac4', 'https://www.bibsonomy.org/bibtex/289fef1b9a3cc679877cf6a50a1fabac4/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/289fef1b9a3cc679877cf6a50a1fabac4/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_89fef1b9a3cc679877cf6a50a1fabac4lepsky" style="display:none;border:1px dotted grey;">
Lingo ist ein frei verfügbares System (open source) zur automatischen Indexierung der deutschen Sprache. Bei der Entwicklung von lingo standen hohe Konfigurierbarkeit und Flexibilität des Systems für unterschiedliche Einsatzmöglichkeiten im Vordergrund. Der Beitrag zeigt den Nutzen einer linguistisch basierten automatischen Indexierung faür das Information Retrieval auf. Die für eine Retrievalverbesserung zur Verfügung stehende linguistische Funktionalität von lingo wird vorgestellt und an Beispielen erläutert: Grundformerkennung, Kompositumerkennung bzw. Kompositumzerlegung, Wortrelationierung, lexikalische und algorithmische Mehrwortgruppenerkennung, OCR-Fehlerkorrektur. Der offene Systemaufbau von lingo wird beschrieben, mögliche Einsatzszenarien und Anwendungsgrenzen werden benannt.
</div>
<div style="position:relative">						
	<div id="bib_89fef1b9a3cc679877cf6a50a1fabac4lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2005" class="bibsonomy_quicknav_group"><a name="2005">2005</a></h3>
<div style="margin-bottom:1em"><b>Integration automatischer Indexierung in die Inhaltserschließung : Entwickeln eines Erschließungskonzepts für den FrauenMediaTurm</b>.
<br/>
PhD thesis, Fachhochschule Köln; Fakultät für Informations- und Kommunikationswissenschaften, Köln, 2005.

<br/>
Katrin Baum.
<br/>


<a onclick="toggleBibtex('lepsky', '063b88acf8b4e4b275d941dba74a13a1', 'https://www.bibsonomy.org/bibtex/2063b88acf8b4e4b275d941dba74a13a1/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2063b88acf8b4e4b275d941dba74a13a1/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_063b88acf8b4e4b275d941dba74a13a1lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_063b88acf8b4e4b275d941dba74a13a1lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Grundlagen der automatischen Indexierung : ein Lehrbuch</b>.<br/>
2005. 
<br/>Holger Nohr.
<br/>


<a onclick="toggleBibtex('lepsky', '26e0fa1573aef26332d3364f87f9e6e2', 'https://www.bibsonomy.org/bibtex/226e0fa1573aef26332d3364f87f9e6e2/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/226e0fa1573aef26332d3364f87f9e6e2/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_26e0fa1573aef26332d3364f87f9e6e2lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_26e0fa1573aef26332d3364f87f9e6e2lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatische Indexierung an Bibliotheken : Systeme, Projekte und Einsatzmöglichkeiten</b>.
<br/>
PhD thesis, Fachhochschule Köln; Fakultät für Informations- und Kommunikationswissenschaften, Köln, 2005.

<br/>
Florian Pusl.
<br/>


<a onclick="toggleBibtex('lepsky', 'efa419518620277edde781046b8da870', 'https://www.bibsonomy.org/bibtex/2efa419518620277edde781046b8da870/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2efa419518620277edde781046b8da870/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_efa419518620277edde781046b8da870lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_efa419518620277edde781046b8da870lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Die Stecknadel im Heuhaufen : natürlichsprachlicher Zugang zu Volltextdatenbanken</b>.<br/>
2005. 
<br/>Christoph Rösener.
<br/>


<a onclick="toggleBibtex('lepsky', '67b49a0c4b8e5ac885cff86463188593', 'https://www.bibsonomy.org/bibtex/267b49a0c4b8e5ac885cff86463188593/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/267b49a0c4b8e5ac885cff86463188593/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_67b49a0c4b8e5ac885cff86463188593lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_67b49a0c4b8e5ac885cff86463188593lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Terminology extraction and automatic indexing : comparison and qualitative evaluation of methods</b>. <br/>
In: .
2005.

<br/>
Hans Friedrich Witschel.
<br/>

<a href="http://wortschatz.uni-leipzig.de/~fwitschel/papers/TKEIndexing.pdf">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '0b29ef26b5fbeafcc1668403748c65e9'); return false;" href="https://www.bibsonomy.org/bibtex/20b29ef26b5fbeafcc1668403748c65e9/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '0b29ef26b5fbeafcc1668403748c65e9', 'https://www.bibsonomy.org/bibtex/20b29ef26b5fbeafcc1668403748c65e9/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/20b29ef26b5fbeafcc1668403748c65e9/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_0b29ef26b5fbeafcc1668403748c65e9lepsky" style="display:none;border:1px dotted grey;">
Many terminology engineering processes involve the task of automatic terminology extraction: before the terminology of a given domain can be modelled, organised or standardised, important concepts (or terms) of this domain have to be identified and fed into terminological databases. On the other hand, many machine learning or information retrieval applications require automatic indexing techniques. In Machine Learning applications concerned with the automatic clustering or classification of texts, often feature vectors are needed that describe the contents of a given text briefly but meaningfully. Short but meaningful descriptions of document contents as provided by good index terms are also useful to humans: some knowledge management applications (e.g. topic maps) use them as a set of basic concepts (topics). The author believes that the tasks of terminology extraction and automatic indexing have much in common and can thus benefit from the same set of basic algorithms. It is the goal of this paper to outline some methods that may be used in both contexts, but also to find the discriminating factors between the two tasks that call for the variation of parameters or application of different techniques.
</div>
<div style="position:relative">						
	<div id="bib_0b29ef26b5fbeafcc1668403748c65e9lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2004" class="bibsonomy_quicknav_group"><a name="2004">2004</a></h3>
<div style="margin-bottom:1em"><b>Semantische Anreicherung der Schlagwortnormdatei</b>.<br/>
Fachhochschule Köln: Institut für Informationswissenschaft, 2004. 
<br/>Winfried Gödert, Sarah Hartmann, Jessica Hubrich, Klaus Lepsky, Karin Schulenborg and Daniela Trunk.
<br/>


<a onclick="toggleBibtex('lepsky', '85f90037e48846b042441c29af143459', 'https://www.bibsonomy.org/bibtex/285f90037e48846b042441c29af143459/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/285f90037e48846b042441c29af143459/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_85f90037e48846b042441c29af143459lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_85f90037e48846b042441c29af143459lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Ist automatische Normierung möglich?</b>.<br/>
In: 

<i>Regelwerke für die Sacherschließung: sexy oder uncool? Hrsg. v. Jörn Sieglerschmidt</i>, pages 40-51.
Berlin, 2004.

<br/>
Klaus Lepsky.
<br/>

<a href="http://swop.bsz-bw.de/volltexte/2008/180/">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '6ad0ff3ea3527ac22c6b85ce21864623'); return false;" href="https://www.bibsonomy.org/bibtex/26ad0ff3ea3527ac22c6b85ce21864623/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '6ad0ff3ea3527ac22c6b85ce21864623', 'https://www.bibsonomy.org/bibtex/26ad0ff3ea3527ac22c6b85ce21864623/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/26ad0ff3ea3527ac22c6b85ce21864623/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_6ad0ff3ea3527ac22c6b85ce21864623lepsky" style="display:none;border:1px dotted grey;">
Normierung ist allgemein ein nützliches Instrument der formalen und inhaltlichen Dokument- und Medienbeschreibung. Aus diesem Grund werden in der bibliothekarischen Formal- und Inhaltserschlietextbackslashs sung zentrale Beschreibungselemente über sog. Normdateien kontrolliert, die über die Festlegung von Ansetzungsformen die einheitliche Beschreibung sichern, gleichzeitig durch die Bereitstellung von Nicht-Ansetzungsformen (Verweisungsformen) die Suche auch mit nicht bevorzugten Schreibweisen unterstützen (Synonymen). Normierungselemente in der bibliothekarischen Formalerschließung sind Verfassernamen, Körperschaften, in der Inhaltserschließung sind es Schlagwörter. Die gemeinsame Verwendung der Normdateien in Verbindung mit einem einheitlichen Erfassungsstandard (RAK) bzw. einem Quasi-Erschließungsstandard (RSWK) erleichtert die Datenübernahme und führt zu verlässlichen Erschließungs- und Katalogumgebungen.
</div>
<div style="position:relative">						
	<div id="bib_6ad0ff3ea3527ac22c6b85ce21864623lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Bibliometric analysis of the automatic indexing literature : 1950-2000</b>. <br/>
<i>Information Processing &amp; Management</i>, 40(2):365-377, 2004.

<br/>
Antonio Pulgarín and Isidoro Gil-Leiva.
<br/>
<a href="http://eprints.rclis.org/11730/">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '537edde1f80e4a807db251fc553128df'); return false;" href="https://www.bibsonomy.org/bibtex/2537edde1f80e4a807db251fc553128df/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '537edde1f80e4a807db251fc553128df', 'https://www.bibsonomy.org/bibtex/2537edde1f80e4a807db251fc553128df/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2537edde1f80e4a807db251fc553128df/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_537edde1f80e4a807db251fc553128dflepsky" style="display:none;border:1px dotted grey;">
We present a bibliometric study of a corpus of 839 bibliographic references about automatic indexing, covering the period 1956-2000. We analyse the distribution of authors and works, the obsolescence and its dispersion, and the distribution of the literature by topic, year, and source type. We conclude that: (i) there has been a constant interest on the part of researchers; (ii) the most studied topics were the techniques and methods employed and the general aspects of automatic indexing; (iii) the productivity of the authors does fit a Lotka distribution (Dmax = 0.02 and critical value = 0.054); (iv) the annual aging factor is 95 and (v) the dispersion of the literature is low.
</div>
<div style="position:relative">						
	<div id="bib_537edde1f80e4a807db251fc553128dflepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2003" class="bibsonomy_quicknav_group"><a name="2003">2003</a></h3>
<div style="margin-bottom:1em">
<b>Teilautomatische Erschließung in Pressearchiven : Markt, Produkte, Tests und Anwendungen</b>. <br/>
<i>Info</i>, 7(18):96-100, 2003.

<br/>
Klaus Leesch.
<br/>


<a onclick="toggleBibtex('lepsky', '3f0b724743835d5bc7978bbe611a40e8', 'https://www.bibsonomy.org/bibtex/23f0b724743835d5bc7978bbe611a40e8/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/23f0b724743835d5bc7978bbe611a40e8/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_3f0b724743835d5bc7978bbe611a40e8lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_3f0b724743835d5bc7978bbe611a40e8lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>OPAC-Erweiterung durch automatische Indexierung : eine empirische Untersuchung mit Daten aus dem Österreichischen Verbundkatalog</b>. <br/>
<i>ABI-Technik</i>, 23(4):305-314, 2003.

<br/>
Otto Oberhauser and Josef Labner.
<br/>
<a href="http://eprints.rclis.org/8426/">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'c7f565b2e0eb97c23563156f953cfd1b'); return false;" href="https://www.bibsonomy.org/bibtex/2c7f565b2e0eb97c23563156f953cfd1b/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'c7f565b2e0eb97c23563156f953cfd1b', 'https://www.bibsonomy.org/bibtex/2c7f565b2e0eb97c23563156f953cfd1b/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2c7f565b2e0eb97c23563156f953cfd1b/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_c7f565b2e0eb97c23563156f953cfd1blepsky" style="display:none;border:1px dotted grey;">
In the 1990s the German MILOS projects examined the suitability of an automatic linguistic indexing technique for library OPACs. Following this approach, an empirical investigation was conducted that aimed at assessing and evaluating the use of automatic indexing for the OPACs of the Austrian Library Network. As most users prefer to do their OPAC searches in the basic index the study focused on the effects of enriching this index with automatically generated terms. For this purpose an Aleph 500 OPAC consisting of a representative random sample of records drawn from the Austrian Union Catalogue was used for searching 100 queries in the basic index before and after adding the new index terms. The results include an increase of relevant hits at only moderately lower precision, the reduction of zero-hit results and insights into the role of existing subject headings.
</div>
<div style="position:relative">						
	<div id="bib_c7f565b2e0eb97c23563156f953cfd1blepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2002" class="bibsonomy_quicknav_group"><a name="2002">2002</a></h3>
<div style="margin-bottom:1em"><b>Maschinelles Indexieren und die Erschliessung von Internet-Ressourcen : eine Untersuchung zur Onlineressourcen-Datenbank des Deutschen Bildungsservers</b>.
<br/>
PhD thesis, Fachhochschule Köln; Fakultät für Informations- und Kommunikationswissenschaften, Köln, 2002.

<br/>
Beate Leder.
<br/>


<a onclick="toggleBibtex('lepsky', 'd974f57a20ca46b217c44e8e3e4609cc', 'https://www.bibsonomy.org/bibtex/2d974f57a20ca46b217c44e8e3e4609cc/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2d974f57a20ca46b217c44e8e3e4609cc/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_d974f57a20ca46b217c44e8e3e4609cclepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_d974f57a20ca46b217c44e8e3e4609cclepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2001" class="bibsonomy_quicknav_group"><a name="2001">2001</a></h3>
<div style="margin-bottom:1em">
<b>The nature of indexing : how humans and machines analyze messages and texts for retrieval - Part I: Research, and the nature of human indexing.</b>. <br/>
<i>Information Processing &amp; Management</i>, 37(2):231-254, 2001.
bibtex: journals/ipm/AndersonC01 bibtex[biburl=http://www.bibsonomy.org/bibtex/2e1648fb81c818e8c34f35f736e0b41be/dblp;ee=http://dx.doi.org/10.1016/S0306-4573(00)00026-1;interhash=e1b8d6769a9039db709d81419784902b;intrahash=e1648fb81c818e8c34f35f736e0b41be]
<br/>
James D. Anderson and Jose Pérez Carballo.
<br/>
<a href="http://dblp.uni-trier.de/db/journals/ipm/ipm37.html#AndersonC01">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '77bae5dca229fb29f5f72f92c50b9af9', 'https://www.bibsonomy.org/bibtex/277bae5dca229fb29f5f72f92c50b9af9/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/277bae5dca229fb29f5f72f92c50b9af9/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_77bae5dca229fb29f5f72f92c50b9af9lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_77bae5dca229fb29f5f72f92c50b9af9lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatic indexing of PDF documents with ontologies</b>. <br/>
, 2001.

<br/>
Anjo Anjewierden and Suzanne Kabel.
<br/>
<a href="http://hcs.science.uva.nl/usr/kabel/Bnaic.pdf">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'd6cd6f1f71e6a78afaacf8e78316a607'); return false;" href="https://www.bibsonomy.org/bibtex/2d6cd6f1f71e6a78afaacf8e78316a607/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'd6cd6f1f71e6a78afaacf8e78316a607', 'https://www.bibsonomy.org/bibtex/2d6cd6f1f71e6a78afaacf8e78316a607/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2d6cd6f1f71e6a78afaacf8e78316a607/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_d6cd6f1f71e6a78afaacf8e78316a607lepsky" style="display:none;border:1px dotted grey;">
Indexing large bodies of data is necessary to enable satisfactory search results. Ontologies serve as fixed vocabularies to index data from different viewpoints. We describe how AIDAS, a software tool, automatically divides the source data (PDF documents) into reusable chunks, how it automatically indexes these chunks and stores them in a database to enable reuse. 1
</div>
<div style="position:relative">						
	<div id="bib_d6cd6f1f71e6a78afaacf8e78316a607lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2000" class="bibsonomy_quicknav_group"><a name="2000">2000</a></h3>
<div style="margin-bottom:1em">
<b>Katalogerweiterung durch Scanning und automatische Dokumenterschließung : Ergebnisse des DFG-Projekts KASCADE</b>. <br/>
<i>Zeitschrift für Bibliothekswesen und Bibliographie</i>, 47:305-316, 2000.

<br/>
Klaus Lepsky and Harald Zimmermann.
<br/>

<a onclick="toggleAbstract('lepsky', '04f419311208a29d549273ba4e7c8f42'); return false;" href="https://www.bibsonomy.org/bibtex/204f419311208a29d549273ba4e7c8f42/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '04f419311208a29d549273ba4e7c8f42', 'https://www.bibsonomy.org/bibtex/204f419311208a29d549273ba4e7c8f42/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/204f419311208a29d549273ba4e7c8f42/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_04f419311208a29d549273ba4e7c8f42lepsky" style="display:none;border:1px dotted grey;">
Ziel von KASCADE war der Aufbau einer Datenbasis aus inhaltlich angereicherten und maschinell tiefer gehend erschlossenen Dokumenten. Die Welt des klassischen bibliothekarischen Online-Katalogs (OPAC) wurde dabei in mehrfacher Hinsicht verlassen.Auf der Daten- bzw. Dokumentebene erfolgt keine Beschränkung mehr auf die Datenelemente der monographischen bibliothekarischen Titelaufnahme,auf der Erschließungsebene wurden die Quelldaten angereichert und automatisch verarbeitet, die Erschließungsmethode selbst wurde verbreitert (Gewichtungsverfahren, Dokument-Typisierung). Für das exemplarisch ausgewählte Fach Jura wurden neben konventionellen Volltexten auch elektronisch vorliegende Volltexte ermittelt, ggf. konvertiert und in die Datenbasis aufgenommen.Die projekteigene Durchführung der Scanningarbeiten bot wurden bei der Projektevaluierung mit berücksichtigt.
</div>
<div style="position:relative">						
	<div id="bib_04f419311208a29d549273ba4e7c8f42lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>KASCADE : Dokumentanreicherung und automatische Inhaltserschließung ; Projektbericht und Ergebnisse des Retrievaltests</b>.<br/>
2000. 
<br/>Hartmut Lohmann.
<br/>


<a onclick="toggleBibtex('lepsky', 'c2a74afedc42f51926bd0e1553d49099', 'https://www.bibsonomy.org/bibtex/2c2a74afedc42f51926bd0e1553d49099/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2c2a74afedc42f51926bd0e1553d49099/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_c2a74afedc42f51926bd0e1553d49099lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_c2a74afedc42f51926bd0e1553d49099lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatic indexing and abstracting of document texts</b>.<br/>
2000. 
<br/>MF Moens.
<br/>
<a href="http://books.google.co.in/books?id=RzOc2ygYH0wC">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'dbcefb88086457ce008c4c661a68d045'); return false;" href="https://www.bibsonomy.org/bibtex/2dbcefb88086457ce008c4c661a68d045/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'dbcefb88086457ce008c4c661a68d045', 'https://www.bibsonomy.org/bibtex/2dbcefb88086457ce008c4c661a68d045/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2dbcefb88086457ce008c4c661a68d045/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_dbcefb88086457ce008c4c661a68d045lepsky" style="display:none;border:1px dotted grey;">
Automatic Indexing and Abstracting of Document Texts summarizes the latest techniques of automatic indexing and abstracting, and the results of their application. It also places the techniques in the context of the study of text, manual indexing and abstracting, and the use of the indexing descriptions and abstracts in systems that select documents or information from large collections. Important sections of the book consider the development of new techniques for indexing and abstracting. The techniques involve the following: using text grammars, learning of the themes of the texts including the identification of representative sentences or paragraphs by means of adequate cluster algorithms, and learning of classification patterns of texts. In addition, the book is an attempt to illuminate new avenues for future research. Automatic Indexing and Abstracting of Document Texts is an excellent reference for researchers and professionals working in the field of content management and information retrieval.
</div>
<div style="position:relative">						
	<div id="bib_dbcefb88086457ce008c4c661a68d045lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1999" class="bibsonomy_quicknav_group"><a name="1999">1999</a></h3>
<div style="margin-bottom:1em">
<b>Automatische Indexierung zur Erschließung deutschsprachiger Dokumente</b>. <br/>
<i>nfd - Information - Wissenschaft und Praxis</i>, 50:325-330, 1999.

<br/>
Klaus Lepsky.
<br/>

<a onclick="toggleAbstract('lepsky', '808618be0b06d0f892ffe01e092fc913'); return false;" href="https://www.bibsonomy.org/bibtex/2808618be0b06d0f892ffe01e092fc913/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '808618be0b06d0f892ffe01e092fc913', 'https://www.bibsonomy.org/bibtex/2808618be0b06d0f892ffe01e092fc913/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2808618be0b06d0f892ffe01e092fc913/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_808618be0b06d0f892ffe01e092fc913lepsky" style="display:none;border:1px dotted grey;">
Der Beitrag beschäftigt sich mit der Anwendung eines Verfahrens zur automatischen Indexierung in Bibliotheken. Die Arbeitsweise des Verfahrens und seine Entwicklung innerhalb der von der Deutschen Forschungsgemeinschaft geförderten und an der Universitäts- und Landesbibliothek Düsseldorf gemeinsam mit der Fachrichtung Informationswissenschaft der Universität des Saarlandes durchgeführten Projekte MILOS I, MILOS II und KASCADE werden geschildert. Die Ergebnisse von Retrievaltests belegen die Tauglichkeit des Verfahrens für den Einsatz in Bibliotheken. Aufsetzend auf diesen Ergebnissen werden Perspektiven für die bibliothekarische Sacherschließung im Hinblick auf den Einsatz von automatischen Verfahren entworfen.
</div>
<div style="position:relative">						
	<div id="bib_808618be0b06d0f892ffe01e092fc913lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1998" class="bibsonomy_quicknav_group"><a name="1998">1998</a></h3>
<div style="margin-bottom:1em">
<b>Automatische Erschließung von Internet-Quellen : Möglichkeiten und Grenzen</b>. <br/>
<i>Buch und Bibliothek</i>, 50:336-340, 1998.

<br/>
Klaus Lepsky.
<br/>


<a onclick="toggleBibtex('lepsky', '084a5fbbd715e67a68d94503ceedec65', 'https://www.bibsonomy.org/bibtex/2084a5fbbd715e67a68d94503ceedec65/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2084a5fbbd715e67a68d94503ceedec65/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_084a5fbbd715e67a68d94503ceedec65lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_084a5fbbd715e67a68d94503ceedec65lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Indexierung in der Inhaltserschliessung</b>. <br/>
<i>7e Dag van het Document. 19 &amp; 20 mei 1998. Congrescentrum De Reehorst, Ede. Groningen 1998</i>:12-20, 1998.

<br/>
Klaus Lepsky.
<br/>


<a onclick="toggleBibtex('lepsky', 'e209fc580a1c01868053f5924543a678', 'https://www.bibsonomy.org/bibtex/2e209fc580a1c01868053f5924543a678/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e209fc580a1c01868053f5924543a678/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e209fc580a1c01868053f5924543a678lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_e209fc580a1c01868053f5924543a678lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Katalogerweiterung durch Scanning und Automatische Dokumenterschließung</b>. <br/>
<i>ABI-Technik</i>, 18:56-60, 1998.

<br/>
Klaus Lepsky and Harald Zimmermann.
<br/>

<a onclick="toggleAbstract('lepsky', 'e569ab1179fd5372d2f20b0dba057532'); return false;" href="https://www.bibsonomy.org/bibtex/2e569ab1179fd5372d2f20b0dba057532/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'e569ab1179fd5372d2f20b0dba057532', 'https://www.bibsonomy.org/bibtex/2e569ab1179fd5372d2f20b0dba057532/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e569ab1179fd5372d2f20b0dba057532/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e569ab1179fd5372d2f20b0dba057532lepsky" style="display:none;border:1px dotted grey;">
Der Beitrag befasst sich mit den Zielen, Inhalten und Ergebnissen des von der DFG geförderten Projekts KASCADE. Für KASCADE wurden Katalogdaten aus dem Fachbereich Rechtswissenschafft um Inhaltsverzeichnisse angereichert. Die angereicherten Titeldaten wurden mit einem erweiterten MILOS-Verfahren automatisch indexiert sowie mit den beiden linguistisch und statistisch basierten Verfahren SELIX und THEAS zusätzlich erschlossen. In einem umfangreichen Retrievaltest wurden die Ergebnisse der automatischen Indexierung und Gewichtung untersucht.
</div>
<div style="position:relative">						
	<div id="bib_e569ab1179fd5372d2f20b0dba057532lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatische Indexierung unter Einbeziehung semantischer Relationen : Ergebnisse eines Retrievaltests zum MILOS-II-Projekt</b>.<br/>
1998. 
<br/>Elisabeth Sachse, Martina Liebig and Winfried Gödert.
<br/>
<a href="http://ixtrieve.fh-koeln.de/lehre/sachse-1998-a.pdf">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '7cc4619492cd108bfa6dac851eea0434', 'https://www.bibsonomy.org/bibtex/27cc4619492cd108bfa6dac851eea0434/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/27cc4619492cd108bfa6dac851eea0434/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_7cc4619492cd108bfa6dac851eea0434lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_7cc4619492cd108bfa6dac851eea0434lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1997" class="bibsonomy_quicknav_group"><a name="1997">1997</a></h3>
<div style="margin-bottom:1em">
<b>Auf dem Weg zur automatischen Inhaltserschließung? : das DFG-Projekt MILOS und seine Ergebnisse</b>. <br/>
<i>Mitteilungen der Gesellschaft für Bibliothekswesen und Dokumentation des Landbaues</i>, 53:46-52, 1997.

<br/>
Klaus Lepsky.
<br/>

<a onclick="toggleAbstract('lepsky', '13bc3ae8562b678b093b68e8e6b8328b'); return false;" href="https://www.bibsonomy.org/bibtex/213bc3ae8562b678b093b68e8e6b8328b/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '13bc3ae8562b678b093b68e8e6b8328b', 'https://www.bibsonomy.org/bibtex/213bc3ae8562b678b093b68e8e6b8328b/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/213bc3ae8562b678b093b68e8e6b8328b/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_13bc3ae8562b678b093b68e8e6b8328blepsky" style="display:none;border:1px dotted grey;">
Der Beitrag beschäftigt sich mit der Anwendung eines Verfahrens zur automatischen Indexierung von Titeldaten in Bibliotheken. Die Arbeitsweise des Verfahrens und seine Nutzung innerhalb des von der Deutschen Forschungsgemeinschaft geförderten und an der Universitäts- und Landesbibliothek Düsseldorf durchgeführten Projekts MILOS werden geschildert. Die Ergebnisse eines Retrievaltests belegen die Tauglichkeit des Verfahrens für den Einsatz in Bibliotheken. Aufsetzend auf diesen Ergebnissen werden Perspektiven für eine Abstimmung der bibliothekarischen Sacherschließung im Hinblick auf den Einsatz von automatischen Verfahren entworfen.
</div>
<div style="position:relative">						
	<div id="bib_13bc3ae8562b678b093b68e8e6b8328blepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>DFG-Projekt KASCADE an der ULB Düsseldorf</b>. <br/>
<i>ProLibris</i>, 3:136, 1997.

<br/>
Klaus Lepsky.
<br/>


<a onclick="toggleBibtex('lepsky', 'ecf23eb3f26af69be9ea4299d41828cf', 'https://www.bibsonomy.org/bibtex/2ecf23eb3f26af69be9ea4299d41828cf/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2ecf23eb3f26af69be9ea4299d41828cf/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_ecf23eb3f26af69be9ea4299d41828cflepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_ecf23eb3f26af69be9ea4299d41828cflepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Inhaltserschließung von bibliothekarischen Massendaten</b>.<br/>
In: 

<i>Ressourcen nutzen für neue Aufgaben / 86. Deutscher Bibliothekartag in Erlangen 1996. Hrsg. von Sabine Wefers. Frankfurt am Main 1997. (Zeitschrift für Bibliothekswesen und Bibliographie; Sonderheft 66)</i>, pages 296-306.
Klostermann, Frankfurt am Main, 1997.

<br/>
Klaus Lepsky.
<br/>



<a onclick="toggleBibtex('lepsky', 'cceb248b3d3d30df9d2417710685f4ec', 'https://www.bibsonomy.org/bibtex/2cceb248b3d3d30df9d2417710685f4ec/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2cceb248b3d3d30df9d2417710685f4ec/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_cceb248b3d3d30df9d2417710685f4eclepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_cceb248b3d3d30df9d2417710685f4eclepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1996" class="bibsonomy_quicknav_group"><a name="1996">1996</a></h3>
<div style="margin-bottom:1em">
<b>Automatische Indexierung für Online-Kataloge : Ergebnisse eines Retrievaltests</b>. <br/>
<i>Zeitschrift für Bibliothekswesen und Bibliographie</i>, 43:47-56, 1996.

<br/>
Klaus Lepsky, Jörg Siepmann and Andrea Zimmermann.
<br/>

<a onclick="toggleAbstract('lepsky', '9c32681baa67507024ba328edb9f9cb5'); return false;" href="https://www.bibsonomy.org/bibtex/29c32681baa67507024ba328edb9f9cb5/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '9c32681baa67507024ba328edb9f9cb5', 'https://www.bibsonomy.org/bibtex/29c32681baa67507024ba328edb9f9cb5/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/29c32681baa67507024ba328edb9f9cb5/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_9c32681baa67507024ba328edb9f9cb5lepsky" style="display:none;border:1px dotted grey;">
Examines the effectiveness of automated indexing and presents the results of a study of information retrieval from a segment (40.000 items) of the ULB Düsseldorf database. The segment was selected randomly and all the documents included were indexed automatically. The search topics included 50 subject areas ranging from economic growth to alternative energy sources. While there were 876 relevant documents in the database segment for each of the 50 search topics, the recall ranged from 1 to 244 references, with the average being 17.52 documents per topic. Therefore it seems that, in the immediate future, automatic indexing should be used in combination with intellectual indexing.
</div>
<div style="position:relative">						
	<div id="bib_9c32681baa67507024ba328edb9f9cb5lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Indexierung und bibliothekarische Inhaltserschließung : Ergebnisse des DFG-Projekts MILOS I</b>.<br/>
In: 
E. Niggemann and K. Lepsky, editors, 
<i>Zukunft der Sacherschließung im OPAC: Vorträge des 2. Düsseldorfer OPAC-Kolloquiums am 21. Juni 1996</i>, pages 13-36.
Universitäts- und Landesbibliothek, Düsseldorf, 1996.

<br/>
Klaus Lepsky.
<br/>



<a onclick="toggleBibtex('lepsky', '60cd982c6f6c9a75536768d7db1bcda5', 'https://www.bibsonomy.org/bibtex/260cd982c6f6c9a75536768d7db1bcda5/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/260cd982c6f6c9a75536768d7db1bcda5/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_60cd982c6f6c9a75536768d7db1bcda5lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_60cd982c6f6c9a75536768d7db1bcda5lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatisierung in der Sacherschließung : maschinelles Indexieren von Titeldaten</b>. <br/>
<i>Die Herausforderung der Bibliotheken durch elektronische Medien und neue Organisationsformen / 85. Deutscher Bibliothekartag in Göttingen 1995. Hrsg. von Sabine Wefers. Frankfurt am Main 1996. (Zeitschrift für Bibliothekswesen und Bibliographie; Sonderheft 63)</i>:223-233, 1996.

<br/>
Klaus Lepsky.
<br/>


<a onclick="toggleBibtex('lepsky', 'e61571aead3480e88a7ad61debbecfc9', 'https://www.bibsonomy.org/bibtex/2e61571aead3480e88a7ad61debbecfc9/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e61571aead3480e88a7ad61debbecfc9/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e61571aead3480e88a7ad61debbecfc9lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_e61571aead3480e88a7ad61debbecfc9lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Vom OPAC zum Hyperkatalog : Daten und Indexierung</b>.<br/>
In: 

<i>Erschließen, Suchen, Finden: Vorträge aus den bibliothekarischen Arbeitsgruppen der 19. und 20. Jahrestagungen (Basel 1995 / Freiburg 1996) der Gesellschaft für Klassifikation. Hrsg.: H.-J. Hermes u. H.-J. Wätjen</i>, pages 65-73.
BIS, Oldenburg, 1996.

<br/>
Klaus Lepsky.
<br/>



<a onclick="toggleBibtex('lepsky', 'e0e4388dc00eac7eee0c167d1a9ac242', 'https://www.bibsonomy.org/bibtex/2e0e4388dc00eac7eee0c167d1a9ac242/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e0e4388dc00eac7eee0c167d1a9ac242/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e0e4388dc00eac7eee0c167d1a9ac242lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_e0e4388dc00eac7eee0c167d1a9ac242lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Zukunft der Sacherschließung im OPAC : Vorträge des 2. Düsseldorfer OPAC-Kolloquiums am 21. Juni 1996</b>.<br/>
1996. 

<br/>


<a onclick="toggleBibtex('lepsky', 'd21fe3f574986af441b5297a8fb0a630', 'https://www.bibsonomy.org/bibtex/2d21fe3f574986af441b5297a8fb0a630/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2d21fe3f574986af441b5297a8fb0a630/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_d21fe3f574986af441b5297a8fb0a630lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_d21fe3f574986af441b5297a8fb0a630lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1994" class="bibsonomy_quicknav_group"><a name="1994">1994</a></h3>
<div style="margin-bottom:1em">
<b>Automatische Indexierung</b>.<br/>
In: 

<i>Wissensrepräsentation und Information Retrieval</i>, pages 138-196.
Universität, Potsdam, 1994.

<br/>
Gerhard Knorz.
<br/>



<a onclick="toggleBibtex('lepsky', '6cc87822b7a00baa7b5b9bbba1c4442e', 'https://www.bibsonomy.org/bibtex/26cc87822b7a00baa7b5b9bbba1c4442e/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/26cc87822b7a00baa7b5b9bbba1c4442e/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_6cc87822b7a00baa7b5b9bbba1c4442elepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_6cc87822b7a00baa7b5b9bbba1c4442elepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Maschinelle Indexierung von Titelaufnahmen zur Verbesserung der sachlichen Erschließung in Online-Publikumskatalogen</b>.<br/>
1994. 
<br/>Klaus Lepsky.
<br/>


<a onclick="toggleBibtex('lepsky', '1b502ce4312926f4ed78b21ada5aa7bd', 'https://www.bibsonomy.org/bibtex/21b502ce4312926f4ed78b21ada5aa7bd/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/21b502ce4312926f4ed78b21ada5aa7bd/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_1b502ce4312926f4ed78b21ada5aa7bdlepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_1b502ce4312926f4ed78b21ada5aa7bdlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Maschinelles Indexieren zur Verbesserung der sachlichen Suche im OPAC : DFG-Projekt an der Universitäts- und Landesbibliothek Düsseldorf</b>. <br/>
<i>Bibliotheksdienst</i>, 28:1234-1242, 1994.

<br/>
Klaus Lepsky.
<br/>


<a onclick="toggleBibtex('lepsky', 'e24c569a0f2c6791161f207366faed2d', 'https://www.bibsonomy.org/bibtex/2e24c569a0f2c6791161f207366faed2d/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e24c569a0f2c6791161f207366faed2d/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e24c569a0f2c6791161f207366faed2dlepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_e24c569a0f2c6791161f207366faed2dlepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1989" class="bibsonomy_quicknav_group"><a name="1989">1989</a></h3>
<div style="margin-bottom:1em">
<b>The effectiveness of a nonsyntactic approach to automatic phrase indexing for document retrieval</b>. <br/>
<i>Journal of the American Society for Information Science</i>, 40(2):115-132, 1989.

<br/>
Joel Fagan.
<br/>
<a href="http://dx.doi.org/10.1002/(SICI)1097-4571(198903)40:2%3C115::AID-ASI6%3E3.0.CO;2-B">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '013119879c16068ddd37c56ca4ec7e59'); return false;" href="https://www.bibsonomy.org/bibtex/2013119879c16068ddd37c56ca4ec7e59/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '013119879c16068ddd37c56ca4ec7e59', 'https://www.bibsonomy.org/bibtex/2013119879c16068ddd37c56ca4ec7e59/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2013119879c16068ddd37c56ca4ec7e59/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_013119879c16068ddd37c56ca4ec7e59lepsky" style="display:none;border:1px dotted grey;">
It may be possible to improve the quality of automatic indexing systems by using complex descriptors, for example, phrases, in addition to the simple descriptors (words or word stems) that are normally used in automatically constructed representations of document content. This study is directed toward the goal of developing effective methods of identifying phrases in natural language text from which good quality phrase descriptors can be constructed. The effectiveness of one method, a simple nonsyntactic phrase indexing procedure, has been tested on five experimental document collections. The results have been analyzed in order to identify the inadequacies of the procedure, and to determine what kinds of information about text structure are needed in order to construct phrase descriptors that are good indicators of document content. Two primary conclusions have been reached: (1) In the retrieval experiments, the nonsyntactic phrase construction procedure did not consistently yield substantial improvements in effectiveness. It is therefore not likely that phrase indexing of this kind will prove to be an important method of enhancing the performance of automatic document indexing and retrieval systems in operational environments. (2) Many of the shortcomings of the nonsyntactic approach can be overcome by incorporating syntactic information into the phrase construction process. However, a general syntactic analysis facility may be required, since many useful sources of phrases cannot be exploited if only a limited inventory of syntactic patterns can be recognized. Further research should be conducted into methods of incorporating automatic syntactic analysis into content analysis for document retrieval. © 1989 John Wiley &amp; Sons, Inc.
</div>
<div style="position:relative">						
	<div id="bib_013119879c16068ddd37c56ca4ec7e59lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1979" class="bibsonomy_quicknav_group"><a name="1979">1979</a></h3>
<div style="margin-bottom:1em">
<b>Ansätze einer realistischen automatischen Indexierung unter Verwendung linguistischer Verfahren</b>.<br/>
In: 
R. Kuhlen, editor, 
<i>Datenbasen, Datenbanken, Netzwerke. Praxis des IR. Band 1, Aufbau von Datenbasen</i>, pages 311-338.
K. G. Saur, München, 1979.

<br/>
Harald Zimmermann.
<br/>

<a href="http://scidok.sulb.uni-saarland.de/volltexte/2007/748/">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '58335f860ac4e5d4b2474c7c8b943baa'); return false;" href="https://www.bibsonomy.org/bibtex/258335f860ac4e5d4b2474c7c8b943baa/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '58335f860ac4e5d4b2474c7c8b943baa', 'https://www.bibsonomy.org/bibtex/258335f860ac4e5d4b2474c7c8b943baa/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/258335f860ac4e5d4b2474c7c8b943baa/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_58335f860ac4e5d4b2474c7c8b943baalepsky" style="display:none;border:1px dotted grey;">
Zimmermann führt ein in die maschinelle Indexierung, ihre Anwendungsbereiche, die allgemeine Problemstellung, Probleme der maschinellen Sprachanalyse und Anforderungen an Information-Retrieval-Verfahren mit linguistischen Komponenten und stellt einen Vergleich bekannter Verfahren (PASSAT, CONDOR, JUDO) an.
</div>
<div style="position:relative">						
	<div id="bib_58335f860ac4e5d4b2474c7c8b943baalepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1977" class="bibsonomy_quicknav_group"><a name="1977">1977</a></h3>
<div style="margin-bottom:1em"><b>Experimentelle Morphologie in der Informationswissenschaft</b>.<br/>
1977. 
<br/>Rainer Kuhlen.
<br/>


<a onclick="toggleBibtex('lepsky', 'e05b4aad2c87f8672e7da8e76b0b9929', 'https://www.bibsonomy.org/bibtex/2e05b4aad2c87f8672e7da8e76b0b9929/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2e05b4aad2c87f8672e7da8e76b0b9929/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_e05b4aad2c87f8672e7da8e76b0b9929lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_e05b4aad2c87f8672e7da8e76b0b9929lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<!-- 
	This software is distributed under a Creative Commons Attribution 3.0 License
	http://creativecommons.org/licenses/by/3.0/

	*Attribution*
	JavaScript by Mark Schenk, Dominik Benz and Michael Domhardt
	JabRef export filter and css by Michael Domhardt http://mensch-maschine-systemtechnik.de/
	BibSonomy and Typo3 integration by Dominik Benz
	Content by BibSonomy - Lesezeichen und Referenzen teilen - in blau! http://bibsonomy.org/
-->

<script type="text/javascript">
<!--
function toggleAbstract(user,hash) {
	var abs = document.getElementById('abs_'+hash+user);	
	if (abs) {
		if(abs.id.indexOf('abs_') != -1) {
			abs.style.display = ( abs.style.display == 'none' ? '' : 'none' );
		}
	} 
	return;
}

function toggleBibtex(user,hash,biburl) {
    var f = document.getElementById('bib_' + hash + user + '_src');
	if (undefined != f) {
		f.parentNode.removeChild(f);
		return;
	}
	var el = document.getElementById('bib_' + hash + user);
    iframe = document.createElement("iframe");
    iframe.setAttribute("src", biburl);
	iframe.setAttribute("id", 'bib_' + hash + user + '_src');
    iframe.style.width = 500+"px";
    iframe.style.height = 200+"px";
	iframe.style.background = "#eee";
    el.appendChild(iframe);
	return;
}
-->
</script>
