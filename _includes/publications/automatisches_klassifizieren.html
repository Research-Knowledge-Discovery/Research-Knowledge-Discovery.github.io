<h3 id="bib:year-2021" class="bibsonomy_quicknav_group"><a name="2021">2021</a></h3>
<div style="margin-bottom:1em">
<b>Classifying scientific publications with BERT : is self-attention a feature selection method?</b>. <br/>
<i>arXiv:2101.08114 [cs]</i>, 2021.
arXiv: 2101.08114
<br/>
Andres Garcia-Silva and Jose Manuel Gomez-Perez.
<br/>
<a href="http://arxiv.org/abs/2101.08114">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '57864d428bcd30bae72078cf98677e85'); return false;" href="https://www.bibsonomy.org/bibtex/257864d428bcd30bae72078cf98677e85/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '57864d428bcd30bae72078cf98677e85', 'https://www.bibsonomy.org/bibtex/257864d428bcd30bae72078cf98677e85/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/257864d428bcd30bae72078cf98677e85/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_57864d428bcd30bae72078cf98677e85lepsky" style="display:none;border:1px dotted grey;">
We investigate the self-attention mechanism of BERT in a fine-tuning scenario for the classification of scientific articles over a taxonomy of research disciplines. We observe how self-attention focuses on words that are highly related to the domain of the article. Particularly, a small subset of vocabulary words tends to receive most of the attention. We compare and evaluate the subset of the most attended words with feature selection methods normally used for text classification in order to characterize self-attention as a possible feature selection approach. Using ConceptNet as ground truth, we also find that attended words are more related to the research fields of the articles. However, conventional feature selection methods are still a better option to learn classifiers from scratch. This result suggests that, while self-attention identifies domain-relevant terms, the discriminatory information in BERT is encoded in the contextualized outputs and the classification layer. It also raises the question whether injecting feature selection methods in the self-attention mechanism could further optimize single sequence classification using transformers.
</div>
<div style="position:relative">						
	<div id="bib_57864d428bcd30bae72078cf98677e85lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2020" class="bibsonomy_quicknav_group"><a name="2020">2020</a></h3>
<div style="margin-bottom:1em">
<b>Data processing and information classification : an in-memory approach</b>. <br/>
<i>preprints.org</i>, 2020.
Publisher: Preprints
<br/>
Milena Andrighetti, Giovanna Turvani, Giulia Santoro, Marco Vacca, Andrea Marchesin, Fabrizio Ottati, Massimo Ruo Roch, Mariagrazia Graziano and Maurizio Zamboni.
<br/>
<a href="https://www.preprints.org/manuscript/202002.0294/v1">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'edcf3302d77402f97a909025ce10954f'); return false;" href="https://www.bibsonomy.org/bibtex/2edcf3302d77402f97a909025ce10954f/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'edcf3302d77402f97a909025ce10954f', 'https://www.bibsonomy.org/bibtex/2edcf3302d77402f97a909025ce10954f/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2edcf3302d77402f97a909025ce10954f/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_edcf3302d77402f97a909025ce10954flepsky" style="display:none;border:1px dotted grey;">
To live in the information society means to be surrounded by billions of electronic devices full of sensors that constantly acquire data. This enormous amount of data must be processed and classified. A solution commonly adopted is to send these data to server farms to be remotely elaborated. The drawback is a huge battery drain due to high amount of information that must be exchanged. To compensate this problem data must be processed locally, near the sensor itself. But this solution requires huge computational capabilities. While microprocessors, even mobile ones, nowadays have enough computational power, their performance are severely limited by the Memory Wall problem. Memories are too slow, so microprocessors cannot fetch enough data from them, greatly limiting their performance. A solution is the Processing-In-Memory (PIM) approach. New memories are designed that are able to elaborate data inside them eliminating the Memory Wall problem. In this work we present an example of such system, using as a case of study the Bitmap Indexing algorithm. Such algorithm is used to classify data coming from many sources in parallel. We propose an hardware accelerator designed around the Processing-In-Memory approach, that is capable of implementing this algorithm and that can also be reconfigured to do other tasks or to work as standard memory. The architecture has been synthesized using CMOS technology. The results that we have obtained highlights that, not only it is possible to process and classify huge amount of data locally, but also that it is possible to obtain this result with a very low power consumption.
</div>
<div style="position:relative">						
	<div id="bib_edcf3302d77402f97a909025ce10954flepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Octet : online catalog taxonomy enrichment with self-supervision</b>. <br/>
<i>arXiv:2006.10276 [cs]</i>, 2020.
arXiv: 2006.10276
<br/>
Yuning Mao, Tong Zhao, Andrey Kan, Chenwei Zhang, Xin Luna Dong, Christos Faloutsos and Jiawei Han.
<br/>
<a href="http://arxiv.org/abs/2006.10276">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '27c80adddd32c25d00916d4e31453ef6'); return false;" href="https://www.bibsonomy.org/bibtex/227c80adddd32c25d00916d4e31453ef6/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '27c80adddd32c25d00916d4e31453ef6', 'https://www.bibsonomy.org/bibtex/227c80adddd32c25d00916d4e31453ef6/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/227c80adddd32c25d00916d4e31453ef6/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_27c80adddd32c25d00916d4e31453ef6lepsky" style="display:none;border:1px dotted grey;">
Taxonomies have found wide applications in various domains, especially online for item categorization, browsing, and search. Despite the prevalent use of online catalog taxonomies, most of them in practice are maintained by humans, which is labor-intensive and difficult to scale. While taxonomy construction from scratch is considerably studied in the literature, how to effectively enrich existing incomplete taxonomies remains an open yet important research question. Taxonomy enrichment not only requires the robustness to deal with emerging terms but also the consistency between existing taxonomy structure and new term attachment. In this paper, we present a self-supervised end-to-end framework, Octet, for Online Catalog Taxonomy EnrichmenT. Octet leverages heterogeneous information unique to online catalog taxonomies such as user queries, items, and their relations to the taxonomy nodes while requiring no other supervision than the existing taxonomies. We propose to distantly train a sequence labeling model for term extraction and employ graph neural networks (GNNs) to capture the taxonomy structure as well as the query-item-taxonomy interactions for term attachment. Extensive experiments in different online domains demonstrate the superiority of Octet over state-of-the-art methods via both automatic and human evaluations. Notably, Octet enriches an online catalog taxonomy in production to 2 times larger in the open-world evaluation.
</div>
<div style="position:relative">						
	<div id="bib_27c80adddd32c25d00916d4e31453ef6lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Algorithmic labeling in hierarchical classifications of publications : evaluation of bibliographic fields and term weighting approaches</b>. <br/>
<i>arXiv:2004.08090 [cs]</i>, 2020.
arXiv: 2004.08090
<br/>
Peter Sjögårde, Per Ahlgren and Ludo Waltman.
<br/>
<a href="http://arxiv.org/abs/2004.08090">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'f8bcda62b871f909468cdac5ce36dc56'); return false;" href="https://www.bibsonomy.org/bibtex/2f8bcda62b871f909468cdac5ce36dc56/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'f8bcda62b871f909468cdac5ce36dc56', 'https://www.bibsonomy.org/bibtex/2f8bcda62b871f909468cdac5ce36dc56/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2f8bcda62b871f909468cdac5ce36dc56/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_f8bcda62b871f909468cdac5ce36dc56lepsky" style="display:none;border:1px dotted grey;">
Algorithmic classifications of research publications can be used to study many different aspects of the science system, such as the organization of science into fields, the growth of fields, interdisciplinarity, and emerging topics. How to label the classes in these classifications is a problem that has not been thoroughly addressed in the literature. In this study we evaluate different approaches to label the classes in algorithmically constructed classifications of research publications. We focus on two important choices: the choice of (1) different bibliographic fields and (2) different approaches to weight the relevance of terms. To evaluate the different choices, we created two baselines: one based on the Medical Subject Headings in MEDLINE and another based on the Science-Metrix journal classification. We tested to what extent different approaches yield the desired labels for the classes in the two baselines. Based on our results we recommend extracting terms from titles and keywords to label classes at high levels of granularity (e.g. topics). At low levels of granularity (e.g. disciplines) we recommend extracting terms from journal names and author addresses. We recommend the use of a new approach, term frequency to specificity ratio, to calculate the relevance of terms.
</div>
<div style="position:relative">						
	<div id="bib_f8bcda62b871f909468cdac5ce36dc56lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Minimally supervised categorization of text with metadata</b>. <br/>
<i>arXiv:2005.00624 [cs]</i>, 2020.
arXiv: 2005.00624
<br/>
Yu Zhang, Yu Meng, Jiaxin Huang, Frank F. Xu, Xuan Wang and Jiawei Han.
<br/>
<a href="http://arxiv.org/abs/2005.00624">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '298fc299a60480b23ff20949a81a73c8'); return false;" href="https://www.bibsonomy.org/bibtex/2298fc299a60480b23ff20949a81a73c8/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '298fc299a60480b23ff20949a81a73c8', 'https://www.bibsonomy.org/bibtex/2298fc299a60480b23ff20949a81a73c8/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2298fc299a60480b23ff20949a81a73c8/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_298fc299a60480b23ff20949a81a73c8lepsky" style="display:none;border:1px dotted grey;">
Document categorization, which aims to assign a topic label to each document, plays a fundamental role in a wide variety of applications. Despite the success of existing studies in conventional supervised document classification, they are less concerned with two real problems: (1) textbackslashtextitthe presence of metadata: in many domains, text is accompanied by various additional information such as authors and tags. Such metadata serve as compelling topic indicators and should be leveraged into the categorization framework; (2) textbackslashtextitlabel scarcity: labeled training samples are expensive to obtain in some cases, where categorization needs to be performed using only a small set of annotated data. In recognition of these two challenges, we propose textbackslashtextscMetaCat, a minimally supervised framework to categorize text with metadata. Specifically, we develop a generative process describing the relationships between words, documents, labels, and metadata. Guided by the generative model, we embed text and metadata into the same semantic space to encode heterogeneous signals. Then, based on the same generative process, we synthesize training samples to address the bottleneck of label scarcity. We conduct a thorough evaluation on a wide range of datasets. Experimental results prove the effectiveness of textbackslashtextscMetaCat over many competitive baselines.
</div>
<div style="position:relative">						
	<div id="bib_298fc299a60480b23ff20949a81a73c8lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2019" class="bibsonomy_quicknav_group"><a name="2019">2019</a></h3>
<div style="margin-bottom:1em">
<b>New book classification based on Dewey Decimal Classification (DDC) law using tf-idf and cosine similarity method</b>. <br/>
<i>Journal of Physics: Conference Series</i>, 1211:012044, 2019.

<br/>
Y. Nurdiansyah, A. Andrianto and L. Kamshal.
<br/>
<a href="https://doi.org/10.1088%2F1742-6596%2F1211%2F1%2F012044">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'a385f55da69f411f5ca9b8e799fd2d8a'); return false;" href="https://www.bibsonomy.org/bibtex/2a385f55da69f411f5ca9b8e799fd2d8a/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'a385f55da69f411f5ca9b8e799fd2d8a', 'https://www.bibsonomy.org/bibtex/2a385f55da69f411f5ca9b8e799fd2d8a/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2a385f55da69f411f5ca9b8e799fd2d8a/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_a385f55da69f411f5ca9b8e799fd2d8alepsky" style="display:none;border:1px dotted grey;">
Abstract Classification new book is needed in facilitating students and lecturers to find books. The law used is Dewey Decimal Classification (DDC) classification. The application of the DDC classification requires a high level of accuracy and concentration in grouping books into appropriate classes. Errors that occur in the form of discrepancies in the provision of class books. Performance can be improved by the existence of an information system that can help classify classes in books according to DDC law. The process of giving classes to books by looking for the highest similarity between titles and synopsis of books with each DDC dictionary class. Adjusting to the process of giving classes to books at the University of Jember Library, the title, synopsis and DDC dictionary are processed using the text mining method. Text mining produces data in the form of basic words from the title, synopsis and DDC dictionary. The number of occurrences of each word is useful for measuring how important a word is in a document. The method that is suitable for calculating the importance of a word in a document is the method of weighting Term Frequency-Inverse Document Frequency (TF-IDF). The results of the TF-IDF weighting are used to find the highest similarity between the title and the synopsis with the class in the DDC dictionary. The appropriate method in calculating the similarity of two documents is Cosine Similarity. The biggest similarity value between the title and synopsis with the DDC dictionary using Cosine Similarity method is made a priority in determining the class of books. The results of the application of the method in the system there are 20 data books resulting in book classes in DDC 000 class there are 3 books, DDC 100 class is 1 book, DDC class 200 there is 1 book, DDC 300 class there are 6 books, DDC 400 class there are 4 books, DDC 500 class is 1 book, DDC 600 class there are 2 books and DDC 700 class there are 2 books. Testing book classification information system produces accuracy percentage of 35 
</div>
<div style="position:relative">						
	<div id="bib_a385f55da69f411f5ca9b8e799fd2d8alepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Towards robust image classification using sequential attention models</b>. <br/>
<i>arXiv:1912.02184 [cs]</i>, 2019.
arXiv: 1912.02184
<br/>
Daniel Zoran, Mike Chrzanowski, Po-Sen Huang, Sven Gowal, Alex Mott and Pushmeet Kohl.
<br/>
<a href="http://arxiv.org/abs/1912.02184">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '2fa8424308fcacaf6bec6b9f1c8c41a7'); return false;" href="https://www.bibsonomy.org/bibtex/22fa8424308fcacaf6bec6b9f1c8c41a7/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '2fa8424308fcacaf6bec6b9f1c8c41a7', 'https://www.bibsonomy.org/bibtex/22fa8424308fcacaf6bec6b9f1c8c41a7/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/22fa8424308fcacaf6bec6b9f1c8c41a7/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_2fa8424308fcacaf6bec6b9f1c8c41a7lepsky" style="display:none;border:1px dotted grey;">
In this paper we propose to augment a modern neural-network architecture with an attention model inspired by human perception. Specifically, we adversarially train and analyze a neural model incorporating a human inspired, visual attention component that is guided by a recurrent top-down sequential process. Our experimental evaluation uncovers several notable findings about the robustness and behavior of this new model. First, introducing attention to the model significantly improves adversarial robustness resulting in state-of-the-art ImageNet accuracies under a wide range of random targeted attack strengths. Second, we show that by varying the number of attention steps (glances/fixations) for which the model is unrolled, we are able to make its defense capabilities stronger, even in light of stronger attacks --- resulting in a "computational race" between the attacker and the defender. Finally, we show that some of the adversarial examples generated by attacking our model are quite different from conventional adversarial examples --- they contain global, salient and spatially coherent structures coming from the target class that would be recognizable even to a human, and work by distracting the attention of the model away from the main object in the original image.
</div>
<div style="position:relative">						
	<div id="bib_2fa8424308fcacaf6bec6b9f1c8c41a7lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2018" class="bibsonomy_quicknav_group"><a name="2018">2018</a></h3>
<div style="margin-bottom:1em">
<b>Automatic classification using DDC on the Swedish Union Catalogue</b>. <br/>
In: <i>Proceedings of the 18th European Networked Knowledge Organization Systems (NKOS) Workshop co-located with the 22nd International Conference on Theory and Practice of Digital Libraries 2018 (TPDL 2018), Porto, Portugal, September 13, 2018.</i>, pages 4-16.
2018.

<br/>
Koraljka Golub, Johan Hagelbäck and Anders Ardö.
<br/>

<a href="http://ceur-ws.org/Vol-2200/paper1.pdf">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', 'bfd33c29793f00ae6197249723abcc02', 'https://www.bibsonomy.org/bibtex/2bfd33c29793f00ae6197249723abcc02/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2bfd33c29793f00ae6197249723abcc02/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_bfd33c29793f00ae6197249723abcc02lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_bfd33c29793f00ae6197249723abcc02lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Counteracting concept drift in natural langage classifiers : proposal for an automated method</b>.<br/>
2018. Zugl.:Thesis zum Master of Science FHO in Business Administration, Major Information and Data Management.
<br/>Kirsten Scherer Auberson.
<br/>
<a href="https://www.htwchur.ch/fileadmin/htw_chur/angewandte_zukunftstechnologien/SII/churer_schriften/CSI_97_Betrachtung_der_Data_Visualization_Literacy.pdf">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', 'de33acc3a0f58f025e45ac29828eecf6', 'https://www.bibsonomy.org/bibtex/2de33acc3a0f58f025e45ac29828eecf6/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2de33acc3a0f58f025e45ac29828eecf6/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_de33acc3a0f58f025e45ac29828eecf6lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_de33acc3a0f58f025e45ac29828eecf6lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2017" class="bibsonomy_quicknav_group"><a name="2017">2017</a></h3>
<div style="margin-bottom:1em">
<b>The impact of indexing approaches on Arabic text classification</b>. <br/>
<i>Journal of Information Science</i>, 43(2):159-173, 2017.

<br/>
Amer Al-Badarneh, Emad Al-Shawakfa, Basel Bani-Ismail, Khaleel Al-Rababah and Safwan Shatnawi.
<br/>

<a onclick="toggleAbstract('lepsky', 'b66118e5924f39edd9fdac4c648c3c0d'); return false;" href="https://www.bibsonomy.org/bibtex/2b66118e5924f39edd9fdac4c648c3c0d/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'b66118e5924f39edd9fdac4c648c3c0d', 'https://www.bibsonomy.org/bibtex/2b66118e5924f39edd9fdac4c648c3c0d/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2b66118e5924f39edd9fdac4c648c3c0d/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_b66118e5924f39edd9fdac4c648c3c0dlepsky" style="display:none;border:1px dotted grey;">
This paper investigates the impact of using different indexing approaches (full-word, stem, and root) when classifying Arabic text. In this study, the naïve Bayes classifier is used to construct the multinomial classification models and is evaluated using stratified k-fold cross-validation (k ranges from 2 to 10). It is also uses a corpus that consists of 1000 normalized Arabic documents. The results of one experiment in this study show that significant accuracy improvements have occurred when the full-word form is used in most k-folds. Further experiments show that the classifier has achieved the highest accuracy in the eight-fold by using 7/8–1/8 train–test ratio, despite the indexing approach being used. The overall results of this study show that the classifier has achieved the maximum micro-average accuracy 99.36 either by using the full-word form or the stem form. This proves that the stem is a better choice to use when classifying Arabic text, because it makes the corpus dataset smaller and this will enhance both the processing time and storage utilization, and achieve the highest level of accuracy.
</div>
<div style="position:relative">						
	<div id="bib_b66118e5924f39edd9fdac4c648c3c0dlepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Learning domain taxonomies : the TaxoLine approach</b>. <br/>
<i>International Journal of Web Information Systems</i>:00-00, 2017.

<br/>
Omar El idrissi esserhrouchni, bouchra Frikh, Brahim OUHBI and Ismail Khalil Ibrahim.
<br/>
<a href="http://www.emeraldinsight.com/doi/abs/10.1108/IJWIS-04-2017-0024">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '9a0a6553f9ccc9c600793d38e2b59250', 'https://www.bibsonomy.org/bibtex/29a0a6553f9ccc9c600793d38e2b59250/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/29a0a6553f9ccc9c600793d38e2b59250/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_9a0a6553f9ccc9c600793d38e2b59250lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_9a0a6553f9ccc9c600793d38e2b59250lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2016" class="bibsonomy_quicknav_group"><a name="2016">2016</a></h3>
<div style="margin-bottom:1em">
<b>A framework for evaluating automatic indexing or classification in the context of retrieval</b>. <br/>
<i>Journal of the American Society For Information Science And Technology</i>, 67(1):3-16, 2016.

<br/>
Koraljka Golub, Soergel Dagobert, George Buchanan, Douglas Tudhope, Debra Hiom and Marianne Lykke.
<br/>
<a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A842453&amp;dswid=_new">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'be084123eab58c556affb88cfaf600b3'); return false;" href="https://www.bibsonomy.org/bibtex/2be084123eab58c556affb88cfaf600b3/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'be084123eab58c556affb88cfaf600b3', 'https://www.bibsonomy.org/bibtex/2be084123eab58c556affb88cfaf600b3/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2be084123eab58c556affb88cfaf600b3/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_be084123eab58c556affb88cfaf600b3lepsky" style="display:none;border:1px dotted grey;">
Tools for automatic subject assignment help deal with scale and sustainability in creating and enriching metadata, establishing more connections across and between resources and enhancing consistency. While some software vendors and experimental researchers claim the tools can replace manual subject indexing, hard scientific evidence of their performance in operating information environments is scarce. A major reason for this is that research is usually conducted in laboratory conditions, excluding the complexities of real-life systems and situations. The paper reviews and discusses issues with existing evaluation approaches such as problems of aboutness and relevance assessments, implying the need to use more than a single “gold standard” method when evaluating indexing and retrieval and proposes a comprehensive evaluation framework. The framework is informed by a systematic review of the literature on indexing, classification and approaches: evaluating indexing quality directly through assessment by an evaluator or through comparison with a gold standard; evaluating the quality of computer-assisted indexing directly in the context of an indexing workflow, and evaluating indexing quality indirectly through analyzing retrieval performance.
</div>
<div style="position:relative">						
	<div id="bib_be084123eab58c556affb88cfaf600b3lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatische Klassifizierung medizinischer Literatur durch Analyse verfügbarer Notationen</b>.
<br/>
PhD thesis, Hochschule Hannover; Fakultät III: Medien, Information und Design, Hannover, 2016.

<br/>
Andreas Lüschow.
<br/>
<a href="https://serwiss.bib.hs-hannover.de/frontdoor/index/index/docId/1058">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'b2a5ef133ed7c4725ad7139565a9792e'); return false;" href="https://www.bibsonomy.org/bibtex/2b2a5ef133ed7c4725ad7139565a9792e/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'b2a5ef133ed7c4725ad7139565a9792e', 'https://www.bibsonomy.org/bibtex/2b2a5ef133ed7c4725ad7139565a9792e/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2b2a5ef133ed7c4725ad7139565a9792e/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_b2a5ef133ed7c4725ad7139565a9792elepsky" style="display:none;border:1px dotted grey;">
In den letzten Jahren ist, nicht zuletzt aufgrund der schnellen und einfachen Verfügbarkeit von Daten und Informationen, ein Anstieg an veröffentlichter Literatur zu beobachten. Bibliotheken stehen vor der Herausforderung, diese Ressourcen zu erschließen und damit verfügbar zu machen. Ein Teilaspekt ist hierbei die Klassifizierung. Die Arbeit untersucht Voraussetzungen und Möglichkeiten der automatischen Klassifizierung am Beispiel medizinischer Literatur. Der erste, theoretische Teil beinhaltet die Beschreibung der Grundlagen der Inhaltserschließung, des Data Mining und der automatischen Klassifizierung sowie eine umfassende Übersicht über den aktuellen Forschungsstand in diesem Bereich. Im zweiten Teil wird die Auswahl, Aufbereitung und Analyse eines aus Katalogdatensätzen der Bibliothek der Medizinischen Hochschule Hannover bestehenden Datenbestandes erläutert. Die Anwendung von Verfahren des maschinellen Lernens zur Klassifizierung bibliographischer Datensätze wird am Beispiel des Algorithmus k-nearest-neighbours verdeutlicht. Hierbei lässt sich eine korrekte Klassifizierung von rund 58 %der Dokumente erreichen. Abschließend werden Optimierungsansätze (z.B. semi-automatische Verfahren) und Herausforderungen automatischer Klassifizierungsverfahren (z.B. uneinheitlich erschlossene Datensätze oder ungleiche Verteilung der Klassen einer Systematik in den Dokumenten) aufgezeigt.
</div>
<div style="position:relative">						
	<div id="bib_b2a5ef133ed7c4725ad7139565a9792elepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A quantitative analysis of the temporal effects on automatic text classification</b>. <br/>
<i>Journal of the Association for Information Science &amp; Technology</i>, 67(7):1639-1667, 2016.

<br/>
Thiago Salles, Leonardo Rocha, Marcos André Gonçalves, Jussara M. Almeida, Fernando Mourão, Wagner Meira and Felipe Viegas.
<br/>

<a onclick="toggleAbstract('lepsky', '24936c47a387ceb6e0bae2f6a4222182'); return false;" href="https://www.bibsonomy.org/bibtex/224936c47a387ceb6e0bae2f6a4222182/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '24936c47a387ceb6e0bae2f6a4222182', 'https://www.bibsonomy.org/bibtex/224936c47a387ceb6e0bae2f6a4222182/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/224936c47a387ceb6e0bae2f6a4222182/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_24936c47a387ceb6e0bae2f6a4222182lepsky" style="display:none;border:1px dotted grey;">
Automatic text classification ( TC) continues to be a relevant research topic and several TC algorithms have been proposed. However, the majority of TC algorithms assume that the underlying data distribution does not change over time. In this work, we are concerned with the challenges imposed by the temporal dynamics observed in textual data sets. We provide evidence of the existence of temporal effects in three textual data sets, reflected by variations observed over time in the class distribution, in the pairwise class similarities, and in the relationships between terms and classes. We then quantify, using a series of full factorial design experiments, the impact of these effects on four well-known TC algorithms. We show that these temporal effects affect each analyzed data set differently and that they restrict the performance of each considered TC algorithm to different extents. The reported quantitative analyses, which are the original contributions of this article, provide valuable new insights to better understand the behavior of TC algorithms when faced with nonstatic (temporal) data distributions and highlight important requirements for the proposal of more accurate classification models.
</div>
<div style="position:relative">						
	<div id="bib_24936c47a387ceb6e0bae2f6a4222182lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2015" class="bibsonomy_quicknav_group"><a name="2015">2015</a></h3>
<div style="margin-bottom:1em">
<b>Classification using the Zipfian kernel</b>. <br/>
<i>Journal of Classification</i>, 32(2):305-326, 2015.

<br/>
Marcel Jiřina.
<br/>

<a onclick="toggleAbstract('lepsky', '2e36c10c4a375918ecb3551555f43d5a'); return false;" href="https://www.bibsonomy.org/bibtex/22e36c10c4a375918ecb3551555f43d5a/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '2e36c10c4a375918ecb3551555f43d5a', 'https://www.bibsonomy.org/bibtex/22e36c10c4a375918ecb3551555f43d5a/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/22e36c10c4a375918ecb3551555f43d5a/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_2e36c10c4a375918ecb3551555f43d5alepsky" style="display:none;border:1px dotted grey;">
We propose to use the Zipfian distribution as a kernel for the design of a nonparametric classifier in contrast to the Gaussian distribution used in most kernel methods. We show that the Zipfian distribution takes into account multifractal nature of data and gives a true picture of scaling properties inherent in data. We also show that this new look at data structure can lead to a simple classifier that can, for some tasks, outperform more complex systems.
</div>
<div style="position:relative">						
	<div id="bib_2e36c10c4a375918ecb3551555f43d5alepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A new term-weighting scheme for text classification using the odds of positive and negative class probabilities</b>. <br/>
<i>Journal of the Association for Information Science and Technology</i>, 66(12):2553-2565, 2015.

<br/>
Youngjoong Ko.
<br/>
<a href="http://dx.doi.org/10.1002/asi.23338">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'addf73a1d7f49369021418652eb52678'); return false;" href="https://www.bibsonomy.org/bibtex/2addf73a1d7f49369021418652eb52678/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'addf73a1d7f49369021418652eb52678', 'https://www.bibsonomy.org/bibtex/2addf73a1d7f49369021418652eb52678/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2addf73a1d7f49369021418652eb52678/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_addf73a1d7f49369021418652eb52678lepsky" style="display:none;border:1px dotted grey;">
Text classification (TC) is a core technique for text mining and information retrieval. It has been applied to many applications in many different research and industrial areas. Term-weighting schemes assign an appropriate weight to each term to obtain a high TC performance. Although term weighting is one of the important modules for TC and TC has different peculiarities from those in information retrieval, many term-weighting schemes used in information retrieval, such as term frequency–inverse document frequency (tf–idf), have been used in TC in the same manner. The peculiarity of TC that differs most from information retrieval is the existence of class information. This article proposes a new term-weighting scheme that uses class information using positive and negative class distributions. As a result, the proposed scheme, log tf–TRR, consistently performs better than do other schemes using class information as well as traditional schemes such as tf–idf.
</div>
<div style="position:relative">						
	<div id="bib_addf73a1d7f49369021418652eb52678lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2014" class="bibsonomy_quicknav_group"><a name="2014">2014</a></h3>
<div style="margin-bottom:1em">
<b>Automatisierte und semiautomatisierte Klassifizierung : eine Analyse aktueller Projekte</b>. <br/>
<i>Perspektive Bibliothek</i>, 3(1):85-110, 2014.

<br/>
Anna Kasprzik.
<br/>
<a href="http://journals.ub.uni-heidelberg.de/index.php/bibliothek/article/view/14022">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '14f225d594f46e50121b355a3ccdc714'); return false;" href="https://www.bibsonomy.org/bibtex/214f225d594f46e50121b355a3ccdc714/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '14f225d594f46e50121b355a3ccdc714', 'https://www.bibsonomy.org/bibtex/214f225d594f46e50121b355a3ccdc714/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/214f225d594f46e50121b355a3ccdc714/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_14f225d594f46e50121b355a3ccdc714lepsky" style="display:none;border:1px dotted grey;">
Das sprunghafte Anwachsen der Menge digital verfügbarer Dokumente gepaart mit dem Zeit- und Personalmangel an wissenschaftlichen Bibliotheken legt den Einsatz von halb- oder vollautomatischen Verfahren für die verbale und klassifikatorische Inhaltserschliessung nahe. Nach einer kurzen allgemeinen Einführung in die gängige Methodik beleuchtet dieser Artikel eine Reihe von Projekten zur automatisierten Klassifizierung aus dem Zeitraum 2007-2012 und aus dem deutschsprachigen Raum. Ein Grossteil der vorgestellten Projekte verwendet Methoden des Maschinellen Lernens aus der Künstlichen Intelligenz, arbeitet meist mit angepassten Versionen einer kommerziellen Software und bezieht sich in der Regel auf die Dewey Decimal Classification (DDC). Als Datengrundlage dienen Metadatensätze, Abstracs, Inhaltsverzeichnisse und Volltexte in diversen Datenformaten. Die abschliessende Analyse enthält eine Anordnung der Projekte nach einer Reihe von verschiedenen Kriterien und eine Zusammenfassung der aktuellen Lage und der grössten Herausfordungen für automatisierte Klassifizierungsverfahren.
</div>
<div style="position:relative">						
	<div id="bib_14f225d594f46e50121b355a3ccdc714lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>The use of noun phrases in information retrieval : proposing a mechanism for automatic classification</b>.<br/>
In: 

<i>Knowledge organization in the 21st century: between historical patterns and future prospects. Proceedings of the Thirteenth International ISKO Conference 19-22 May 2014, Krakόw, Poland. Ed.: Wieslaw Babik</i>, pages 320-326.
Ergon, Würzburg, 2014.

<br/>
Agnaldo Martins, Renato Souza and Heliana Ribeiro de Mello.
<br/>


<a onclick="toggleAbstract('lepsky', 'd17f5676d8189dc654bcaa4f667839ff'); return false;" href="https://www.bibsonomy.org/bibtex/2d17f5676d8189dc654bcaa4f667839ff/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'd17f5676d8189dc654bcaa4f667839ff', 'https://www.bibsonomy.org/bibtex/2d17f5676d8189dc654bcaa4f667839ff/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2d17f5676d8189dc654bcaa4f667839ff/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_d17f5676d8189dc654bcaa4f667839fflepsky" style="display:none;border:1px dotted grey;">
This paper presents a research on syntactic structures known as noun phrases (NP) being applied to increase the effectiveness and efficiency of the mechanisms for the document's classification. Our hypothesis is the fact that the NP can be used instead of single words as a semantic aggregator to reduce the number of words that will be used for the classification system without losing its semantic coverage, increasing its efficiency. The experiment divided the documents classification process in three phases: a) NP preprocessing; b) system training; and c) classification experiments. In the first step, a corpus of digitalized texts was submitted to a natural language processing platform1 in which the part-of-speech tagging was done, and them PERL scripts pertaining to the PALAVRAS package were used to extract the Noun Phrases. The preprocessing also involved the tasks of a) removing NP low meaning pre-modifiers, as quantifiers; b) identification of synonyms and corresponding substitution for common hyperonyms; and c) stemming of the relevant words contained in the NP, for similitude checking with other NPs. The first tests with the resulting documents have demonstrated its effectiveness. We have compared the structural similarity of the documents before and after the whole pre-processing steps of phase one. The texts maintained the consistency with the original and have kept the readability. The second phase involves submitting the modified documents to a SVM algorithm to identify clusters and classify the documents. The classification rules are to be established using a machine learning approach. Finally, tests will be conducted to check the effectiveness of the whole process.
</div>
<div style="position:relative">						
	<div id="bib_d17f5676d8189dc654bcaa4f667839fflepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>A novel semantic level text classification by combining NLP and thesaurus concepts</b>. <br/>
<i>IOSR Journal of Computer Engineering (IOSR-JCE)</i>, 16(4):14-26, 2014.

<br/>
R Nagaraj, V Thiagarasu and P Vijayakumar.
<br/>
<a href="http://www.iosrjournals.org/iosr-jce/papers/Vol16-issue4/Version-6/C016461426.pdf">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '244b0dce2c7bd1b1c5dfec5f9123a4f6'); return false;" href="https://www.bibsonomy.org/bibtex/2244b0dce2c7bd1b1c5dfec5f9123a4f6/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '244b0dce2c7bd1b1c5dfec5f9123a4f6', 'https://www.bibsonomy.org/bibtex/2244b0dce2c7bd1b1c5dfec5f9123a4f6/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2244b0dce2c7bd1b1c5dfec5f9123a4f6/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_244b0dce2c7bd1b1c5dfec5f9123a4f6lepsky" style="display:none;border:1px dotted grey;">
Text categorization (also known as text classification or topic spotting) is the task of automatically sorting a set of documents into categories from a predefined set. Automated text classification is attractive because it frees organizations from the need of manually organizing document bases, but it can be too expensive or simply not feasible given the time constraints of the application or the number of documents involved. In the previous approaches only the Wikipedia concepts related to terms in syntactic level are used to represent document in semantic level. This paper proposes a new approach to represent semantic level with the use of Word Net. The semantic weight of terms related to the concepts from Wikipedia and Word Net are used to represent semantic information. The semantic vector space model of terms by combining the Word Net and Wikipedia is being further improved the classification accuracy of the Text classification. Because of, two different concept extractor are gives the concepts related to the terms in the syntactic level o find the better concept vector space for documents. So we obtain the improved classification by using this approach. In this study the classification framework are presented. In classification framework, the primary information is effectively kept and the noise is reduced by compressing the original information, so that this framework can guarantee the quality of the input of all classifiers. This proposed method can help to further improve the performance of classification framework by introducing Wikipedia with Word Net. We find that the proposed approach result in a high classification accuracy.
</div>
<div style="position:relative">						
	<div id="bib_244b0dce2c7bd1b1c5dfec5f9123a4f6lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2013" class="bibsonomy_quicknav_group"><a name="2013">2013</a></h3>
<div style="margin-bottom:1em">
<b>Abgleichen, anreichern, verknüpfen : das Clustering-Verfahren ; eine neue Möglichkeit für die Analyse und Verbesserung von Katalogdaten</b>. <br/>
<i>BUB - Buch und Bibliothek</i>, 65(09):625-629, 2013.

<br/>
Magnus Pfeffer and Heidrun Wiesenmüller.
<br/>


<a onclick="toggleBibtex('lepsky', '76378a087d37e6c380930dc4bca3448c', 'https://www.bibsonomy.org/bibtex/276378a087d37e6c380930dc4bca3448c/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/276378a087d37e6c380930dc4bca3448c/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_76378a087d37e6c380930dc4bca3448clepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_76378a087d37e6c380930dc4bca3448clepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2012" class="bibsonomy_quicknav_group"><a name="2012">2012</a></h3>
<div style="margin-bottom:1em"><b>Automatische DDC-Klassifizierung mit Lingo : Vorgehensweise und Ergebnisse</b>.
<br/>
PhD thesis, Fachhochschule Köln; Fakultät für Informations- und Kommunikationswissenschaften, Köln, 2012.

<br/>
Tomislav Jersek.
<br/>

<a onclick="toggleAbstract('lepsky', '6c777d25a1675e9f827b54a992f6894e'); return false;" href="https://www.bibsonomy.org/bibtex/26c777d25a1675e9f827b54a992f6894e/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '6c777d25a1675e9f827b54a992f6894e', 'https://www.bibsonomy.org/bibtex/26c777d25a1675e9f827b54a992f6894e/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/26c777d25a1675e9f827b54a992f6894e/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_6c777d25a1675e9f827b54a992f6894elepsky" style="display:none;border:1px dotted grey;">
Die Arbeit befasst sich mit der Realisierung und der Durchführung einer automatischen DDC- Klassifizierung durch das Indexierungssystem Lingo. Dies geschieht durch die Einbeziehung von Relationen des DFG-Projektes CrissCross, anhand derer Lingo bibliographische Titeldatensätze automatisch klassifiziert. Der dabei verwendete Ansatz wird mit dem üblichen methodischen Vorgehen bei automatischen Klassifizierungssystemen verglichen. Das Klassifizierungsverfahren wird daraufhin anhand einer Testkollektion von bibliographischen Titeldatensätzen der Deutschen Nationalbibliothek (DNB) getestet. Es folgt eine Diskussion der Ergebnisse und eine Bewertung des Klassifizierungssystems.
</div>
<div style="position:relative">						
	<div id="bib_6c777d25a1675e9f827b54a992f6894elepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Maschinelle Sachgruppenvergabe für Netzpublikationen : vom Projekt PETRUS in die Praxis</b>. <br/>
<i>Dialog mit Bibliotheken</i>, 24(1):17-24, 2012.

<br/>
Elisabeth Mödden and Katrin Tomanek.
<br/>
<a href="http://nbn-resolving.de/urn:nbn:de:101-2012100834">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '1088f2fba207ed3af52e7f3c4025cd40', 'https://www.bibsonomy.org/bibtex/21088f2fba207ed3af52e7f3c4025cd40/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/21088f2fba207ed3af52e7f3c4025cd40/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_1088f2fba207ed3af52e7f3c4025cd40lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_1088f2fba207ed3af52e7f3c4025cd40lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em">
<b>Automatische Generierung von DDC-Notationen für Hochschulveröffentlichungen</b>. <br/>
, 2012.

<br/>
Maike Sommer.
<br/>
<a href="http://opus.bsz-bw.de/fhhv/volltexte/2012/397">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', '8431eb9d06a509f54a67d86c519605ad'); return false;" href="https://www.bibsonomy.org/bibtex/28431eb9d06a509f54a67d86c519605ad/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '8431eb9d06a509f54a67d86c519605ad', 'https://www.bibsonomy.org/bibtex/28431eb9d06a509f54a67d86c519605ad/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/28431eb9d06a509f54a67d86c519605ad/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_8431eb9d06a509f54a67d86c519605adlepsky" style="display:none;border:1px dotted grey;">
Das Thema dieser Bachelorarbeit ist die automatische Generierung von Notationen der Dewey-Dezimalklassifikation für Metadaten. Die Metadaten sind im Dublin-Core-Format und stammen vom Server für wissenschaftliche Schriften der Hochschule Hannover. Zu Beginn erfolgt eine allgemeine Einführung über die Methoden und Hauptanwendungsbereiche des automatischen Klassifizierens. Danach werden die Dewey- Dezimalklassifikation und der Prozess der Metadatengewinnung beschrieben. Der theoretische Teil endet mit der Beschreibung von zwei Projekten. In dem ersten Projekt wurde ebenfalls versucht Metadaten mit Notationen der Dewey-Dezimalklassifikation anzureichern. Das Ergebnis des zweiten Projekts ist eine Konkordanz zwischen der Schlagwortnormdatei und der Dewey-Dezimalklassifikation. Diese Konkordanz wurde im praktischen Teil dieser Arbeit dazu benutzt um automatisch Notationen der Dewey- Dezimalklassifikation zu vergeben.
</div>
<div style="position:relative">						
	<div id="bib_8431eb9d06a509f54a67d86c519605adlepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2011" class="bibsonomy_quicknav_group"><a name="2011">2011</a></h3>
<div style="margin-bottom:1em">
<b>An application to support reclassification of large libraries</b>. <br/>
In: , pages 461-464.
2011.

<br/>
Kai Eckert and Magnus Pfeffer.
<br/>



<a onclick="toggleBibtex('lepsky', 'f6eae8f5582eea6dd34e6e7cf59720c9', 'https://www.bibsonomy.org/bibtex/2f6eae8f5582eea6dd34e6e7cf59720c9/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2f6eae8f5582eea6dd34e6e7cf59720c9/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_f6eae8f5582eea6dd34e6e7cf59720c9lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_f6eae8f5582eea6dd34e6e7cf59720c9lepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Forschungsvorhaben Automatische Klassifizierung mit DDC : autoclass/DDC ; Forschungsbericht</b>.<br/>
Forschungsbericht, 2011. 
<br/>Klaus Lepsky, Thomas Müller and Ulrike Reiner.
<br/>

<a onclick="toggleAbstract('lepsky', '22d15298774d5a3a12ec7c4899ae345d'); return false;" href="https://www.bibsonomy.org/bibtex/222d15298774d5a3a12ec7c4899ae345d/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', '22d15298774d5a3a12ec7c4899ae345d', 'https://www.bibsonomy.org/bibtex/222d15298774d5a3a12ec7c4899ae345d/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/222d15298774d5a3a12ec7c4899ae345d/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_22d15298774d5a3a12ec7c4899ae345dlepsky" style="display:none;border:1px dotted grey;">
Im Projekt Colibri/DDC der Verbundzentrale (VZG) des Gemeinsamen Bibliotheksverbundes (GBV) wurde seit 2003 ein Algorithmus zur automatischen Zerlegung von Notationen der Dewey Dezi- malklassifikation (DDC) entwickelt.1 Ebenfalls dort entstand ein System zur automatischen Verga- be von DDC-Notationen zu Dokumenten, d. h. eine automatische DDC-Klassifizierung. Erste Tests des Systems mit einem Titeldatenpool der Deutschen Nationalbibliothek (DNB) wurden durchge- führt und evaluiert.2 Die Ergebnisse belegten die grundsätzliche Tauglichkeit des Verfahrens, zeig- ten aber auch deutlich noch vorhandene Schwachstellen des Ansatzes. Die Evaluierungsergebnisse ließen ein erhebliches Verbesserungspotenzial durch die Integration einer sprachlichen Verarbei- tung (linguistisch basierte automatische Indexierung) der Quelldaten sowie durch die Einbezie- hung von terminologischen Daten (Normdaten, Synonymdateien) in den Klassifizierungsprozess erwarten. Mit der open source-Lösung Lingo3 liegt ein erprobtes und leistungsstarkes System zur automati- schen Indexierung des Deutschen vor, das am Institut für Informationswissenschaft (IWS) der Fachhochschule Köln erfolgreich in Forschung und Lehre eingesetzt und kontinuierlich gepflegt wird. An der DNB wurden in den in Kooperation mit dem IWS durchgeführten Projekten DDC-Deutsch4 und CrissCross5 umfangreiche terminologische Ressourcen aufgebaut, die für eine automatische Klassifizierung mit DDC nutzbar gemacht werden sollten. Ziel des in Kooperation von DNB, VZG und IWS durchgeführten Projekts war die Weiterentwick- lung der automatischen DDC-Klassifizierung durch Integration einer automatischen Indexierung und Aufbereitung und Relationierung terminologischer Ressourcen. Bestandteil des Projekts war ebenfalls eine erneute Evaluierung der erzielten Ergebnisse.
</div>
<div style="position:relative">						
	<div id="bib_22d15298774d5a3a12ec7c4899ae345dlepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2010" class="bibsonomy_quicknav_group"><a name="2010">2010</a></h3>
<div style="margin-bottom:1em">
<b>Automatische DDC-Klassifizierung : bibliografische Titeldatensätze der Deutschen Nationalbibliografie</b>. <br/>
<i>Dialog mit Bibliotheken</i>, 22(1):23-29, 2010.

<br/>
Ulrike Reiner.
<br/>
<a href="http://nbn-resolving.de/urn:nbn:de:101-2011012860">[doi]</a>&nbsp;

<a onclick="toggleBibtex('lepsky', '864d2f99fffd24099f686aeb9533d94c', 'https://www.bibsonomy.org/bibtex/2864d2f99fffd24099f686aeb9533d94c/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2864d2f99fffd24099f686aeb9533d94c/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_864d2f99fffd24099f686aeb9533d94clepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_864d2f99fffd24099f686aeb9533d94clepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2009" class="bibsonomy_quicknav_group"><a name="2009">2009</a></h3>
<div style="margin-bottom:1em"><b>VZG-Projekt Colibri Bewertung von automatisch DDC-klassifizierten Titeldatensätzen der Deutschen Nationalbibliothek (DNB) August 2008 - Februar 2009</b>.<br/>
Projektbericht, Verbundzentrale des Gemeinsamen Bibliotheksverbundes (VZG), 2009. 
<br/>Ulrike Reiner.
<br/>

<a onclick="toggleAbstract('lepsky', 'a9240fe92fd296b5adf3128ff3e69146'); return false;" href="https://www.bibsonomy.org/bibtex/2a9240fe92fd296b5adf3128ff3e69146/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'a9240fe92fd296b5adf3128ff3e69146', 'https://www.bibsonomy.org/bibtex/2a9240fe92fd296b5adf3128ff3e69146/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2a9240fe92fd296b5adf3128ff3e69146/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_a9240fe92fd296b5adf3128ff3e69146lepsky" style="display:none;border:1px dotted grey;">
Das VZG-Projekt Colibri/DDC beschäftigt sich seit 2003 mit automatischen Verfahren zur Dewey- Dezimalklassifikation (Dewey Decimal Classification, kurz DDC). Ziel des Projektes ist eine einheitliche DDC-Erschließung von bibliografischen Titeldatensätzen und eine Unterstützung der DDC-Expert(inn)en und DDC-Laien, z. B. bei der Analyse und Synthese von DDC-Notationen und deren Qualitätskontrolle und der DDC-basierten Suche. Der vorliegende Bericht konzentriert sich auf die erste größere automatische DDC-Klassifizierung und erste automatische und intellektuelle Bewertung mit der Klassifizierungskomponente vcdcl1. Grundlage hierfür waren die von der Deutschen Nationabibliothek (DNB) im November 2007 zur V erfügung gestellten 25. 653 Titeldatensätze (12 W ochen-/Monatslieferungen) der Deutschen Nationalbibliografie der Reihen A, B und H. Nach Erläuterung der automatischen DDC-Klassifizierung und automatischen Bewertung in Kapitel 2 wird in Kapitel 3 auf den DNB-Bericht „ColibriAuswertungDDCEndberichtSommer2008“ eingegangen. Es werden Sachverhalte geklärt und Fragen gestellt, deren Antworten die Weichen für den Verlauf der weiteren Klassifizierungstests stellen werden. Über das Kapitel 3 hinaus führende weitergehende Betrachtungen und Gedanken zur Fortführung der automatischen DDC-Klassifizierung werden in Kapitel 4 angestellt. Der Bericht dient dem vertieften Verständnis für die automatischen Verfahren.
</div>
<div style="position:relative">						
	<div id="bib_a9240fe92fd296b5adf3128ff3e69146lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2006" class="bibsonomy_quicknav_group"><a name="2006">2006</a></h3>
<div style="margin-bottom:1em"><b>Categorisation in Knowledge Contexts</b>.<br/>
2006. 
<br/>James Sinclair.
<br/>
<a href="http://jrsinclair.com/categorisation-research/2006/categorisation-in-knowledge-contexts/index.html">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'f801268d5cd943f7563b3a88696099de'); return false;" href="https://www.bibsonomy.org/bibtex/2f801268d5cd943f7563b3a88696099de/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'f801268d5cd943f7563b3a88696099de', 'https://www.bibsonomy.org/bibtex/2f801268d5cd943f7563b3a88696099de/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2f801268d5cd943f7563b3a88696099de/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_f801268d5cd943f7563b3a88696099delepsky" style="display:none;border:1px dotted grey;">
Categorisation is something that we do naturally and unconsciously every day. We recognise one animal as a cat and another as a dog. We organise objects in the world around us in ways that reﬂect these categories. In our kitchens, we keep baking trays with other baking trays, saucepans with other saucepans and keep food separate from cleaning products. We categorise ideas, people, tasks and objects. Categorisation is fundamental to the way we think.
</div>
<div style="position:relative">						
	<div id="bib_f801268d5cd943f7563b3a88696099delepsky" style="display:inline;position:absolute;"></div>
</div></div>

<div style="margin-bottom:1em"><b>Automatisches Klassifizieren bibliographischer Beschreibungsdaten : Vorgehensweise und Ergebnisse</b>.<br/>
2006. 
<br/>Jens Wille.
<br/>
<a href="http://blackwinter.de/da/wille_-_automatisches_klassifizieren_bibliographischer_beschreibungsdaten_(diplomarbeit).pdf">[doi]</a>&nbsp;
<a onclick="toggleAbstract('lepsky', 'd49a7057f2a03f5cb0a852224ab27eed'); return false;" href="https://www.bibsonomy.org/bibtex/2d49a7057f2a03f5cb0a852224ab27eed/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'd49a7057f2a03f5cb0a852224ab27eed', 'https://www.bibsonomy.org/bibtex/2d49a7057f2a03f5cb0a852224ab27eed/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2d49a7057f2a03f5cb0a852224ab27eed/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_d49a7057f2a03f5cb0a852224ab27eedlepsky" style="display:none;border:1px dotted grey;">
This work deals with the practical aspects of automated categorization of bibliographic records. Its main concern regards the course of action within the ad hoc developed open source program 'COBRA -- Classification Of Bibliographic Records, Automatic'. Preconditions and parameters for application in the library field are clarified. Finally, categorization results of socio-scientific records from the database SOLIS are evaluated. Diese Arbeit befasst sich mit den praktischen Aspekten des Automatischen Klassifizierens bibliographischer Referenzdaten. Im Vordergrund steht die konkrete Vorgehensweise anhand des eigens zu diesem Zweck entwickelten Open Source-Programms 'COBRA -- Classification Of Bibliographic Records, Automatic'. Es werden die Rahmenbedingungen und Parameter für einen Einsatz im bibliothekarischen Umfeld geklärt. Schliesslich erfolgt eine Auswertung von Klassifizierungsergebnissen am Beispiel sozialwissenschaftlicher Daten aus der Datenbank SOLIS.
</div>
<div style="position:relative">						
	<div id="bib_d49a7057f2a03f5cb0a852224ab27eedlepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-2002" class="bibsonomy_quicknav_group"><a name="2002">2002</a></h3>
<div style="margin-bottom:1em"><b>Automatische Klassifizierung und Strukturierung von Internetressourcen</b>.
<br/>
PhD thesis, Fachhochschule Köln; Fakultät für Informations- und Kommunikationswissenschaften, Köln, 2002.

<br/>
Daniel Hörnig.
<br/>


<a onclick="toggleBibtex('lepsky', 'caf6c1fd51de45a03b0c6ce2b4872940', 'https://www.bibsonomy.org/bibtex/2caf6c1fd51de45a03b0c6ce2b4872940/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2caf6c1fd51de45a03b0c6ce2b4872940/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_caf6c1fd51de45a03b0c6ce2b4872940lepsky" style="display:none;border:1px dotted grey;">

</div>
<div style="position:relative">						
	<div id="bib_caf6c1fd51de45a03b0c6ce2b4872940lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<h3 id="bib:year-1998" class="bibsonomy_quicknav_group"><a name="1998">1998</a></h3>
<div style="margin-bottom:1em">
<b>The dynamics of classification systems as boundary objects for cooperation in the electronic library</b>. <br/>
, 47(2):293-, 1998.

<br/>
Hanne Albrechtsen and Elin K. Jacob.
<br/>

<a onclick="toggleAbstract('lepsky', 'ca2486bb65ee78744b2b15444a885970'); return false;" href="https://www.bibsonomy.org/bibtex/2ca2486bb65ee78744b2b15444a885970/lepsky?format=bibtex">[abstract]</a>&nbsp;
<a onclick="toggleBibtex('lepsky', 'ca2486bb65ee78744b2b15444a885970', 'https://www.bibsonomy.org/bibtex/2ca2486bb65ee78744b2b15444a885970/lepsky?format=bibtex'); return false;" href="https://www.bibsonomy.org/bibtex/2ca2486bb65ee78744b2b15444a885970/lepsky?format=bibtex">[BibTeX]</a>&nbsp;
<div id="abs_ca2486bb65ee78744b2b15444a885970lepsky" style="display:none;border:1px dotted grey;">
Investigates the role of classificatory structures in supporting coherence and articulation in contexts where knowledge is produced and mediated.  Discussion on the rationalism, empiricism and social constructivism of classification systems; Role of classification in information ecologies; Progression of public libraries; Collaborative development and the agency of libraries.
</div>
<div style="position:relative">						
	<div id="bib_ca2486bb65ee78744b2b15444a885970lepsky" style="display:inline;position:absolute;"></div>
</div></div>
<!-- 
	This software is distributed under a Creative Commons Attribution 3.0 License
	http://creativecommons.org/licenses/by/3.0/

	*Attribution*
	JavaScript by Mark Schenk, Dominik Benz and Michael Domhardt
	JabRef export filter and css by Michael Domhardt http://mensch-maschine-systemtechnik.de/
	BibSonomy and Typo3 integration by Dominik Benz
	Content by BibSonomy - Lesezeichen und Referenzen teilen - in blau! http://bibsonomy.org/
-->

<script type="text/javascript">
<!--
function toggleAbstract(user,hash) {
	var abs = document.getElementById('abs_'+hash+user);	
	if (abs) {
		if(abs.id.indexOf('abs_') != -1) {
			abs.style.display = ( abs.style.display == 'none' ? '' : 'none' );
		}
	} 
	return;
}

function toggleBibtex(user,hash,biburl) {
    var f = document.getElementById('bib_' + hash + user + '_src');
	if (undefined != f) {
		f.parentNode.removeChild(f);
		return;
	}
	var el = document.getElementById('bib_' + hash + user);
    iframe = document.createElement("iframe");
    iframe.setAttribute("src", biburl);
	iframe.setAttribute("id", 'bib_' + hash + user + '_src');
    iframe.style.width = 500+"px";
    iframe.style.height = 200+"px";
	iframe.style.background = "#eee";
    el.appendChild(iframe);
	return;
}
-->
</script>
